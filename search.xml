<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>jupyter notebook配置笔记</title>
      <link href="/post/202007040910/"/>
      <url>/post/202007040910/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>记录下jupyter notebook的配置。</p><a id="more"></a><h2 id="插件拓展库"><a href="#插件拓展库" class="headerlink" title="插件拓展库"></a>插件拓展库</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install jupyter_contrib_nbextensions</span><br><span class="line">pip install jupyter_nbextensions_configurator</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jupyter nbextensions_configurator install --user</span><br><span class="line">jupyter nbextensions_configurator enable --user</span><br></pre></td></tr></table></figure><p>安装完成后，即可在jupyter的页面看到 Nbextensions 选项卡（或许需要重新打开jupyter）</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200704061750041.png" alt="image-20200704061750041"></p><p>使用filter筛选插件时全小写，大写识别不出来</p><h3 id="Snippets-Menu"><a href="#Snippets-Menu" class="headerlink" title="Snippets Menu"></a>Snippets Menu</h3><p>自定义代码模块</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200704062022806.png" alt="image-20200704062022806"></p><p>可以在对应的库中选择Setup（基本导入），或者根据要求生成代码。</p><p>My favorites 为自定义的代码块，在 Nbextensions 中选择Snippets Menu来设置</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200704062214712.png" alt="image-20200704062214712"></p><p>json内容如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"name"</span> : <span class="string">"My favorites(自定义名称)"</span>,</span><br><span class="line">  <span class="attr">"sub-menu"</span> : [</span><br><span class="line">      &#123;</span><br><span class="line">          <span class="attr">"name"</span> : <span class="string">"代码块名称"</span>,</span><br><span class="line">          <span class="attr">"snippet"</span> : [<span class="string">"import numpy as np"</span>,</span><br><span class="line">            <span class="string">"import pandas as pd"</span>,</span><br><span class="line">            <span class="string">"import tensorflow as tf"</span>,</span><br><span class="line">            <span class="string">"import matplotlib.pyplot as plt"</span>,</span><br><span class="line">            <span class="string">"%matplotlib inline"</span>,</span><br><span class="line">            <span class="string">" "</span>,</span><br><span class="line">            <span class="string">"plt.rcParams['font.sans-serif']=['SimHei'] # 显示中文标签"</span>,</span><br><span class="line">            <span class="string">"plt.rcParams['axes.unicode_minus']=False # 显示负号"</span>]</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">          <span class="attr">"name"</span> : <span class="string">"第二个代码块"</span>,</span><br><span class="line">          <span class="attr">"snippet"</span> : [</span><br><span class="line">          其余内容同上</span><br><span class="line">          ]</span><br><span class="line">      &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>json格式，注意逗号。</p><h3 id="ExecuteTime"><a href="#ExecuteTime" class="headerlink" title="ExecuteTime"></a>ExecuteTime</h3><p>可以在cell执行完毕后显示运行使用的时间与执行的时间</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200704062615009.png" alt="image-20200704062615009"></p><h3 id="Notify"><a href="#Notify" class="headerlink" title="Notify"></a>Notify</h3><p>可以在需要长时间运行代码时使用，运行完毕后提醒自己。</p><h3 id="Table-of-Contents"><a href="#Table-of-Contents" class="headerlink" title="Table of Contents"></a>Table of Contents</h3><p>markdown文本开启目录</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200704062824767.png" alt="image-20200704062824767"></p><h3 id="Variable-Inspector"><a href="#Variable-Inspector" class="headerlink" title="Variable Inspector"></a>Variable Inspector</h3><p>显示所有变量信息</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200704062859359.png" alt="image-20200704062859359"></p><h2 id="修改样式"><a href="#修改样式" class="headerlink" title="修改样式"></a>修改样式</h2><p>jupyterthemes的主题配置简单，但是和一些拓展有些bug而且并不能完全符合自己的喜好。</p><p>故使用自定义CSS的方法来配置。同路径下有个custom.js可以配置js脚本</p><p>配置文件路径： <code>C:\Users\用户名\.jupyter\custom\custom.css</code></p><br><p>关于修改方法：建议打开jupyter页面，然后按F12，在这里测试样式，然后最后再写进代码里保存，刷新页面查看。</p><p>关于单元格字体的样式，修改对象：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200704073730823.png" alt="image-20200704073730823">)<img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200704073737931.png" alt="image-20200704073737931"></p><p>关于代码区域的字体样式，修改对象：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200704085644088.png" alt="image-20200704085644088"></p><p>定义了变量来存储值，修改只需要修改<code>:root</code>里面的值即可，详细的根据自己自定义的样式更改。</p><p>分享一下自己的设置，直接添加到最后面即可。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/******** DIY ********/</span></span><br><span class="line"><span class="comment">/* 定义变量 */</span></span><br><span class="line"><span class="selector-pseudo">:root</span> &#123;</span><br><span class="line">  <span class="comment">/* 不透明度 */</span></span><br><span class="line">  <span class="attribute">--opacity</span>: <span class="number">0.9</span>;</span><br><span class="line">  <span class="comment">/* 代码区域的字体样式 */</span></span><br><span class="line">  <span class="attribute">--code_font_size</span>: <span class="number">16</span>;</span><br><span class="line">  <span class="attribute">--code_font_family</span>: consolas;</span><br><span class="line">  <span class="comment">/* 单元格字体样式 */</span></span><br><span class="line">  <span class="attribute">--cell_font_size</span>: <span class="number">14</span>;</span><br><span class="line">  <span class="attribute">--cell_font_family</span>: consolas;</span><br><span class="line">  <span class="comment">/* 代码区行距  */</span></span><br><span class="line">  <span class="attribute">--line_height</span>: <span class="number">1.4</span>;</span><br><span class="line">  <span class="comment">/* 背景图片url */</span></span><br><span class="line">  <span class="attribute">--background_image_url</span>: <span class="built_in">url</span>(https://gitee.com/lluuiq/blog_img/raw/master/img/<span class="number">932</span>b3092a3fccecb49bb7b7880c3f24a9ed76d83.jpg@<span class="number">1320</span>w_742h.png);</span><br><span class="line">  <span class="comment">/* 网页背景颜色 */</span></span><br><span class="line">  <span class="attribute">--bg_color</span>: gray;</span><br><span class="line">  <span class="comment">/* 笔记本的宽度 （默认居中）*/</span></span><br><span class="line">  <span class="attribute">--width</span>: <span class="number">80%</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* cell单元格区域 */</span></span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.code_cell</span> &#123;</span><br><span class="line">  <span class="comment">/* 字体样式 */</span></span><br><span class="line">  <span class="attribute">font-size</span>: <span class="built_in">calc</span>(var(--cell_font_size) * <span class="number">1px</span>);</span><br><span class="line">  <span class="attribute">font-family</span>: <span class="built_in">var</span>(--code_font_family);</span><br><span class="line">  <span class="comment">/* 行距 */</span></span><br><span class="line">  <span class="attribute">line-height</span>: <span class="built_in">calc</span>(var(--line_height) * <span class="number">1em</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 代码区域 */</span></span><br><span class="line"><span class="selector-class">.CodeMirror</span> &#123;</span><br><span class="line">  <span class="comment">/* 字体样式 */</span></span><br><span class="line">  <span class="attribute">font-size</span>: <span class="built_in">calc</span>(var(--code_font_size) * <span class="number">1px</span>);</span><br><span class="line">  <span class="attribute">font-family</span>: <span class="built_in">var</span>(--code_font_family);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 注释 */</span></span><br><span class="line"><span class="selector-class">.cm-comment</span> &#123;</span><br><span class="line">  <span class="comment">/* 去掉斜体*/</span></span><br><span class="line">  <span class="attribute">font-style</span>: normal <span class="meta">!important</span>;</span><br><span class="line">  <span class="comment">/* 样式与代码区一样 */</span></span><br><span class="line">  <span class="attribute">font-family</span>: <span class="built_in">var</span>(--code_font_family);</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="built_in">var</span>(--code_font_size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 目录 */</span></span><br><span class="line"><span class="selector-id">#toc-wrapper</span> &#123;</span><br><span class="line">  <span class="comment">/* 背景颜色 */</span></span><br><span class="line">  <span class="attribute">background-color</span>: <span class="number">#ffffff</span>;</span><br><span class="line">  <span class="comment">/* 不透明度 */</span></span><br><span class="line">  <span class="attribute">opacity</span>: <span class="built_in">var</span>(--opacity);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 变量信息区域 */</span></span><br><span class="line"><span class="selector-class">.varInspector-float-wrapper</span> &#123;</span><br><span class="line">  <span class="attribute">opacity</span>: <span class="built_in">var</span>(--opacity) <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* 笔记本区域 */</span></span><br><span class="line"><span class="selector-tag">div</span><span class="selector-id">#notebook</span> &#123;</span><br><span class="line">  <span class="comment">/* 不透明度 */</span></span><br><span class="line">  <span class="attribute">opacity</span>: <span class="built_in">var</span>(--opacity);</span><br><span class="line">  <span class="comment">/* 宽度缩小 */</span></span><br><span class="line">  <span class="attribute">width</span>: <span class="built_in">var</span>(--width);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* 笔记本区域的边框角弧度 */</span></span><br><span class="line"><span class="selector-id">#notebook-container</span> &#123;</span><br><span class="line">  <span class="attribute">border-radius</span>: <span class="number">10px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 页面 */</span></span><br><span class="line"><span class="selector-id">#site</span> &#123;</span><br><span class="line">  <span class="comment">/* 背景图片 ，与背景颜色二选一 */</span></span><br><span class="line">  <span class="attribute">background</span>: <span class="built_in">var</span>(--background_image_url) no-repeat fixed;</span><br><span class="line">  <span class="comment">/* 背景颜色 */</span></span><br><span class="line">  <span class="comment">/* background-color: var(--bg_color); */</span></span><br><span class="line">  <span class="attribute">background-size</span>: cover;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>效果图：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200704090834597.png" alt="image-20200704090834597"></p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Anaconda3 </tag>
            
            <tag> jupyter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow2.1 安装以及开启GPU加速</title>
      <link href="/post/202007030500/"/>
      <url>/post/202007030500/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>记录下TensorFlow2的安装以及开启GPU加速功能。</p><p>使用Anaconda3的conda进行安装。</p><a id="more"></a><h2 id="查看GPU驱动版本与升级"><a href="#查看GPU驱动版本与升级" class="headerlink" title="查看GPU驱动版本与升级"></a>查看GPU驱动版本与升级</h2><p>首先确定系统环境变量path里有下方路径，没有的话添加进去。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\NVIDIA Corporation\NVSMI</span><br></pre></td></tr></table></figure><p>然后在终端运行 <code>nvidia-smi</code></p><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703051133275.png" alt="image-20200703051133275"></p><p>这里可以看到我的<code>NVIDIA-SMI</code>版本为382.05 需要升级</p><p>打开 <code>GeForce Experience</code>更新驱动。</p><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703051745498.png" alt="image-20200703051745498"></p><h2 id="安装tensorflow-gpu并配置"><a href="#安装tensorflow-gpu并配置" class="headerlink" title="安装tensorflow-gpu并配置"></a>安装tensorflow-gpu并配置</h2><ol><li><strong>使用conda创建一个虚拟环境并安装tensorflow-gpu</strong></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n tf2 tensorflow-gpu</span><br></pre></td></tr></table></figure><p>其中 -n 后面的 <code>tf2</code>是环境的名称，可自定义。</p><p>中间出现输入 Y/N 的时候可以检查一下要安装的包，确认一下tensorflow版本为2.1。</p><p>并不推荐换国内源安装，我换源安装结果显示的是tensorflow1.x版本。</p><br><ol start="2"><li><strong>安装完成后 启用新环境</strong></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate tf2</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>在新环境中安装一下ipython</strong></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install ipython</span><br></pre></td></tr></table></figure><ol start="4"><li><strong>安装 nb_code，使得 jupyter notebook可以切换kernel</strong></li></ol><p>首先关闭tf2环境，在tf2环境时输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda deactivate</span><br></pre></td></tr></table></figure><p>然后安装nb_code</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install nb_conda</span><br></pre></td></tr></table></figure><p>接着修改一下配置文件，<code>Anaconda3\Lib\site-packages\nb_conda\envmanager.py</code></p><p>找到如下所示的代码块</p><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703110217107.png" alt="image-20200703110217107"></p><p>修改为 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> &#123;</span><br><span class="line"><span class="string">"environments"</span>: [root_env] + [get_info(env) <span class="keyword">for</span> env <span class="keyword">in</span> info[<span class="string">'envs'</span>] <span class="keyword">if</span> env !=root_env[<span class="string">'dir'</span>]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后就可以打开jupyter notebook切换kernel了。</p><h2 id="jupyter-notebook-测试tensorflow"><a href="#jupyter-notebook-测试tensorflow" class="headerlink" title="jupyter notebook 测试tensorflow"></a>jupyter notebook 测试tensorflow</h2><p>在新建notebook时选择环境</p><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703110452754.png" alt="image-20200703110452754"></p><p>或者在已有的notebook中修改环境</p><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703110527821.png" alt="image-20200703110527821"></p><p>查看版本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.__version__</span><br></pre></td></tr></table></figure><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703105923890.png" alt="image-20200703105923890"></p><p>查看是否启用加速</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from tensorflow.python.client import device_lib</span><br><span class="line">print(device_lib.list_local_devices())</span><br></pre></td></tr></table></figure><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703105858744.png" alt="image-20200703105858744"></p><h2 id="pycharm测试tensorflow"><a href="#pycharm测试tensorflow" class="headerlink" title="pycharm测试tensorflow"></a>pycharm测试tensorflow</h2><p>新建一个project，选择已存在的环境，可以看到当前指定的为默认环境，而不是tf2环境，在后方点击 <code>...</code> 图标选择。</p><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703111052850.png" alt="image-20200703111052850"></p><p>我这里点开后自动选择了虚拟环境，如果没有参考该路径选择自己的。并勾选全工程生效。</p><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703111141985.png" alt="image-20200703111141985"></p><p>等待更新</p><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703111209025.png" alt="image-20200703111209025"></p><p>输入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure><p>执行后即可看到运行成功。</p><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703111414478.png" alt="image-20200703111414478"></p><p><img src="C:%5CUsers%5C84452%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200703111421743.png" alt="image-20200703111421743"></p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow2 </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux云服务器配置Anaconda3</title>
      <link href="/post/202007030455/"/>
      <url>/post/202007030455/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>记录一下Linux云服务器上搭建Anaconda3并进行配置的过程，开启远程访问。</p><a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>Linux服务器：Centos7</p><p>Anaconda3版本：2020.02-Linux-x86_64</p><p><a href="https://www.anaconda.com/products/individual" target="_blank" rel="noopener">Anaconda3下载</a></p><h2 id="下载Anaconda3并上传到服务器"><a href="#下载Anaconda3并上传到服务器" class="headerlink" title="下载Anaconda3并上传到服务器"></a>下载Anaconda3并上传到服务器</h2><p>在[说明](# 说明)中的下载地址里，找到Linux版本。</p><p>（选择适合自己的安装包，我这里Linux是<strong>x86_64</strong>）</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630170224375.png" alt="image-20200630170224375"></p><p>将下载的安装包上传到服务器（Xshell、FinalShell等软件）</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630170537967.png" alt="image-20200630170537967"></p><h2 id="安装Anaconda3"><a href="#安装Anaconda3" class="headerlink" title="安装Anaconda3"></a>安装Anaconda3</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3-2020.02-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>安装包的名字对应自己下载的版本即可。</p><br><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630170639627.png" alt="image-20200630170639627"></p><p>回车</p><br><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630170718992.png" alt="image-20200630170718992"></p><p>疯狂回车</p><br><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630170757862.png" alt="image-20200630170757862"></p><p>输入yes</p><br><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630171034378.png" alt="image-20200630171034378"></p><p>按回车安装到当前目录 <code>/root/anaconda3</code></p><br><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630171800088.png" alt="image-20200630171800088"></p><p>输入yes</p><hr><p>最后安装完成后，输入<code>ipython</code>即可启动ipython</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630174756536.png" alt="image-20200630174756536"></p><p>输入<code>exit()</code>或使用<code>ctrl+z</code>退出</p><h2 id="配置-root-bashrc-文件"><a href="#配置-root-bashrc-文件" class="headerlink" title="配置 /root/.bashrc 文件"></a>配置 <code>/root/.bashrc</code> 文件</h2><h3 id="使用Anaconda3的python3-7"><a href="#使用Anaconda3的python3-7" class="headerlink" title="使用Anaconda3的python3.7"></a>使用Anaconda3的python3.7</h3><p>Anaconda3附带的是python3.7，在安装好Anaconda3后，输入python还是linux自带的python2。故对版本进行配置。</p><p>添加如下代码（若安装路径不一样修改为自己的路径 ）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH="/root/anaconda3/bin:$PATH"</span><br></pre></td></tr></table></figure><h3 id="是否显示-base"><a href="#是否显示-base" class="headerlink" title="是否显示(base)"></a>是否显示<code>(base)</code></h3><p>添加Anaconda3的python后会在指令行前面会出现<code>(base)</code></p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630172947611.png" alt="image-20200630172947611"></p><p>表示启用了conda。如果不想显示这个<code>(base)</code>的话，在<code>/root/.bashrc</code>中添加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda deactivate</span><br></pre></td></tr></table></figure><h3 id="配置alias"><a href="#配置alias" class="headerlink" title="配置alias"></a>配置alias</h3><p>加入下方代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alias python2="/usr/bin/python2.7"</span><br></pre></td></tr></table></figure><p>python2为自定义的别名，可以使用py2或者其余自己喜欢的别名替代</p><h3 id="更新-bashrc"><a href="#更新-bashrc" class="headerlink" title="更新.bashrc"></a>更新.bashrc</h3><p>每次修改.bashrc后都要输入<code>source ~/.bashrc</code> 进行更新才能生效。</p><h2 id="远程访问jupyter"><a href="#远程访问jupyter" class="headerlink" title="远程访问jupyter"></a>远程访问jupyter</h2><p>打开ipython，然后按顺序输入以下代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd()</span><br></pre></td></tr></table></figure><p>然后输入一个登陆jupyter的密码，再输入一次确认。</p><p>输入后，会输出一个跟密钥一样的字符串</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630175648701.png" alt="image-20200630175648701"></p><p>然后退出ipython。到anaconda3的安装目录下的<code>etc/jupyter</code>，执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630175919302.png" alt="image-20200630175919302"></p><p>会输入信息显示配置文件的位置，编辑<code>/root/.jupyter/jupyter_notebook_config.py</code></p><p>最后一行如果是root用户就加上，否则不用加。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip = <span class="string">'*'</span> <span class="comment"># 设置使用此服务器的ip进行访问</span></span><br><span class="line">c.NotebookApp.password = <span class="string">u'sha1:XXXX'</span> <span class="comment"># 输入之前生成的key</span></span><br><span class="line">c.NotebookApp.open_browser = <span class="literal">False</span> <span class="comment"># 关闭启动jupyter时打开浏览器</span></span><br><span class="line">c.NotebookApp.port = XXXX <span class="comment"># 设置使用的端口</span></span><br><span class="line">c.NotebookApp.enable_mathjax = <span class="literal">True</span> <span class="comment"># 启用 MathJax</span></span><br><span class="line">c.NotebookApp.notebook_dir = <span class="string">'你的目录'</span> <span class="comment">#设置共享目录</span></span><br><span class="line">c.NotebookApp.allow_remote_access = <span class="literal">True</span></span><br><span class="line">c.NotebookApp.allow_root = <span class="literal">True</span> <span class="comment"># 允许在root用户下运行</span></span><br></pre></td></tr></table></figure><p>效果图：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630182338967.png" alt="image-20200630182338967"></p><br><p>接下来到服务器商那里放行设置的端口，如果有安装宝塔，宝塔上也要放行。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630182248653.png" alt="image-20200630182248653"></p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630182351764.png" alt="image-20200630182351764"></p><br><p>然后输入<code>jupyter notebook</code>，开启jupyter</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630182143408.png" alt="image-20200630182143408"></p><br><p>其余设备上打开浏览器，输入 <code>IP:port</code> 即可访问，如 <code>192.168.0.123:8888</code></p><p>输入密码即可进入。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630182122207.png" alt="image-20200630182122207"></p><br><p>修改密码方法为输入 <code>jupyter notebook password</code>，然后像设置密码一样输入密码，最后会生成json配置文件。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630183218003.png" alt="image-20200630183218003"></p><p>然后打开生成的json文件，在.py配置文件中使用新生成的key</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200630183536102.png" alt="image-20200630183536102"></p><p>json文件的优先级大于py，所以会覆盖。</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Anaconda3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达深度学习编程作业2-2</title>
      <link href="/post/202006252316/"/>
      <url>/post/202006252316/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>吴恩达深度学习课程《改善深层神经网络：超参数调试、正则化以及优化》第二周（优化算法）的编程作业。</p><a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>题目与参考作业的地址：<a href="https://blog.csdn.net/u013733326/article/details/79907419" target="_blank" rel="noopener">【中文】【吴恩达课后编程作业】Course 2 - 改善深层神经网络 - 第二周作业</a></p><p>相关数据集与前提代码在该博文中下载。</p><p>本次作业的目的是测试在mini-batch梯度下降中：动量梯度下降、Adam梯度下降，与未优化的梯度下降进行对比 。</p><h2 id="导入库函数"><a href="#导入库函数" class="headerlink" title="导入库函数"></a>导入库函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">7.0</span>, <span class="number">4.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scipy.io</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> opt_utils <span class="comment"># 存储常用函数的库</span></span><br><span class="line"><span class="keyword">import</span> testCase  <span class="comment"># 测试用库</span></span><br></pre></td></tr></table></figure><h2 id="未优化的梯度下降函数"><a href="#未优化的梯度下降函数" class="headerlink" title="未优化的梯度下降函数"></a>未优化的梯度下降函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters_with_gd</span><span class="params">(parameters,grads,learning_rate)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    使用梯度下降更新参数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        parameters - 字典，包含了要更新的参数：</span></span><br><span class="line"><span class="string">            parameters['W' + str(l)] = Wl</span></span><br><span class="line"><span class="string">            parameters['b' + str(l)] = bl</span></span><br><span class="line"><span class="string">        grads - 字典，包含了每一个梯度值用以更新参数</span></span><br><span class="line"><span class="string">            grads['dW' + str(l)] = dWl</span></span><br><span class="line"><span class="string">            grads['db' + str(l)] = dbl</span></span><br><span class="line"><span class="string">        learning_rate - 学习率</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    返回值：</span></span><br><span class="line"><span class="string">        parameters - 字典，包含了更新后的参数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    L = len(parameters) // <span class="number">2</span> <span class="comment">#神经网络的层数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#更新每个参数</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        parameters[<span class="string">"W"</span> + str(l +<span class="number">1</span>)] = parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)] - learning_rate * grads[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)]</span><br><span class="line">        parameters[<span class="string">"b"</span> + str(l +<span class="number">1</span>)] = parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)] - learning_rate * grads[<span class="string">"db"</span> + str(l + <span class="number">1</span>)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure></br><p>之前学习的梯度下降算法，即 $w = w - α*dW$ 。</p><h2 id="mini-batch梯度下降函数"><a href="#mini-batch梯度下降函数" class="headerlink" title="mini-batch梯度下降函数"></a>mini-batch梯度下降函数</h2><h3 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h3><p>mini-batch梯度下降是先将所有样本 根据指定的size来划分为若干样本子集。然后对样本子集进行梯度下降。</p><p>步骤为：</p><ol><li>打乱训练集</li><li>分割样本</li><li>处理剩余样本</li></ol><h3 id="打乱训练集"><a href="#打乱训练集" class="headerlink" title="打乱训练集"></a>打乱训练集</h3><p>首先将训练集打乱 ，即采取随机划分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">permutation = list(np.random.permutation(m)) <span class="comment"># 返回一个长度为m的 元素不重复的 随机排序的数组，且里面的数是0到m-1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过切片操作按列排序</span></span><br><span class="line">shuffled_X = X[:,permutation]</span><br><span class="line">shuffled_Y = Y[:,permutation].reshape((<span class="number">1</span>,m))</span><br></pre></td></tr></table></figure><p>假设X为(2,3)的矩阵，Y为(1,3)的矩阵，则m=3，permutation为维度(1,3)的不重复随机数组，可能是<code>1,0,2</code>，可能是<code>2,0,1</code>等等。</p><p>然后<code>X[:,permutation]</code> 会根据permutation对X的列进行重新排序，新的列索引等于permutation对应的元素。</p></br><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200626003316574.png" alt="image-20200626003316574"></p><h3 id="分割样本"><a href="#分割样本" class="headerlink" title="分割样本"></a>分割样本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于存储分割后的样本子集</span></span><br><span class="line">mini_batches = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据划分尺寸mini_batch_size来确定有多少个样本子集</span></span><br><span class="line">num_complete_minibatches = math.floor(m / mini_batch_size) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历样本子集</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,num_complete_minibatches):</span><br><span class="line">    <span class="comment"># 根据mini_batch_size来分割数据集</span></span><br><span class="line">    mini_batch_X = shuffled_X[:,k * mini_batch_size:(k+<span class="number">1</span>)*mini_batch_size]</span><br><span class="line">    mini_batch_Y = shuffled_Y[:,k * mini_batch_size:(k+<span class="number">1</span>)*mini_batch_size]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># mini_batch 存储分割后的数据集</span></span><br><span class="line">    mini_batch = (mini_batch_X,mini_batch_Y)</span><br><span class="line">    <span class="comment"># 加到mini_batches列表中</span></span><br><span class="line">    mini_batches.append(mini_batch)</span><br></pre></td></tr></table></figure><p>使用math.floor函数来对数据进行向下取整，所以 可能会有部分剩余的样本。</p></br><p>在循环中 shuffled_X是随机打乱后的样本，<code>shuffled_X[:,k * mini_batch_size:(k+1)*mini_batch_size]</code> 进行分割。</p><p>假如一共有3个子集，即k=0，1，2。 然后设置mini_batch_size为64。</p><p>当k=0时， <code>mini_batch_X = shuffled_X[:,0*64:1*64]  =  shuffled_X[:,0:64]</code> </p><p>当k=1时， <code>mini_batch_X = shuffled_X[:,1*64:2*64]  =  shuffled_X[:,64:128]</code> </p><p>当k=2时， <code>mini_batch_X = shuffled_X[:,2*64:3*64]  =  shuffled_X[:,128:192]</code></p><p>根据python列表的切片操作来进行分割。 标签Y也同理进行操作。</p><h3 id="处理剩余样本"><a href="#处理剩余样本" class="headerlink" title="处理剩余样本"></a>处理剩余样本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 若样本划分后 有剩余样本</span></span><br><span class="line"><span class="keyword">if</span> m % mini_batch_size != <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># 获取最后剩余的部分</span></span><br><span class="line">    mini_batch_X = shuffled_X[:,mini_batch_size * num_complete_minibatches:]</span><br><span class="line">    mini_batch_Y = shuffled_Y[:,mini_batch_size * num_complete_minibatches:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 存储最后剩余的部分</span></span><br><span class="line">    mini_batch = (mini_batch_X,mini_batch_Y)</span><br><span class="line">    mini_batches.append(mini_batch)</span><br></pre></td></tr></table></figure><p>m%mini_batch_size若不等于0，若明有剩余的样本，则对剩余的样本进行处理。</p><p>根据之前的切片操作，可知<code>num_complete_minibatches * mini_batch_size</code>可以获得剩余部分的第一个位置。</p><br><p>假设有240个样本，即m=240。mini_batch_size = 64，则一共有 floor(240/64) = 3， 所以num_complete_minibatches=3 。</p><p>如图下图一样，进行分割后，可以通过 <code>mini_batch_size * num_complete_minibatches</code>  即 <code>64 * 3 =  192</code> 来获得剩余样本的第一个数据的位置。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200626005623871.png" alt="image-20200626005623871"></p><h3 id="完整函数代码"><a href="#完整函数代码" class="headerlink" title="完整函数代码"></a>完整函数代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_mini_batches</span><span class="params">(X,Y,mini_batch_size=<span class="number">64</span>,seed=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    从（X，Y）中创建一个随机的mini-batch列表</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X - 输入数据，维度为(输入节点数量，样本的数量)</span></span><br><span class="line"><span class="string">        Y - 对应的是X的标签，【1 | 0】（蓝|红），维度为(1,样本的数量)</span></span><br><span class="line"><span class="string">        mini_batch_size - 每个mini-batch的样本数量</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        mini-bacthes - 一个同步列表，维度为（mini_batch_X,mini_batch_Y）</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    np.random.seed(seed) <span class="comment">#指定随机种子</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>] <span class="comment"># 获取样本数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ===== 打乱训练集 ===== #</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 返回一个长度为m的 元素不重复的 随机排序的数组，且里面的数是0到m-1</span></span><br><span class="line">    permutation = list(np.random.permutation(m)) </span><br><span class="line">    <span class="comment"># 通过切片操作按列排序</span></span><br><span class="line">    shuffled_X = X[:,permutation]</span><br><span class="line">    shuffled_Y = Y[:,permutation].reshape((<span class="number">1</span>,m))</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ===== 分割样本 ====== #</span></span><br><span class="line">   </span><br><span class="line">    mini_batches = []  <span class="comment"># 用于存储分割后的样本子集</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 根据划分尺寸mini_batch_size来确定有多少个样本子集</span></span><br><span class="line">    num_complete_minibatches = math.floor(m / mini_batch_size)  </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历样本子集</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,num_complete_minibatches):</span><br><span class="line">        <span class="comment"># 根据mini_batch_size来分割数据集</span></span><br><span class="line">        mini_batch_X = shuffled_X[:,k * mini_batch_size:(k+<span class="number">1</span>)*mini_batch_size]</span><br><span class="line">        mini_batch_Y = shuffled_Y[:,k * mini_batch_size:(k+<span class="number">1</span>)*mini_batch_size]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># mini_batch 存储分割后的数据集</span></span><br><span class="line">        mini_batch = (mini_batch_X,mini_batch_Y)</span><br><span class="line">        <span class="comment"># 加到mini_batches列表中</span></span><br><span class="line">        mini_batches.append(mini_batch)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># ===== 处理剩余样本 ===== #</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 若样本划分后 有剩余样本</span></span><br><span class="line">    <span class="keyword">if</span> m % mini_batch_size != <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 获取最后剩余的部分</span></span><br><span class="line">        mini_batch_X = shuffled_X[:,mini_batch_size * num_complete_minibatches:]</span><br><span class="line">        mini_batch_Y = shuffled_Y[:,mini_batch_size * num_complete_minibatches:]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 存储最后剩余的部分</span></span><br><span class="line">        mini_batch = (mini_batch_X,mini_batch_Y)</span><br><span class="line">        mini_batches.append(mini_batch)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> mini_batches</span><br></pre></td></tr></table></figure><h2 id="动量梯度下降函数"><a href="#动量梯度下降函数" class="headerlink" title="动量梯度下降函数"></a>动量梯度下降函数</h2><h3 id="初始化Vdw与Vdb"><a href="#初始化Vdw与Vdb" class="headerlink" title="初始化Vdw与Vdb"></a>初始化Vdw与Vdb</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_velocity</span><span class="params">(parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    初始化速度，v是一个字典：</span></span><br><span class="line"><span class="string">        - keys: "dW1", "db1", ..., "dWL", "dbL" </span></span><br><span class="line"><span class="string">        - values:与相应的梯度/参数维度相同的值为零的矩阵。</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        parameters - 一个字典，包含了以下参数：</span></span><br><span class="line"><span class="string">            parameters["W" + str(l)] = Wl</span></span><br><span class="line"><span class="string">            parameters["b" + str(l)] = bl</span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">        v - 一个字典变量，包含了以下参数：</span></span><br><span class="line"><span class="string">            v["dW" + str(l)] = dWl的速度</span></span><br><span class="line"><span class="string">            v["db" + str(l)] = dbl的速度</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    L = len(parameters) // <span class="number">2</span> <span class="comment">#神经网络的层数</span></span><br><span class="line">    v = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        v[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] = np.zeros_like(parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)])</span><br><span class="line">        v[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] = np.zeros_like(parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> v</span><br></pre></td></tr></table></figure><p>这里使用np.zeros_like来生成与 传入参数相同shape的 元素均为0的 ndarray。</p><p>因为$V_{dW}$与dW的维度相同，而dW的维度又与W相同，故直接使得与W同维度即可。</p><h3 id="更新参数函数"><a href="#更新参数函数" class="headerlink" title="更新参数函数"></a>更新参数函数</h3><p>动量梯度下降更新参数的公式：</p><p>$ V_{dW} = β * V_{dW} + ( 1 - β) * dW $</p><p>$ V_{db} = β * V_{db} + ( 1 - β) * db $</p><p>$W =  W - α*V_{dW}$</p><p>$b = b - α*V_{db}$</p><p>要做的就是遍历每一层，对每一层都执行该操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters_with_momentun</span><span class="params">(parameters,grads,v,beta,learning_rate)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    使用动量更新参数</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        parameters - 一个字典类型的变量，包含了以下字段：</span></span><br><span class="line"><span class="string">            parameters["W" + str(l)] = Wl</span></span><br><span class="line"><span class="string">            parameters["b" + str(l)] = bl</span></span><br><span class="line"><span class="string">        grads - 一个包含梯度值的字典变量，具有以下字段：</span></span><br><span class="line"><span class="string">            grads["dW" + str(l)] = dWl</span></span><br><span class="line"><span class="string">            grads["db" + str(l)] = dbl</span></span><br><span class="line"><span class="string">        v - 包含当前速度的字典变量，具有以下字段：</span></span><br><span class="line"><span class="string">            v["dW" + str(l)] = ...</span></span><br><span class="line"><span class="string">            v["db" + str(l)] = ...</span></span><br><span class="line"><span class="string">        beta - 超参数，动量，实数</span></span><br><span class="line"><span class="string">        learning_rate - 学习率，实数</span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        parameters - 更新后的参数字典</span></span><br><span class="line"><span class="string">        v - 包含了更新后的速度变量</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取层数</span></span><br><span class="line">    L = len(parameters) // <span class="number">2</span> </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        <span class="comment">#计算速度</span></span><br><span class="line">        v[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] = beta * v[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta) * grads[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)]</span><br><span class="line">        v[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] = beta * v[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta) * grads[<span class="string">"db"</span> + str(l + <span class="number">1</span>)]</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#更新参数</span></span><br><span class="line">        parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)] = parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)] - learning_rate * v[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)]</span><br><span class="line">        parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)] = parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)] - learning_rate * v[<span class="string">"db"</span> + str(l + <span class="number">1</span>)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters,v</span><br></pre></td></tr></table></figure><h2 id="Adam梯度下降函数"><a href="#Adam梯度下降函数" class="headerlink" title="Adam梯度下降函数"></a>Adam梯度下降函数</h2><h3 id="说明-2"><a href="#说明-2" class="headerlink" title="说明"></a>说明</h3><p>Adam是动量梯度下降与RMSprop算法的结合。公式为：</p><br><ol><li><p>初始化：</p><p>​    $V_{dW}、V_{db}、S_{dW}、S_{db} = 0$</p></li><li><p>动量：</p><p>​    $ V_{dW} = β<em>1 * V</em>{dW} + ( 1 - β_1) * dW $</p><p>​    $ V_{db} = β<em>1 * V</em>{db} + ( 1 - β_1) * db $</p></li><li><p>RMSprop：</p><p>​    $ S_{dW} = β<em>2 * S</em>{dW} + ( 1 - β_2) * (dW)^2 $</p><p>​    $ S_{db} = β<em>2 * S</em>{db} + ( 1 - β_2) * (db)^2 $</p></li><li><p>计算偏差修正：</p><p>​    $V^{corrected}<em>{dW} =  \frac{V</em>{dW}}{1 - β_1^t}$</p><p>​    $V^{corrected}<em>{db} =  \frac{V</em>{db}}{1 - β_1^t}$</p><p>​    $S^{corrected}<em>{dW} =  \frac{S</em>{dW}}{1 - β_2^t}$</p><p>​    $S^{corrected}<em>{db} =  \frac{S</em>{db}}{1 - β_2^t}$</p></li><li><p>更新参数：</p><p>​    $W =  W - α * \frac{V^{corrected}<em>{dW}}{ \sqrt{S^{corrected}</em>{dW} + ε}} $</p><p>​    $b =  b - α * \frac{V^{corrected}<em>{db}}{ \sqrt{S^{corrected}</em>{db} + ε}} $</p></li></ol><h3 id="初始化Vdw、Vdb、Sdw、Sdb"><a href="#初始化Vdw、Vdb、Sdw、Sdb" class="headerlink" title="初始化Vdw、Vdb、Sdw、Sdb"></a>初始化Vdw、Vdb、Sdw、Sdb</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_adam</span><span class="params">(parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    初始化v和s，它们都是字典类型的变量，都包含了以下字段：</span></span><br><span class="line"><span class="string">        - keys: "dW1", "db1", ..., "dWL", "dbL" </span></span><br><span class="line"><span class="string">        - values：与对应的梯度/参数相同维度的值为零的numpy矩阵</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        parameters - 包含了以下参数的字典变量：</span></span><br><span class="line"><span class="string">            parameters["W" + str(l)] = Wl</span></span><br><span class="line"><span class="string">            parameters["b" + str(l)] = bl</span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        v - 包含梯度的指数加权平均值，字段如下：</span></span><br><span class="line"><span class="string">            v["dW" + str(l)] = ...</span></span><br><span class="line"><span class="string">            v["db" + str(l)] = ...</span></span><br><span class="line"><span class="string">        s - 包含平方梯度的指数加权平均值，字段如下：</span></span><br><span class="line"><span class="string">            s["dW" + str(l)] = ...</span></span><br><span class="line"><span class="string">            s["db" + str(l)] = ...</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    L = len(parameters) // <span class="number">2</span></span><br><span class="line">    v = &#123;&#125;</span><br><span class="line">    s = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        v[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] = np.zeros_like(parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)])</span><br><span class="line">        v[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] = np.zeros_like(parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)])</span><br><span class="line">        </span><br><span class="line">        s[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] = np.zeros_like(parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)])</span><br><span class="line">        s[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] = np.zeros_like(parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (v,s)</span><br></pre></td></tr></table></figure><p>与动量梯度下降中的初始化类似，区别就是多了个字典s。</p><h3 id="更新参数函数-1"><a href="#更新参数函数-1" class="headerlink" title="更新参数函数"></a>更新参数函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters_with_adam</span><span class="params">(parameters,grads,v,s,t,learning_rate=<span class="number">0.01</span>,beta1=<span class="number">0.9</span>,beta2=<span class="number">0.999</span>,epsilon=<span class="number">1e-8</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    使用Adam更新参数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        parameters - 包含了以下字段的字典：</span></span><br><span class="line"><span class="string">            parameters['W' + str(l)] = Wl</span></span><br><span class="line"><span class="string">            parameters['b' + str(l)] = bl</span></span><br><span class="line"><span class="string">        grads - 包含了梯度值的字典，有以下key值：</span></span><br><span class="line"><span class="string">            grads['dW' + str(l)] = dWl</span></span><br><span class="line"><span class="string">            grads['db' + str(l)] = dbl</span></span><br><span class="line"><span class="string">        v - Adam的变量，第一个梯度的移动平均值，是一个字典类型的变量</span></span><br><span class="line"><span class="string">        s - Adam的变量，平方梯度的移动平均值，是一个字典类型的变量</span></span><br><span class="line"><span class="string">        t - 当前迭代的次数</span></span><br><span class="line"><span class="string">        learning_rate - 学习率</span></span><br><span class="line"><span class="string">        beta1 - 动量，超参数,用于第一阶段，使得曲线的Y值不从0开始（参见天气数据的那个图）</span></span><br><span class="line"><span class="string">        beta2 - RMSprop的一个参数，超参数</span></span><br><span class="line"><span class="string">        epsilon - 防止除零操作（分母为0）</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        parameters - 更新后的参数</span></span><br><span class="line"><span class="string">        v - 第一个梯度的移动平均值，是一个字典类型的变量</span></span><br><span class="line"><span class="string">        s - 平方梯度的移动平均值，是一个字典类型的变量</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    L = len(parameters) // <span class="number">2</span></span><br><span class="line">    v_corrected = &#123;&#125; <span class="comment">#偏差修正后的值</span></span><br><span class="line">    s_corrected = &#123;&#125; <span class="comment">#偏差修正后的值</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</span><br><span class="line">        <span class="comment"># ===== 动量 ===== #</span></span><br><span class="line">        v[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] = beta1 * v[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta1) * grads[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)]</span><br><span class="line">        v[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] = beta1 * v[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta1) * grads[<span class="string">"db"</span> + str(l + <span class="number">1</span>)]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ===== RMSprop ===== #</span></span><br><span class="line">        s[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] = beta2 * s[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta2) * np.square(grads[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)])</span><br><span class="line">        s[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] = beta2 * s[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta2) * np.square(grads[<span class="string">"db"</span> + str(l + <span class="number">1</span>)])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ===== 计算偏差修正 ===== # </span></span><br><span class="line">        v_corrected[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] = v[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] / (<span class="number">1</span> - np.power(beta1,t))</span><br><span class="line">        v_corrected[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] = v[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] / (<span class="number">1</span> - np.power(beta1,t))</span><br><span class="line">        s_corrected[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] = s[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] / (<span class="number">1</span> - np.power(beta2,t))</span><br><span class="line">        s_corrected[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] = s[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] / (<span class="number">1</span> - np.power(beta2,t))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ===== 更新参数 ===== #</span></span><br><span class="line">        parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)] = parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)] - learning_rate * (v_corrected[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] / np.sqrt(s_corrected[<span class="string">"dW"</span> + str(l + <span class="number">1</span>)] + epsilon))</span><br><span class="line">        parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)] = parameters[<span class="string">"b"</span> + str(l + <span class="number">1</span>)] - learning_rate * (v_corrected[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] / np.sqrt(s_corrected[<span class="string">"db"</span> + str(l + <span class="number">1</span>)] + epsilon))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (parameters,v,s)</span><br></pre></td></tr></table></figure><h2 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h2><p>通过opt_utils文件读取数据 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_X, train_Y = opt_utils.load_dataset(is_plot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200626015155694.png" alt="image-20200626015155694"></p><h2 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h2><p>使用之前实现过的一个三层神经网络（然而我并没有用同样的结构，所以直接用该博主的了）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X,Y,layers_dims,optimizer,learning_rate=<span class="number">0.0007</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">          mini_batch_size=<span class="number">64</span>,beta=<span class="number">0.9</span>,beta1=<span class="number">0.9</span>,beta2=<span class="number">0.999</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">          epsilon=<span class="number">1e-8</span>,num_epochs=<span class="number">10000</span>,print_cost=True,is_plot=True)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    可以运行在不同优化器模式下的3层神经网络模型。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X - 输入数据，维度为（2，输入的数据集里面样本数量）</span></span><br><span class="line"><span class="string">        Y - 与X对应的标签</span></span><br><span class="line"><span class="string">        layers_dims - 包含层数和节点数量的列表</span></span><br><span class="line"><span class="string">        optimizer - 字符串类型的参数，用于选择优化类型，【 "gd" | "momentum" | "adam" 】</span></span><br><span class="line"><span class="string">        learning_rate - 学习率</span></span><br><span class="line"><span class="string">        mini_batch_size - 每个小批量数据集的大小</span></span><br><span class="line"><span class="string">        beta - 用于动量优化的一个超参数</span></span><br><span class="line"><span class="string">        beta1 - 用于计算梯度后的指数衰减的估计的超参数</span></span><br><span class="line"><span class="string">        beta1 - 用于计算平方梯度后的指数衰减的估计的超参数</span></span><br><span class="line"><span class="string">        epsilon - 用于在Adam中避免除零操作的超参数，一般不更改</span></span><br><span class="line"><span class="string">        num_epochs - 整个训练集的遍历次数，（视频2.9学习率衰减，1分55秒处，视频中称作“代”）,相当于之前的num_iteration</span></span><br><span class="line"><span class="string">        print_cost - 是否打印误差值，每遍历1000次数据集打印一次，但是每100次记录一个误差值，又称每1000代打印一次</span></span><br><span class="line"><span class="string">        is_plot - 是否绘制出曲线图</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        parameters - 包含了学习后的参数</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    L = len(layers_dims) <span class="comment"># 获取层数</span></span><br><span class="line">    costs = [] <span class="comment"># 用于存储代价</span></span><br><span class="line">    t = <span class="number">0</span> <span class="comment"># 每学习完一个minibatch就增加1</span></span><br><span class="line">    seed = <span class="number">10</span> <span class="comment"># 随机种子</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用opt_utils文件的初始化函数来进行 模型参数的初始化</span></span><br><span class="line">    parameters = opt_utils.initialize_parameters(layers_dims)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 根据传入的参数 optimizer来选择优化器</span></span><br><span class="line">    <span class="keyword">if</span> optimizer == <span class="string">"gd"</span>:</span><br><span class="line">        <span class="keyword">pass</span> <span class="comment">#不使用任何优化器，直接使用梯度下降法</span></span><br><span class="line">    <span class="keyword">elif</span> optimizer == <span class="string">"momentum"</span>:</span><br><span class="line">        v = initialize_velocity(parameters) <span class="comment">#使用动量</span></span><br><span class="line">    <span class="keyword">elif</span> optimizer == <span class="string">"adam"</span>:</span><br><span class="line">        v, s = initialize_adam(parameters)<span class="comment">#使用Adam优化</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"optimizer参数错误，程序退出。"</span>)</span><br><span class="line">        exit(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 开始学习，num_epochs为周期，用于mini-batch，相当于原来的迭代次数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义随机 minibatches,我们在每次遍历数据集之后增加种子以重新排列数据集，使每次数据的顺序都不同</span></span><br><span class="line">        seed = seed + <span class="number">1</span></span><br><span class="line">        <span class="comment"># 初始化mini-batch列表</span></span><br><span class="line">        minibatches = random_mini_batches(X,Y,mini_batch_size,seed)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历 mini-batch列表，即遍历样本子集</span></span><br><span class="line">        <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line">            <span class="comment"># 获取当前minibatch，以minibatch_X代替之前学习的梯度下降法中的X，minibatch_Y代替Y</span></span><br><span class="line">            (minibatch_X,minibatch_Y) = minibatch</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 正向传播</span></span><br><span class="line">            A3 , cache = opt_utils.forward_propagation(minibatch_X,parameters)</span><br><span class="line">            <span class="comment"># 计算代价</span></span><br><span class="line">            cost = opt_utils.compute_cost(A3 , minibatch_Y)</span><br><span class="line">            <span class="comment"># 反向传播</span></span><br><span class="line">            grads = opt_utils.backward_propagation(minibatch_X,minibatch_Y,cache)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 更新参数</span></span><br><span class="line">            <span class="keyword">if</span> optimizer == <span class="string">"gd"</span>:</span><br><span class="line">                parameters = update_parameters_with_gd(parameters,grads,learning_rate)</span><br><span class="line">            <span class="keyword">elif</span> optimizer == <span class="string">"momentum"</span>:</span><br><span class="line">                parameters, v = update_parameters_with_momentun(parameters,grads,v,beta,learning_rate)</span><br><span class="line">            <span class="keyword">elif</span> optimizer == <span class="string">"adam"</span>:</span><br><span class="line">                t = t + <span class="number">1</span> </span><br><span class="line">                parameters , v , s = update_parameters_with_adam(parameters,grads,v,s,t,learning_rate,beta1,beta2,epsilon)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录代价</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            costs.append(cost)</span><br><span class="line">            <span class="comment">#是否打印误差值</span></span><br><span class="line">            <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"第"</span> + str(i) + <span class="string">"次遍历整个数据集，当前误差值："</span> + str(cost))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#是否绘制曲线图</span></span><br><span class="line">    <span class="keyword">if</span> is_plot:</span><br><span class="line">        plt.plot(costs)</span><br><span class="line">        plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'epochs (per 100)'</span>)</span><br><span class="line">        plt.title(<span class="string">"Learning rate = "</span> + str(learning_rate))</span><br><span class="line">        plt.show()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h2 id="进行测试"><a href="#进行测试" class="headerlink" title="进行测试"></a>进行测试</h2><h3 id="未优化的梯度下降"><a href="#未优化的梯度下降" class="headerlink" title="未优化的梯度下降"></a>未优化的梯度下降</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义神经网络结构</span></span><br><span class="line">layers_dims = [train_X.shape[<span class="number">0</span>],<span class="number">5</span>,<span class="number">2</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">parameters = model(train_X, train_Y, layers_dims, optimizer=<span class="string">"gd"</span>,is_plot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#预测</span></span><br><span class="line">preditions = opt_utils.predict(train_X,train_Y,parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制分类图</span></span><br><span class="line">plt.title(<span class="string">"Model with Gradient Descent optimization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>, <span class="number">2.5</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-1</span>, <span class="number">1.5</span>])</span><br><span class="line">opt_utils.plot_decision_boundary(<span class="keyword">lambda</span> x: opt_utils.predict_dec(parameters, x.T), train_X, train_Y)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200626020310914.png" alt="image-20200626020310914"></p><h3 id="动量梯度下降"><a href="#动量梯度下降" class="headerlink" title="动量梯度下降"></a>动量梯度下降</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">layers_dims = [train_X.shape[<span class="number">0</span>],<span class="number">5</span>,<span class="number">2</span>,<span class="number">1</span>]</span><br><span class="line"><span class="comment">#使用动量的梯度下降</span></span><br><span class="line">parameters = model(train_X, train_Y, layers_dims, beta=<span class="number">0.9</span>,optimizer=<span class="string">"momentum"</span>,is_plot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#预测</span></span><br><span class="line">preditions = opt_utils.predict(train_X,train_Y,parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制分类图</span></span><br><span class="line">plt.title(<span class="string">"Model with Momentum optimization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>, <span class="number">2.5</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-1</span>, <span class="number">1.5</span>])</span><br><span class="line">opt_utils.plot_decision_boundary(<span class="keyword">lambda</span> x: opt_utils.predict_dec(parameters, x.T), train_X, np.squeeze(train_Y))</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200626020727881.png" alt="image-20200626020727881"></p><h3 id="Adam算法"><a href="#Adam算法" class="headerlink" title="Adam算法"></a>Adam算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">layers_dims = [train_X.shape[<span class="number">0</span>], <span class="number">5</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line"><span class="comment">#使用Adam优化的梯度下降</span></span><br><span class="line">parameters = model(train_X, train_Y, layers_dims, optimizer=<span class="string">"adam"</span>,is_plot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#预测</span></span><br><span class="line">preditions = opt_utils.predict(train_X,train_Y,parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制分类图</span></span><br><span class="line">plt.title(<span class="string">"Model with Adam optimization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>, <span class="number">2.5</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-1</span>, <span class="number">1.5</span>])</span><br><span class="line">opt_utils.plot_decision_boundary(<span class="keyword">lambda</span> x: opt_utils.predict_dec(parameters, x.T), train_X,np.squeeze(train_Y))</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200626020827605.png" alt="image-20200626020827605"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这里动量梯度下降与未使用优化算法的梯度下降效果差不多，应该是数据集不算大，拉不开差距 。</p><p>明显看到Adam算法的效果要完爆另外两个。</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达深度学习编程作业2-1</title>
      <link href="/post/202006202233/"/>
      <url>/post/202006202233/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>吴恩达深度学习课程《改善深层神经网络：超参数调试、正则化以及优化》第一周（深度学习的实用层面）的编程作业。</p><a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>题目与参考作业的地址：<a href="https://blog.csdn.net/u013733326/article/details/79847918" target="_blank" rel="noopener">【中文】【吴恩达课后编程作业】Course 2 - 改善深层神经网络 - 第一周作业(1&amp;2&amp;3)</a></p><p>相关数据集与前提代码在该博文中下载。</p><p><strong>注：</strong>本文极其没有营养价值，还请看原文。</p><p>本次作业完成内容：</p><ul><li>初始化内容：<ol><li>使用0来初始化参数。</li><li>使用随机数来初始化参数。</li><li>使用抑梯度异常初始化参数（参见视频中的梯度消失和梯度爆炸）。</li></ol></li><li>正则化模型：<ol><li>使用二范数对二分类模型正则化，尝试避免过拟合。</li><li>使用随机删除节点的方法精简模型，同样是为了尝试避免过拟合。</li></ol></li><li>梯度校验：<ol><li>对模型使用梯度校验，检测它是否在梯度下降的过程中出现误差过大的情况。</li></ol></li></ul><h2 id="导入相关库"><a href="#导入相关库" class="headerlink" title="导入相关库"></a>导入相关库</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> init_utils   <span class="comment">#用于初始化</span></span><br><span class="line"><span class="keyword">import</span> reg_utils    <span class="comment">#用于正则化</span></span><br><span class="line"><span class="keyword">import</span> gc_utils     <span class="comment">#用于梯度校验</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">7.0</span>, <span class="number">4.0</span>) <span class="comment"># 设置画布的默认大小</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span><br></pre></td></tr></table></figure><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><h3 id="读取数据并绘图"><a href="#读取数据并绘图" class="headerlink" title="读取数据并绘图"></a>读取数据并绘图</h3><p>init_utils的load_dataset函数中已有绘制图案代码。</p><p>用4个变量接收训练集、测试集的输入特征与标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_X, train_Y, test_X, test_Y = init_utils.load_dataset(is_plot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620162549.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620162549.png" alt="image-20200620162539883"></a></p><h3 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h3><p>建立一个分类器将红蓝点分开，使用之前的模型（因自己之前建立的模型与该作业的不同，故这里直接使用了原文的模型代码）。</p><p>使用三种初始化方法：</p><ul><li><p>0初始化，传参的值为“zeros”，核心代码：</p><p> parameters[‘W’ + str(l)] = np.zeros((layers_dims[l], layers_dims[l - 1]))</p></li><li><p>随机数初始化，传参的值为 “random”，核心代码：<br>  parameters[‘W’ + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * 10</p></li><li><p>抑梯度异常初始化，传参的值为“he”，核心代码：<br>  parameters[‘W’ + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * np.sqrt(2 / layers_dims[l - 1])</p></li></ul><h3 id="查看模型"><a href="#查看模型" class="headerlink" title="查看模型"></a>查看模型</h3><p>代码作用已写在注释，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X,Y,learning_rate=<span class="number">0.01</span>,num_iterations=<span class="number">15000</span>,print_cost=True,initialization=<span class="string">"he"</span>,is_polt=True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    实现一个三层的神经网络：LINEAR -&gt;RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X - 输入的数据，维度为(2, 要训练/测试的数量)</span></span><br><span class="line"><span class="string">        Y - 标签，【0 | 1】，维度为(1，对应的是输入的数据的标签)</span></span><br><span class="line"><span class="string">        learning_rate - 学习速率</span></span><br><span class="line"><span class="string">        num_iterations - 迭代的次数</span></span><br><span class="line"><span class="string">        print_cost - 是否打印成本值，每迭代1000次打印一次</span></span><br><span class="line"><span class="string">        initialization - 字符串类型，初始化的类型【"zeros" | "random" | "he"】</span></span><br><span class="line"><span class="string">        is_polt - 是否绘制梯度下降的曲线图</span></span><br><span class="line"><span class="string">    返回</span></span><br><span class="line"><span class="string">        parameters - 学习后的参数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    grads = &#123;&#125;  <span class="comment"># 存储导数</span></span><br><span class="line">    costs = []  <span class="comment"># 存储代价</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>] <span class="comment"># 获取样本数</span></span><br><span class="line">    layers_dims = [X.shape[<span class="number">0</span>],<span class="number">10</span>,<span class="number">5</span>,<span class="number">1</span>] <span class="comment"># 定义神经网络结构</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 根据传入的参数来进行初始化</span></span><br><span class="line">    <span class="keyword">if</span> initialization == <span class="string">"zeros"</span>:</span><br><span class="line">        parameters = initialize_parameters_zeros(layers_dims) <span class="comment"># 0初始化</span></span><br><span class="line">    <span class="keyword">elif</span> initialization == <span class="string">"random"</span>:</span><br><span class="line">        parameters = initialize_parameters_random(layers_dims) <span class="comment"># 随机初始化</span></span><br><span class="line">    <span class="keyword">elif</span> initialization == <span class="string">"he"</span>:</span><br><span class="line">        parameters = initialize_parameters_he(layers_dims) <span class="comment"># 抑梯度异常初始化</span></span><br><span class="line">    <span class="keyword">else</span> : </span><br><span class="line">        print(<span class="string">"错误的初始化参数！程序退出"</span>)</span><br><span class="line">        exit</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 开始学习</span></span><br><span class="line">    <span class="keyword">for</span> i  <span class="keyword">in</span> range(<span class="number">0</span>,num_iterations):</span><br><span class="line">        <span class="comment">#正向传播</span></span><br><span class="line">        a3 , cache = init_utils.forward_propagation(X,parameters)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算成本  </span></span><br><span class="line">        cost = init_utils.compute_loss(a3,Y)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#反向传播</span></span><br><span class="line">        grads = init_utils.backward_propagation(X,Y,cache)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#更新参数</span></span><br><span class="line">        parameters = init_utils.update_parameters(parameters,grads,learning_rate)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#记录成本</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            costs.append(cost)</span><br><span class="line">            <span class="comment">#打印成本</span></span><br><span class="line">            <span class="keyword">if</span> print_cost:</span><br><span class="line">                print(<span class="string">"第"</span> + str(i) + <span class="string">"次迭代，成本值为："</span> + str(cost))</span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#学习完毕，绘制成本曲线</span></span><br><span class="line">    <span class="keyword">if</span> is_polt:</span><br><span class="line">        plt.plot(costs)</span><br><span class="line">        plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'iterations (per hundreds)'</span>)</span><br><span class="line">        plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">        plt.show()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#返回学习完毕后的参数</span></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h3 id="使用0初始化"><a href="#使用0初始化" class="headerlink" title="使用0初始化"></a>使用0初始化</h3><h4 id="定义函数"><a href="#定义函数" class="headerlink" title="定义函数"></a>定义函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters_zeros</span><span class="params">(layers_dims)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    将模型的参数全部设置为0</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        layers_dims - 列表，模型的层数和对应每一层的节点的数量</span></span><br><span class="line"><span class="string">    返回</span></span><br><span class="line"><span class="string">        parameters - 包含了所有W和b的字典</span></span><br><span class="line"><span class="string">            W1 - 权重矩阵，维度为（layers_dims[1], layers_dims[0]）</span></span><br><span class="line"><span class="string">            b1 - 偏置向量，维度为（layers_dims[1],1）</span></span><br><span class="line"><span class="string">            ···</span></span><br><span class="line"><span class="string">            WL - 权重矩阵，维度为（layers_dims[L], layers_dims[L -1]）</span></span><br><span class="line"><span class="string">            bL - 偏置向量，维度为（layers_dims[L],1）</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    parameters = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    L = len(layers_dims) <span class="comment">#网络层数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>,L):</span><br><span class="line">        parameters[<span class="string">"W"</span> + str(l)] = np.zeros((layers_dims[l],layers_dims[l<span class="number">-1</span>]))</span><br><span class="line">        parameters[<span class="string">"b"</span> + str(l)] = np.zeros((layers_dims[l],<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#使用断言确保我的数据格式是正确的</span></span><br><span class="line">        <span class="keyword">assert</span>(parameters[<span class="string">"W"</span> + str(l)].shape == (layers_dims[l],layers_dims[l<span class="number">-1</span>]))</span><br><span class="line">        <span class="keyword">assert</span>(parameters[<span class="string">"b"</span> + str(l)].shape == (layers_dims[l],<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y, initialization = <span class="string">"zeros"</span>,is_polt=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620163621.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620163621.png" alt="image-20200620163417967"></a></p><p>可以看到代价根本没有降下来，W初始化为0，梯度下降失效，神经网络再多的层数也只是在计算输入特征X的线性组合而已。</p><h4 id="查看准确率"><a href="#查看准确率" class="headerlink" title="查看准确率"></a>查看准确率</h4><p>调用init_utils的predict函数直接进行预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"训练集:"</span>)</span><br><span class="line">predictions_train = init_utils.predict(train_X, train_Y, parameters)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"测试集:"</span>)</span><br><span class="line">predictions_test = init_utils.predict(test_X, test_Y, parameters)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620163619.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620163619.png" alt="image-20200620163617914"></a></p><h4 id="查看细节"><a href="#查看细节" class="headerlink" title="查看细节"></a>查看细节</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"predictions_train = "</span> + str(predictions_train))</span><br><span class="line">print(<span class="string">"predictions_test = "</span> + str(predictions_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制决策边界</span></span><br><span class="line">plt.title(<span class="string">"Model with Zeros initialization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>, <span class="number">1.5</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-1.5</span>, <span class="number">1.5</span>])</span><br><span class="line">init_utils.plot_decision_boundary(<span class="keyword">lambda</span> x: init_utils.predict_dec(parameters, x.T), train_X, np.squeeze(train_Y))</span><br></pre></td></tr></table></figure><p>注意这里最后一句代码，将原本的train_Y 使用np.squeeze(train_Y)换成压缩后的数组，否则绘图会因为维度报错。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620172649.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620172649.png" alt="image-20200620172210916"></a></p><p>预测值全是0，图像整体呈一个颜色，并没有进行分类。</p><h3 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h3><h4 id="定义函数-1"><a href="#定义函数-1" class="headerlink" title="定义函数"></a>定义函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters_random</span><span class="params">(layers_dims)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        layers_dims - 列表，模型的层数和对应每一层的节点的数量</span></span><br><span class="line"><span class="string">    返回</span></span><br><span class="line"><span class="string">        parameters - 包含了所有W和b的字典</span></span><br><span class="line"><span class="string">            W1 - 权重矩阵，维度为（layers_dims[1], layers_dims[0]）</span></span><br><span class="line"><span class="string">            b1 - 偏置向量，维度为（layers_dims[1],1）</span></span><br><span class="line"><span class="string">            ···</span></span><br><span class="line"><span class="string">            WL - 权重矩阵，维度为（layers_dims[L], layers_dims[L -1]）</span></span><br><span class="line"><span class="string">            b1 - 偏置向量，维度为（layers_dims[L],1）</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    np.random.seed(<span class="number">3</span>)               <span class="comment"># 指定随机种子</span></span><br><span class="line">    parameters = &#123;&#125;</span><br><span class="line">    L = len(layers_dims)            <span class="comment"># 层数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span><br><span class="line">        parameters[<span class="string">'W'</span> + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - <span class="number">1</span>]) * <span class="number">10</span> <span class="comment">#使用10倍缩放</span></span><br><span class="line">        parameters[<span class="string">'b'</span> + str(l)] = np.zeros((layers_dims[l], <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#使用断言确保我的数据格式是正确的</span></span><br><span class="line">        <span class="keyword">assert</span>(parameters[<span class="string">"W"</span> + str(l)].shape == (layers_dims[l],layers_dims[l<span class="number">-1</span>]))</span><br><span class="line">        <span class="keyword">assert</span>(parameters[<span class="string">"b"</span> + str(l)].shape == (layers_dims[l],<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h4 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y, initialization = <span class="string">"random"</span>,is_polt=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620172646.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620172646.png" alt="image-20200620172644445"></a></p><p>相比使用0初始化，随机初始化明显使代价函数降了下来。</p><h4 id="查看准确率-1"><a href="#查看准确率-1" class="headerlink" title="查看准确率"></a>查看准确率</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"训练集："</span>)</span><br><span class="line">predictions_train = init_utils.predict(train_X, train_Y, parameters)</span><br><span class="line">print(<span class="string">"测试集："</span>)</span><br><span class="line">predictions_test = init_utils.predict(test_X, test_Y, parameters)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620172742.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620172742.png" alt="image-20200620172741472"></a></p><p>结果正常多了。</p><h4 id="查看细节-1"><a href="#查看细节-1" class="headerlink" title="查看细节"></a>查看细节</h4><p>同使用0初始化一样，最后绘图代码的<code>tarin_Y</code>要使用<code>np.squeeze(train_Y)</code>替换</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"predictions_train = "</span> + str(predictions_train))</span><br><span class="line">print(<span class="string">"predictions_test = "</span> + str(predictions_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制决策边界</span></span><br><span class="line">plt.title(<span class="string">"Model with large random initialization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>, <span class="number">1.5</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-1.5</span>, <span class="number">1.5</span>])</span><br><span class="line">init_utils.plot_decision_boundary(<span class="keyword">lambda</span> x: init_utils.predict_dec(parameters, x.T), train_X, np.squeeze(train_Y))</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620173006.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620173006.png" alt="image-20200620172919162"></a></p><p>成功进行了分类，但是效果不够很好，</p><h3 id="抑梯度异常初始化"><a href="#抑梯度异常初始化" class="headerlink" title="抑梯度异常初始化"></a>抑梯度异常初始化</h3><h4 id="定义函数-2"><a href="#定义函数-2" class="headerlink" title="定义函数"></a>定义函数</h4><p>与随机初始化的区别是，这里用 <code>np.random.randn</code>初始化后乘上<code>np.sqrt(2 / layers_dims[l - 1])</code> （ReLU使用这个效果比较好）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters_he</span><span class="params">(layers_dims)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        layers_dims - 列表，模型的层数和对应每一层的节点的数量</span></span><br><span class="line"><span class="string">    返回</span></span><br><span class="line"><span class="string">        parameters - 包含了所有W和b的字典</span></span><br><span class="line"><span class="string">            W1 - 权重矩阵，维度为（layers_dims[1], layers_dims[0]）</span></span><br><span class="line"><span class="string">            b1 - 偏置向量，维度为（layers_dims[1],1）</span></span><br><span class="line"><span class="string">            ···</span></span><br><span class="line"><span class="string">            WL - 权重矩阵，维度为（layers_dims[L], layers_dims[L -1]）</span></span><br><span class="line"><span class="string">            b1 - 偏置向量，维度为（layers_dims[L],1）</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    np.random.seed(<span class="number">3</span>)               <span class="comment"># 指定随机种子</span></span><br><span class="line">    parameters = &#123;&#125;</span><br><span class="line">    L = len(layers_dims)            <span class="comment"># 层数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span><br><span class="line">        parameters[<span class="string">'W'</span> + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - <span class="number">1</span>]) * np.sqrt(<span class="number">2</span> / layers_dims[l - <span class="number">1</span>])</span><br><span class="line">        parameters[<span class="string">'b'</span> + str(l)] = np.zeros((layers_dims[l], <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#使用断言确保我的数据格式是正确的</span></span><br><span class="line">        <span class="keyword">assert</span>(parameters[<span class="string">"W"</span> + str(l)].shape == (layers_dims[l],layers_dims[l<span class="number">-1</span>]))</span><br><span class="line">        <span class="keyword">assert</span>(parameters[<span class="string">"b"</span> + str(l)].shape == (layers_dims[l],<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h4 id="训练模型-2"><a href="#训练模型-2" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y, initialization = <span class="string">"he"</span>,is_polt=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620204528.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620204528.png" alt="image-20200620204526691"></a></p><p>代价函数下降速度非常明显的变快了，并且代价函数最小值也得到了优化。</p><h4 id="查看准确率-2"><a href="#查看准确率-2" class="headerlink" title="查看准确率"></a>查看准确率</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"训练集:"</span>)</span><br><span class="line">predictions_train = init_utils.predict(train_X, train_Y, parameters)</span><br><span class="line">print(<span class="string">"测试集:"</span>)</span><br><span class="line">init_utils.predictions_test = init_utils.predict(test_X, test_Y, parameters)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620205039.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620205039.png" alt="image-20200620205038238"></a></p><p>准确率也得到了极大提高</p><h4 id="查看细节-2"><a href="#查看细节-2" class="headerlink" title="查看细节"></a>查看细节</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"predictions_train = "</span> + str(predictions_train))</span><br><span class="line">print(<span class="string">"predictions_test = "</span> + str(predictions_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制决策边界</span></span><br><span class="line">plt.title(<span class="string">"Model with He initialization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-1.5</span>, <span class="number">1.5</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-1.5</span>, <span class="number">1.5</span>])</span><br><span class="line">init_utils.plot_decision_boundary(<span class="keyword">lambda</span> x: init_utils.predict_dec(parameters, x.T), train_X, np.squeeze(train_Y))</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620205211.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620205211.png" alt="image-20200620205209229"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>模型参数的初始化方式会导致不同的算法性能。</li><li>使用0初始化会使得梯度下降失效，神经网络在计算输入特征的线性组合。</li><li>使用随机初始化会正确执行梯度下降，但若初始化时的值过大，会导致算法性能过低。</li></ol><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>假设你现在是一个AI专家，你需要设计一个模型，可以用于推荐在足球场中守门员将球发至哪个位置可以让本队的球员抢到球的可能性更大。说白了，实际上就是一个二分类，一半是己方抢到球，一半就是对方抢到球，我们来看一下这个图：</p><p><a href="https://img-blog.csdn.net/20180408145205837?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM3MzMzMjY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" target="_blank" rel="noopener"><img src="https://img-blog.csdn.net/20180408145205837?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM3MzMzMjY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="football position"></a></p><h3 id="读取数据并绘图-1"><a href="#读取数据并绘图-1" class="headerlink" title="读取数据并绘图"></a>读取数据并绘图</h3><p><strong>注：</strong></p><p>这里和前面的绘图一样，需要将<code>train_Y</code>修改为<code>np.squeeze(train_Y)</code>，但读取数据这里就不能在传参的时候修改了，需要打开<code>reg_utils</code>文件找到<code>load_2D_dataset</code>函数，将里面绘图部分的<code>c=train_Y</code> 改为 <code>c=np.squeeze(train_Y)</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_X, train_Y, test_X, test_Y = reg_utils.load_2D_dataset(is_plot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620211638.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620211638.png" alt="image-20200620211637301"></a></p><p>每个点都代表守门员将球发至的位置，蓝点为己方球员抢到球，红点为对手球员抢到球。</p><p>训练模型，找到适合我方球员抢球的位置。</p><h3 id="查看模型-1"><a href="#查看模型-1" class="headerlink" title="查看模型"></a>查看模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X,Y,learning_rate=<span class="number">0.3</span>,num_iterations=<span class="number">30000</span>,print_cost=True,is_plot=True,lambd=<span class="number">0</span>,keep_prob=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    实现一个三层的神经网络：LINEAR -&gt;RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X - 输入的数据，维度为(2, 要训练/测试的数量)</span></span><br><span class="line"><span class="string">        Y - 标签，【0(蓝色) | 1(红色)】，维度为(1，对应的是输入的数据的标签)</span></span><br><span class="line"><span class="string">        learning_rate - 学习速率</span></span><br><span class="line"><span class="string">        num_iterations - 迭代的次数</span></span><br><span class="line"><span class="string">        print_cost - 是否打印成本值，每迭代10000次打印一次，但是每1000次记录一个成本值</span></span><br><span class="line"><span class="string">        is_polt - 是否绘制梯度下降的曲线图</span></span><br><span class="line"><span class="string">        lambd - L2正则化的超参数，即λ的值，实数。默认值为0表示不使用L2正则化。</span></span><br><span class="line"><span class="string">        keep_prob - 随机删除节点的概率，默认为1表示不使用随机失活</span></span><br><span class="line"><span class="string">    返回</span></span><br><span class="line"><span class="string">        parameters - 学习后的参数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    grads = &#123;&#125;</span><br><span class="line">    costs = []</span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    layers_dims = [X.shape[<span class="number">0</span>],<span class="number">20</span>,<span class="number">3</span>,<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#初始化参数</span></span><br><span class="line">    parameters = reg_utils.initialize_parameters(layers_dims)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#开始学习</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,num_iterations):</span><br><span class="line">        <span class="comment">#前向传播</span></span><br><span class="line">        <span class="comment">##是否随机删除节点</span></span><br><span class="line">        <span class="keyword">if</span> keep_prob == <span class="number">1</span>:</span><br><span class="line">            <span class="comment">###不随机删除节点</span></span><br><span class="line">            a3 , cache = reg_utils.forward_propagation(X,parameters)</span><br><span class="line">        <span class="keyword">elif</span> keep_prob &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="comment">###随机删除节点</span></span><br><span class="line">            a3 , cache = forward_propagation_with_dropout(X,parameters,keep_prob)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"keep_prob参数错误！程序退出。"</span>)</span><br><span class="line">            exit</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#计算成本</span></span><br><span class="line">        <span class="comment">## 是否使用二范数</span></span><br><span class="line">        <span class="keyword">if</span> lambd == <span class="number">0</span>:</span><br><span class="line">            <span class="comment">###不使用L2正则化</span></span><br><span class="line">            cost = reg_utils.compute_cost(a3,Y)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">###使用L2正则化</span></span><br><span class="line">            cost = compute_cost_with_regularization(a3,Y,parameters,lambd)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#反向传播</span></span><br><span class="line">        <span class="comment">##可以同时使用L2正则化和随机删除节点，但是本次实验不同时使用。</span></span><br><span class="line">        <span class="keyword">assert</span>(lambd == <span class="number">0</span>  <span class="keyword">or</span> keep_prob ==<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">##两个参数的使用情况</span></span><br><span class="line">        <span class="keyword">if</span> (lambd == <span class="number">0</span> <span class="keyword">and</span> keep_prob == <span class="number">1</span>):</span><br><span class="line">            <span class="comment">### 不使用L2正则化和不使用随机删除节点</span></span><br><span class="line">            grads = reg_utils.backward_propagation(X,Y,cache)</span><br><span class="line">        <span class="keyword">elif</span> lambd != <span class="number">0</span>:</span><br><span class="line">            <span class="comment">### 使用L2正则化，不使用随机删除节点</span></span><br><span class="line">            grads = backward_propagation_with_regularization(X, Y, cache, lambd)</span><br><span class="line">        <span class="keyword">elif</span> keep_prob &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="comment">### 使用随机删除节点，不使用L2正则化</span></span><br><span class="line">            grads = backward_propagation_with_dropout(X, Y, cache, keep_prob)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#更新参数</span></span><br><span class="line">        parameters = reg_utils.update_parameters(parameters, grads, learning_rate)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#记录并打印成本</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment">## 记录成本</span></span><br><span class="line">            costs.append(cost)</span><br><span class="line">            <span class="keyword">if</span> (print_cost <span class="keyword">and</span> i % <span class="number">10000</span> == <span class="number">0</span>):</span><br><span class="line">                <span class="comment">#打印成本</span></span><br><span class="line">                print(<span class="string">"第"</span> + str(i) + <span class="string">"次迭代，成本值为："</span> + str(cost))</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#是否绘制成本曲线图</span></span><br><span class="line">    <span class="keyword">if</span> is_plot:</span><br><span class="line">        plt.plot(costs)</span><br><span class="line">        plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'iterations (x1,000)'</span>)</span><br><span class="line">        plt.title(<span class="string">"Learning rate ="</span> + str(learning_rate))</span><br><span class="line">        plt.show()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#返回学习后的参数</span></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h3 id="不使用正则化"><a href="#不使用正则化" class="headerlink" title="不使用正则化"></a>不使用正则化</h3><h4 id="训练模型-3"><a href="#训练模型-3" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y,is_plot=<span class="literal">True</span>)</span><br><span class="line">print(<span class="string">"训练集:"</span>)</span><br><span class="line">predictions_train = reg_utils.predict(train_X, train_Y, parameters)</span><br><span class="line">print(<span class="string">"测试集:"</span>)</span><br><span class="line">predictions_test = reg_utils.predict(test_X, test_Y, parameters)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620220431.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620220431.png" alt="image-20200620220421003"></a></p><h4 id="绘制决策边界"><a href="#绘制决策边界" class="headerlink" title="绘制决策边界"></a>绘制决策边界</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Model without regularization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-0.75</span>,<span class="number">0.40</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-0.75</span>,<span class="number">0.65</span>])</span><br><span class="line">reg_utils.plot_decision_boundary(<span class="keyword">lambda</span> x: reg_utils.predict_dec(parameters, x.T), train_X, np.squeeze(train_Y))</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620220704.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620220704.png" alt="image-20200620220651552"></a></p><p>通过无正则化的决策边界，可以看出过拟合现象</p><h3 id="使用L2正则化"><a href="#使用L2正则化" class="headerlink" title="使用L2正则化"></a>使用L2正则化</h3><h4 id="定义L2函数"><a href="#定义L2函数" class="headerlink" title="定义L2函数"></a>定义L2函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算正则化代价</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost_with_regularization</span><span class="params">(A3,Y,parameters,lambd)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    实现公式2的L2正则化计算成本</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        A3 - 正向传播的输出结果，维度为（输出节点数量，训练/测试的数量）</span></span><br><span class="line"><span class="string">        Y - 标签向量，与数据一一对应，维度为(输出节点数量，训练/测试的数量)</span></span><br><span class="line"><span class="string">        parameters - 包含模型学习后的参数的字典</span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        cost - 使用公式2计算出来的正则化损失的值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    m = Y.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 获取各层的模型参数W</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    W3 = parameters[<span class="string">"W3"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算代价</span></span><br><span class="line">    cross_entropy_cost = reg_utils.compute_cost(A3,Y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算L2正则化的代价</span></span><br><span class="line">    L2_regularization_cost = lambd * (np.sum(np.square(W1)) + np.sum(np.square(W2))  + np.sum(np.square(W3))) / (<span class="number">2</span> * m)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算总代价</span></span><br><span class="line">    cost = cross_entropy_cost + L2_regularization_cost</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#因为改变了成本函数，所以必须改变向后传播的函数， 所有的梯度都必须根据这个新的成本值来计算。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation_with_regularization</span><span class="params">(X, Y, cache, lambd)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    实现我们添加了L2正则化的模型的后向传播。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X - 输入数据集，维度为（输入节点数量，数据集里面的数量）</span></span><br><span class="line"><span class="string">        Y - 标签，维度为（输出节点数量，数据集里面的数量）</span></span><br><span class="line"><span class="string">        cache - 来自forward_propagation（）的cache输出</span></span><br><span class="line"><span class="string">        lambda - regularization超参数，实数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        gradients - 一个包含了每个参数、激活值和预激活值变量的梯度的字典</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    m = X.shape[<span class="number">1</span>] <span class="comment"># 获取样本数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取cache的值</span></span><br><span class="line">    (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache</span><br><span class="line">    </span><br><span class="line">    dZ3 = A3 - Y</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 正则化的反向传播</span></span><br><span class="line">    dW3 = (<span class="number">1</span> / m) * np.dot(dZ3,A2.T) + ((lambd * W3) / m )</span><br><span class="line">    db3 = (<span class="number">1</span> / m) * np.sum(dZ3,axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    dA2 = np.dot(W3.T,dZ3)</span><br><span class="line">    dZ2 = np.multiply(dA2,np.int64(A2 &gt; <span class="number">0</span>))</span><br><span class="line">    dW2 = (<span class="number">1</span> / m) * np.dot(dZ2,A1.T) + ((lambd * W2) / m)</span><br><span class="line">    db2 = (<span class="number">1</span> / m) * np.sum(dZ2,axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    dA1 = np.dot(W2.T,dZ2)</span><br><span class="line">    dZ1 = np.multiply(dA1,np.int64(A1 &gt; <span class="number">0</span>))</span><br><span class="line">    dW1 = (<span class="number">1</span> / m) * np.dot(dZ1,X.T) + ((lambd * W1) / m)</span><br><span class="line">    db1 = (<span class="number">1</span> / m) * np.sum(dZ1,axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    gradients = &#123;<span class="string">"dZ3"</span>: dZ3, <span class="string">"dW3"</span>: dW3, <span class="string">"db3"</span>: db3, <span class="string">"dA2"</span>: dA2,</span><br><span class="line">                 <span class="string">"dZ2"</span>: dZ2, <span class="string">"dW2"</span>: dW2, <span class="string">"db2"</span>: db2, <span class="string">"dA1"</span>: dA1, </span><br><span class="line">                 <span class="string">"dZ1"</span>: dZ1, <span class="string">"dW1"</span>: dW1, <span class="string">"db1"</span>: db1&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure><h4 id="训练模型-4"><a href="#训练模型-4" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y, lambd=<span class="number">0.7</span>,is_plot=<span class="literal">True</span>)</span><br><span class="line">print(<span class="string">"使用正则化，训练集:"</span>)</span><br><span class="line">predictions_train = reg_utils.predict(train_X, train_Y, parameters)</span><br><span class="line">print(<span class="string">"使用正则化，测试集:"</span>)</span><br><span class="line">predictions_test = reg_utils.predict(test_X, test_Y, parameters)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620223913.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620223913.png" alt="image-20200620223911772"></a></p><p>训练集准确率稍微降低了点，测试集提高了点，两者几乎持平。</p><h4 id="绘制决策边界-1"><a href="#绘制决策边界-1" class="headerlink" title="绘制决策边界"></a>绘制决策边界</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Model with L2-regularization"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-0.75</span>,<span class="number">0.40</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-0.75</span>,<span class="number">0.65</span>])</span><br><span class="line">reg_utils.plot_decision_boundary(<span class="keyword">lambda</span> x: reg_utils.predict_dec(parameters, x.T), train_X, np.squeeze(train_Y))</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620224100.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620224100.png" alt="image-20200620224058965"></a></p><p>根据决策边界可以看出改善了过拟合现象。</p><p>实际上L2正则化的效果会根据超参数λ的的值而改变。</p><p>L2正则化依赖于较小权重的模型比具有较大权重的模型更简单这样的假设，因此，通过削减成本函数中权重的平方值，可以将所有权重值逐渐改变到到较小的值。权值数值高的话会有更平滑的模型，其中输入变化时输出变化更慢，但是需要花费更多的时间。</p><h3 id="使用随机失活"><a href="#使用随机失活" class="headerlink" title="使用随机失活"></a>使用随机失活</h3><h4 id="定义dropout正向传播函数"><a href="#定义dropout正向传播函数" class="headerlink" title="定义dropout正向传播函数"></a>定义dropout正向传播函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation_with_dropout</span><span class="params">(X,parameters,keep_prob=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    实现具有随机舍弃节点的前向传播。</span></span><br><span class="line"><span class="string">    LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; SIGMOID.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X  - 输入数据集，维度为（2，示例数）</span></span><br><span class="line"><span class="string">        parameters - 包含参数“W1”，“b1”，“W2”，“b2”，“W3”，“b3”的python字典：</span></span><br><span class="line"><span class="string">            W1  - 权重矩阵，维度为（20,2）</span></span><br><span class="line"><span class="string">            b1  - 偏向量，维度为（20,1）</span></span><br><span class="line"><span class="string">            W2  - 权重矩阵，维度为（3,20）</span></span><br><span class="line"><span class="string">            b2  - 偏向量，维度为（3,1）</span></span><br><span class="line"><span class="string">            W3  - 权重矩阵，维度为（1,3）</span></span><br><span class="line"><span class="string">            b3  - 偏向量，维度为（1,1）</span></span><br><span class="line"><span class="string">        keep_prob  - 随机删除的概率，实数</span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        A3  - 最后的激活值，维度为（1,1），正向传播的输出</span></span><br><span class="line"><span class="string">        cache - 存储了一些用于计算反向传播的数值的元组</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">    W3 = parameters[<span class="string">"W3"</span>]</span><br><span class="line">    b3 = parameters[<span class="string">"b3"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</span></span><br><span class="line">    Z1 = np.dot(W1,X) + b1</span><br><span class="line">    A1 = reg_utils.relu(Z1)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#下面的步骤1-4对应于上述的步骤1-4。</span></span><br><span class="line">    D1 = np.random.rand(A1.shape[<span class="number">0</span>],A1.shape[<span class="number">1</span>])    <span class="comment">#步骤1：初始化矩阵D1 = np.random.rand(..., ...)</span></span><br><span class="line">    D1 = D1 &lt; keep_prob                             <span class="comment">#步骤2：将D1的值转换为0或1（使用keep_prob作为阈值）</span></span><br><span class="line">    A1 = A1 * D1                                    <span class="comment">#步骤3：舍弃A1的一些节点（将它的值变为0或False）</span></span><br><span class="line">    A1 = A1 / keep_prob                             <span class="comment">#步骤4：缩放未舍弃的节点(不为0)的值</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    #不理解的同学运行一下下面代码就知道了。</span></span><br><span class="line"><span class="string">    import numpy as np</span></span><br><span class="line"><span class="string">    np.random.seed(1)</span></span><br><span class="line"><span class="string">    A1 = np.random.randn(1,3)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    D1 = np.random.rand(A1.shape[0],A1.shape[1])</span></span><br><span class="line"><span class="string">    keep_prob=0.5</span></span><br><span class="line"><span class="string">    D1 = D1 &lt; keep_prob</span></span><br><span class="line"><span class="string">    print(D1)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    A1 = 0.01</span></span><br><span class="line"><span class="string">    A1 = A1 * D1</span></span><br><span class="line"><span class="string">    A1 = A1 / keep_prob</span></span><br><span class="line"><span class="string">    print(A1)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    Z2 = np.dot(W2,A1) + b2</span><br><span class="line">    A2 = reg_utils.relu(Z2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#下面的步骤1-4对应于上述的步骤1-4。</span></span><br><span class="line">    D2 = np.random.rand(A2.shape[<span class="number">0</span>],A2.shape[<span class="number">1</span>])    <span class="comment">#步骤1：初始化矩阵D2 = np.random.rand(..., ...)</span></span><br><span class="line">    D2 = D2 &lt; keep_prob                             <span class="comment">#步骤2：将D2的值转换为0或1（使用keep_prob作为阈值）</span></span><br><span class="line">    A2 = A2 * D2                                    <span class="comment">#步骤3：舍弃A1的一些节点（将它的值变为0或False）</span></span><br><span class="line">    A2 = A2 / keep_prob                             <span class="comment">#步骤4：缩放未舍弃的节点(不为0)的值</span></span><br><span class="line">    </span><br><span class="line">    Z3 = np.dot(W3, A2) + b3</span><br><span class="line">    A3 = reg_utils.sigmoid(Z3)</span><br><span class="line">    </span><br><span class="line">    cache = (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> A3, cache</span><br></pre></td></tr></table></figure><h4 id="定义dropout反向传播函数"><a href="#定义dropout反向传播函数" class="headerlink" title="定义dropout反向传播函数"></a>定义dropout反向传播函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation_with_dropout</span><span class="params">(X,Y,cache,keep_prob)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    实现我们随机删除的模型的后向传播。</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X  - 输入数据集，维度为（2，示例数）</span></span><br><span class="line"><span class="string">        Y  - 标签，维度为（输出节点数量，示例数量）</span></span><br><span class="line"><span class="string">        cache - 来自forward_propagation_with_dropout（）的cache输出</span></span><br><span class="line"><span class="string">        keep_prob  - 随机删除的概率，实数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        gradients - 一个关于每个参数、激活值和预激活变量的梯度值的字典</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) = cache</span><br><span class="line">    </span><br><span class="line">    dZ3 = A3 - Y</span><br><span class="line">    dW3 = (<span class="number">1</span> / m) * np.dot(dZ3,A2.T)</span><br><span class="line">    db3 = <span class="number">1.</span> / m * np.sum(dZ3, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    dA2 = np.dot(W3.T, dZ3)</span><br><span class="line">    </span><br><span class="line">    dA2 = dA2 * D2          <span class="comment"># 步骤1：使用正向传播期间相同的节点，舍弃那些关闭的节点（因为任何数乘以0或者False都为0或者False）</span></span><br><span class="line">    dA2 = dA2 / keep_prob   <span class="comment"># 步骤2：缩放未舍弃的节点(不为0)的值</span></span><br><span class="line">    </span><br><span class="line">    dZ2 = np.multiply(dA2, np.int64(A2 &gt; <span class="number">0</span>))</span><br><span class="line">    dW2 = <span class="number">1.</span> / m * np.dot(dZ2, A1.T)</span><br><span class="line">    db2 = <span class="number">1.</span> / m * np.sum(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    dA1 = np.dot(W2.T, dZ2)</span><br><span class="line">    </span><br><span class="line">    dA1 = dA1 * D1          <span class="comment"># 步骤1：使用正向传播期间相同的节点，舍弃那些关闭的节点（因为任何数乘以0或者False都为0或者False）</span></span><br><span class="line">    dA1 = dA1 / keep_prob   <span class="comment"># 步骤2：缩放未舍弃的节点(不为0)的值</span></span><br><span class="line"></span><br><span class="line">    dZ1 = np.multiply(dA1, np.int64(A1 &gt; <span class="number">0</span>))</span><br><span class="line">    dW1 = <span class="number">1.</span> / m * np.dot(dZ1, X.T)</span><br><span class="line">    db1 = <span class="number">1.</span> / m * np.sum(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    gradients = &#123;<span class="string">"dZ3"</span>: dZ3, <span class="string">"dW3"</span>: dW3, <span class="string">"db3"</span>: db3,<span class="string">"dA2"</span>: dA2,</span><br><span class="line">                 <span class="string">"dZ2"</span>: dZ2, <span class="string">"dW2"</span>: dW2, <span class="string">"db2"</span>: db2, <span class="string">"dA1"</span>: dA1, </span><br><span class="line">                 <span class="string">"dZ1"</span>: dZ1, <span class="string">"dW1"</span>: dW1, <span class="string">"db1"</span>: db1&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure><h4 id="训练模型-5"><a href="#训练模型-5" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">parameters = model(train_X, train_Y, keep_prob=<span class="number">0.86</span>, learning_rate=<span class="number">0.3</span>,is_plot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"使用随机删除节点，训练集:"</span>)</span><br><span class="line">predictions_train = reg_utils.predict(train_X, train_Y, parameters)</span><br><span class="line">print(<span class="string">"使用随机删除节点，测试集:"</span>)</span><br><span class="line">reg_utils.predictions_test = reg_utils.predict(test_X, test_Y, parameters)</span><br></pre></td></tr></table></figure><p>这里使用keep_prob=0.86，表示对于每个神经单元，每次迭代有86%的概率保留，24%的概率消除。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620225102.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620225102.png" alt="image-20200620225101790"></a></p><p>代价更小，训练集的准确率下降一点，测试集的准确率得到提高。</p><h4 id="绘制决策边界-2"><a href="#绘制决策边界-2" class="headerlink" title="绘制决策边界"></a>绘制决策边界</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Model with dropout"</span>)</span><br><span class="line">axes = plt.gca()</span><br><span class="line">axes.set_xlim([<span class="number">-0.75</span>, <span class="number">0.40</span>])</span><br><span class="line">axes.set_ylim([<span class="number">-0.75</span>, <span class="number">0.65</span>])</span><br><span class="line">reg_utils.plot_decision_boundary(<span class="keyword">lambda</span> x: reg_utils.predict_dec(parameters, x.T), train_X, np.squeeze(train_Y))</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620225236.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200620225236.png" alt="image-20200620225234004"></a></p><p>相比使用L2正则化，随机失活的决策边界更加平滑。</p><h2 id="梯度校验"><a href="#梯度校验" class="headerlink" title="梯度校验"></a>梯度校验</h2><h3 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h3><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621020141.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621020141.png" alt="image-20200621020139237"></a></p><h3 id="一维线性"><a href="#一维线性" class="headerlink" title="一维线性"></a>一维线性</h3><h4 id="定义正向传播函数"><a href="#定义正向传播函数" class="headerlink" title="定义正向传播函数"></a>定义正向传播函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">(x,theta)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    实现图中呈现的线性前向传播（计算J）（J（theta）= theta * x）</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">    x  - 一个实值输入</span></span><br><span class="line"><span class="string">    theta  - 参数，也是一个实数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">    J  - 函数J的值，用公式J（theta）= theta * x计算</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    J = np.dot(theta,x)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> J</span><br></pre></td></tr></table></figure><h4 id="定义反向传播函数"><a href="#定义反向传播函数" class="headerlink" title="定义反向传播函数"></a>定义反向传播函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation</span><span class="params">(x,theta)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    计算J相对于θ的导数。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        x  - 一个实值输入</span></span><br><span class="line"><span class="string">        theta  - 参数，也是一个实数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        dtheta  - 相对于θ的成本梯度</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dtheta = x</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dtheta</span><br></pre></td></tr></table></figure><h4 id="定义校验函数"><a href="#定义校验函数" class="headerlink" title="定义校验函数"></a>定义校验函数</h4><p>梯度检测的过程为：</p><ol><li><p>$θ^+ = θ + ε$</p></li><li><p>$ θ^− = θ − ε $</p></li><li><p>$J^+ = J(θ^+) $</p></li><li><p>$J^- = J(θ^-) $</p></li><li><p>$gradapprox = \frac{J^+ − J^−}{2∗ε}$</p></li></ol><p>然后计算反向传播的值grad，然后计算误差</p><p>$ difference = \frac{||grad−gradapprox||_2}{||grad||_2 + ||gradapprox||_2}$</p><p>若 $ difference &lt; 10^−7 $，则grad是正确的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_check</span><span class="params">(x,theta,epsilon=<span class="number">1e-7</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    实现图中的反向传播。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        x  - 一个实值输入</span></span><br><span class="line"><span class="string">        theta  - 参数，也是一个实数</span></span><br><span class="line"><span class="string">        epsilon  - 使用公式（3）计算输入的微小偏移以计算近似梯度</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        近似梯度和后向传播梯度之间的差异</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#使用公式（3）的左侧计算gradapprox。</span></span><br><span class="line">    thetaplus = theta + epsilon                               <span class="comment"># Step 1</span></span><br><span class="line">    thetaminus = theta - epsilon                              <span class="comment"># Step 2</span></span><br><span class="line">    J_plus = forward_propagation(x, thetaplus)                <span class="comment"># Step 3</span></span><br><span class="line">    J_minus = forward_propagation(x, thetaminus)              <span class="comment"># Step 4</span></span><br><span class="line">    gradapprox = (J_plus - J_minus) / (<span class="number">2</span> * epsilon)           <span class="comment"># Step 5</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#检查gradapprox是否足够接近backward_propagation（）的输出</span></span><br><span class="line">    grad = backward_propagation(x, theta)</span><br><span class="line">    </span><br><span class="line">    numerator = np.linalg.norm(grad - gradapprox)                      <span class="comment"># Step 1'</span></span><br><span class="line">    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)    <span class="comment"># Step 2'</span></span><br><span class="line">    difference = numerator / denominator                               <span class="comment"># Step 3'</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> difference &lt; <span class="number">1e-7</span>:</span><br><span class="line">        print(<span class="string">"梯度检查：梯度正常!"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"梯度检查：梯度超出阈值!"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> difference</span><br></pre></td></tr></table></figure><h4 id="进行测试"><a href="#进行测试" class="headerlink" title="进行测试"></a>进行测试</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#测试gradient_check</span></span><br><span class="line">print(<span class="string">"-----------------测试gradient_check-----------------"</span>)</span><br><span class="line">x, theta = <span class="number">2</span>, <span class="number">4</span></span><br><span class="line">difference = gradient_check(x, theta)</span><br><span class="line">print(<span class="string">"difference = "</span> + str(difference))</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621022048.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621022048.png" alt="image-20200621022045374"></a></p><h3 id="高维度梯度校验"><a href="#高维度梯度校验" class="headerlink" title="高维度梯度校验"></a>高维度梯度校验</h3><h4 id="定义正向传播函数-1"><a href="#定义正向传播函数-1" class="headerlink" title="定义正向传播函数"></a>定义正向传播函数</h4><p>高维度梯度校验与一维类似，区别在于不只是校验一个导数，而是对每一层都进行校验。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation_n</span><span class="params">(X,Y,parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    实现图中的前向传播（并计算成本）。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X - 训练集为m个例子</span></span><br><span class="line"><span class="string">        Y -  m个示例的标签</span></span><br><span class="line"><span class="string">        parameters - 包含参数“W1”，“b1”，“W2”，“b2”，“W3”，“b3”的python字典：</span></span><br><span class="line"><span class="string">            W1  - 权重矩阵，维度为（5,4）</span></span><br><span class="line"><span class="string">            b1  - 偏向量，维度为（5,1）</span></span><br><span class="line"><span class="string">            W2  - 权重矩阵，维度为（3,5）</span></span><br><span class="line"><span class="string">            b2  - 偏向量，维度为（3,1）</span></span><br><span class="line"><span class="string">            W3  - 权重矩阵，维度为（1,3）</span></span><br><span class="line"><span class="string">            b3  - 偏向量，维度为（1,1）</span></span><br><span class="line"><span class="string">   </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        cost - 成本函数（logistic）</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">    W3 = parameters[<span class="string">"W3"</span>]</span><br><span class="line">    b3 = parameters[<span class="string">"b3"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</span></span><br><span class="line">    Z1 = np.dot(W1,X) + b1</span><br><span class="line">    A1 = gc_utils.relu(Z1)</span><br><span class="line">    </span><br><span class="line">    Z2 = np.dot(W2,A1) + b2</span><br><span class="line">    A2 = gc_utils.relu(Z2)</span><br><span class="line">    </span><br><span class="line">    Z3 = np.dot(W3,A2) + b3</span><br><span class="line">    A3 = gc_utils.sigmoid(Z3)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#计算成本</span></span><br><span class="line">    logprobs = np.multiply(-np.log(A3), Y) + np.multiply(-np.log(<span class="number">1</span> - A3), <span class="number">1</span> - Y)</span><br><span class="line">    cost = (<span class="number">1</span> / m) * np.sum(logprobs)</span><br><span class="line">    </span><br><span class="line">    cache = (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cost, cache</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation_n</span><span class="params">(X,Y,cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    实现图中所示的反向传播。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X - 输入数据点（输入节点数量，1）</span></span><br><span class="line"><span class="string">        Y - 标签</span></span><br><span class="line"><span class="string">        cache - 来自forward_propagation_n（）的cache输出</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        gradients - 一个字典，其中包含与每个参数、激活和激活前变量相关的成本梯度。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache</span><br><span class="line">    </span><br><span class="line">    dZ3 = A3 - Y</span><br><span class="line">    dW3 = (<span class="number">1.</span> / m) * np.dot(dZ3,A2.T)</span><br><span class="line">    dW3 = <span class="number">1.</span> / m * np.dot(dZ3, A2.T)</span><br><span class="line">    db3 = <span class="number">1.</span> / m * np.sum(dZ3, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    dA2 = np.dot(W3.T, dZ3)</span><br><span class="line">    dZ2 = np.multiply(dA2, np.int64(A2 &gt; <span class="number">0</span>))</span><br><span class="line">    <span class="comment">#dW2 = 1. / m * np.dot(dZ2, A1.T) * 2  # Should not multiply by 2</span></span><br><span class="line">    dW2 = <span class="number">1.</span> / m * np.dot(dZ2, A1.T)</span><br><span class="line">    db2 = <span class="number">1.</span> / m * np.sum(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    dA1 = np.dot(W2.T, dZ2)</span><br><span class="line">    dZ1 = np.multiply(dA1, np.int64(A1 &gt; <span class="number">0</span>))</span><br><span class="line">    dW1 = <span class="number">1.</span> / m * np.dot(dZ1, X.T)</span><br><span class="line">    <span class="comment">#db1 = 4. / m * np.sum(dZ1, axis=1, keepdims=True) # Should not multiply by 4</span></span><br><span class="line">    db1 = <span class="number">1.</span> / m * np.sum(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    gradients = &#123;<span class="string">"dZ3"</span>: dZ3, <span class="string">"dW3"</span>: dW3, <span class="string">"db3"</span>: db3,</span><br><span class="line">                 <span class="string">"dA2"</span>: dA2, <span class="string">"dZ2"</span>: dZ2, <span class="string">"dW2"</span>: dW2, <span class="string">"db2"</span>: db2,</span><br><span class="line">                 <span class="string">"dA1"</span>: dA1, <span class="string">"dZ1"</span>: dZ1, <span class="string">"dW1"</span>: dW1, <span class="string">"db1"</span>: db1&#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> gradients</span><br></pre></td></tr></table></figure><h4 id="定义校验函数-1"><a href="#定义校验函数-1" class="headerlink" title="定义校验函数"></a>定义校验函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_check_n</span><span class="params">(parameters,gradients,X,Y,epsilon=<span class="number">1e-7</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    检查backward_propagation_n是否正确计算forward_propagation_n输出的成本梯度</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        parameters - 包含参数“W1”，“b1”，“W2”，“b2”，“W3”，“b3”的python字典：</span></span><br><span class="line"><span class="string">        grad_output_propagation_n的输出包含与参数相关的成本梯度。</span></span><br><span class="line"><span class="string">        x  - 输入数据点，维度为（输入节点数量，1）</span></span><br><span class="line"><span class="string">        y  - 标签</span></span><br><span class="line"><span class="string">        epsilon  - 计算输入的微小偏移以计算近似梯度</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        difference - 近似梯度和后向传播梯度之间的差异</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">#初始化参数</span></span><br><span class="line">    parameters_values , keys = gc_utils.dictionary_to_vector(parameters) <span class="comment">#keys用不到</span></span><br><span class="line">    grad = gc_utils.gradients_to_vector(gradients)</span><br><span class="line">    num_parameters = parameters_values.shape[<span class="number">0</span>]</span><br><span class="line">    J_plus = np.zeros((num_parameters,<span class="number">1</span>))</span><br><span class="line">    J_minus = np.zeros((num_parameters,<span class="number">1</span>))</span><br><span class="line">    gradapprox = np.zeros((num_parameters,<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#计算gradapprox</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_parameters):</span><br><span class="line">        <span class="comment">#计算J_plus [i]。输入：“parameters_values，epsilon”。输出=“J_plus [i]”</span></span><br><span class="line">        thetaplus = np.copy(parameters_values)                                                  <span class="comment"># Step 1</span></span><br><span class="line">        thetaplus[i][<span class="number">0</span>] = thetaplus[i][<span class="number">0</span>] + epsilon                                             <span class="comment"># Step 2</span></span><br><span class="line">        J_plus[i], cache = forward_propagation_n(X,Y,gc_utils.vector_to_dictionary(thetaplus))  <span class="comment"># Step 3 ，cache用不到</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#计算J_minus [i]。输入：“parameters_values，epsilon”。输出=“J_minus [i]”。</span></span><br><span class="line">        thetaminus = np.copy(parameters_values)                                                 <span class="comment"># Step 1</span></span><br><span class="line">        thetaminus[i][<span class="number">0</span>] = thetaminus[i][<span class="number">0</span>] - epsilon                                           <span class="comment"># Step 2        </span></span><br><span class="line">        J_minus[i], cache = forward_propagation_n(X,Y,gc_utils.vector_to_dictionary(thetaminus))<span class="comment"># Step 3 ，cache用不到</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#计算gradapprox[i]</span></span><br><span class="line">        gradapprox[i] = (J_plus[i] - J_minus[i]) / (<span class="number">2</span> * epsilon)</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#通过计算差异比较gradapprox和后向传播梯度。</span></span><br><span class="line">    numerator = np.linalg.norm(grad - gradapprox)                                     <span class="comment"># Step 1'</span></span><br><span class="line">    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)                   <span class="comment"># Step 2'</span></span><br><span class="line">    difference = numerator / denominator                                              <span class="comment"># Step 3'</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> difference &lt; <span class="number">1e-7</span>:</span><br><span class="line">        print(<span class="string">"梯度检查：梯度正常!"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"梯度检查：梯度超出阈值!"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> difference</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网易云代理(听灰色歌曲)</title>
      <link href="/post/202006192233/"/>
      <url>/post/202006192233/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>想听一听网易云的灰色歌曲</p><a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>使用的工具地址：<a href="https://github.com/nondanee/UnblockNeteaseMusic" target="_blank" rel="noopener">UnblockNeteaseMusic</a></p><p>分为本地代理与服务器代理两种方法：</p><ul><li>使用服务器代理较为方便，所有设备的代理地址填服务器的即可。</li><li>本地的话只能在本机上运行，且更换设备需要重新配置等等。</li></ul><p>这里就记录下自己使用服务器配置代理的过程。</br></p><p>项目官方说法</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619161000.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619161000.png" alt="image-20200619160958445"></a></p><h2 id="安装宝塔"><a href="#安装宝塔" class="headerlink" title="安装宝塔"></a>安装宝塔</h2><p>若安装过宝塔的可直接跳过</p><p>宝塔官网：<a href="https://www.bt.cn/" target="_blank" rel="noopener">宝塔</a></p><hr><p>根据安装指令，CentOS输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y wget &amp;&amp; wget -O install.sh http:&#x2F;&#x2F;download.bt.cn&#x2F;install&#x2F;install_6.0.sh &amp;&amp; sh install.sh</span><br></pre></td></tr></table></figure><p>途中需要输入Y进行确认。</p><p>安装成功会出现下图提示：</p><ul><li>网址</li><li>用户名</li><li>密码</li></ul><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165445.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165445.png" alt="image-20200619150833197"></a></p><p>安装好宝塔后，服务器的安全组中配置一下规则，放行默认端口8888</p><p>如图填写即可，端口填8888，源填<code>0.0.0.0/0</code>，描述或备注随意。然后保存。</br></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619155038.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619155038.png" alt="image-20200619151217550"></a></p></br><p>本机上进入安装好宝塔输出的网址，填写默认用户名与密码即可进入。</p><p>按需配置，<strong>若仅仅是为了执行node.js的话可以不安装</strong></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165454.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165454.png" alt="image-20200619151602158"></a></p></br><p>网址后面的端口、用户名、密码，均可在宝塔上进行修改。</p><p><strong>建议修改宝塔的端口，修改端口需要在服务器上放行端口。</strong></br></p><p>点击宝塔中的立即修改</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165458.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165458.png" alt="image-20200619151721692"></a></p><p>随后会跳转到设置界面。</p></br><p>顺便建议修改：</p><ul><li>安全入口：默认生成的网址的后缀，修改一个好记的</li><li>面板用户：用户名</li><li>面板密码：密码</li></ul><p>最后保存即可。</p></br><h2 id="宝塔上安装PM2"><a href="#宝塔上安装PM2" class="headerlink" title="宝塔上安装PM2"></a>宝塔上安装PM2</h2><p>在面板左侧进入软件商店</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165501.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165501.png" alt="image-20200619152238820"></a></p><p>然后搜素PM2进行安装</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165503.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165503.png" alt="image-20200619152257830"></a></p><p>安装完成后，会顺带在服务器上安装git。</p><p>可以在右方开启首页显示，这样以后想管理PM2直接在首页就可以进入，不用再进软件商店了。</p></br><h2 id="安装UnblockNeteaseMusic"><a href="#安装UnblockNeteaseMusic" class="headerlink" title="安装UnblockNeteaseMusic"></a>安装UnblockNeteaseMusic</h2><p>克隆项目文件，路径随意，记得就行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;nondanee&#x2F;UnblockNeteaseMusic.git</span><br></pre></td></tr></table></figure><p>例如我在 <code>~/lluuiq/</code>下进行克隆，则项目路径为<code>~/lluuiq/UnblockNeteaseMusic/</code></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165506.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165506.png" alt="image-20200619153752775"></a></p><h2 id="配置PM2"><a href="#配置PM2" class="headerlink" title="配置PM2"></a>配置PM2</h2><p>设置PM2：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165509.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165509.png" alt="image-20200619154708532"></a></p><ul><li>项目所在根目录即克隆后的 项目路径，例如我的为<code>/lluuiq/UnblockNeteaseMusic/</code></li><li>启动文件名称填 <code>app.js</code></li><li>项目名称随意。</li></ul></br><p>最后点击添加即可。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165512.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165512.png" alt="image-20200619154844453"></a></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165514.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165514.png" alt="image-20200619155243246"></a></p><h2 id="放行端口"><a href="#放行端口" class="headerlink" title="放行端口"></a>放行端口</h2><p>服务器上和[安装宝塔](# 安装宝塔)中的放行端口一样。</p><p>UnblockNeteaseMusic的默认端口为8080，因此需要放行8080端口。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165519.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165519.png" alt="image-20200619155205516"></a></p><p>在宝塔面板的防火墙中也要放行8080端口。在左侧菜单栏的安全里，设置防火墙</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165516.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165516.png" alt="image-20200619155357790"></a></p><h2 id="开启代理"><a href="#开启代理" class="headerlink" title="开启代理"></a>开启代理</h2><p>以windows为例，在网易云的设置里，进入工具，选择自定义代理，然后输入</p><ul><li>服务器：自己的服务器公网IP</li><li>端口：UnblockNeteaseMusic的端口</li></ul><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165521.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165521.png" alt="image-20200619155529232"></a></p><p>输入完成后，点击测试，会出现该代理可用，然后点击确定重启网易云。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165523.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165523.png" alt="image-20200619155637332"></a></p><p><del>甚至可以听一些不存在的歌曲</del></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165525.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165525.png" alt="image-20200619155742793"></a></p><p>只要服务器一直在运行，就可以随时设置代理来听一些灰色歌曲了。</p><p>不同系统设置代理的方法，参考说明文档：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165529.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165529.png" alt="image-20200619161056455"></a></p><h2 id="修改UnblockNeteaseMusic端口号（可选）"><a href="#修改UnblockNeteaseMusic端口号（可选）" class="headerlink" title="修改UnblockNeteaseMusic端口号（可选）"></a>修改UnblockNeteaseMusic端口号（可选）</h2><p>如果不想使用默认的8080端口，则可以修改配置。</p><p>编辑UnblockNeteaseMusic项目路径下的 src/app.js，将红框中的8080改成自己想要的端口号，假设为<code>3XX9</code></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165532.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165532.png" alt="image-20200619143758968"></a></p><p>然后在PM2中删除之前添加的任务</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165535.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165535.png" alt="image-20200619160415950"></a></p><p>重新添加一次</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165538.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165538.png" alt="image-20200619160444988"></a></p><p>端口变成了修改配置文件中的端口。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165541.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165541.png" alt="image-20200619160514414"></a></p><p>然后分别到服务器和宝塔面板中放行自定义的端口</p><p>服务器：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165544.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165544.png" alt="image-20200619160728892"></a></p><p>宝塔：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165546.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165546.png" alt="image-20200619160641879"></a></p><p>修改网易云的代理测试一下：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165549.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165549.png" alt="image-20200619160805999"></a></p><p>接下来正常使用就可以了。</p><p>也可以把之前8080端口的放行给删掉</p>]]></content>
      
      
      <categories>
          
          <category> 妙妙工具箱 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 超能力 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达深度学习编程作业1-4</title>
      <link href="/post/202006142233/"/>
      <url>/post/202006142233/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>吴恩达深度学习课程《神经网络和深度学习》第三周（深层神经网络）的编程作业。</p><a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>题目与参考作业的地址：<a href="https://blog.csdn.net/u013733326/article/details/79767169" target="_blank" rel="noopener">【中文】【吴恩达课后编程作业】Course 1 - 神经网络和深度学习 - 第四周作业(1&amp;2)</a></p><p>相关数据集与前提代码在该博文中下载。</p><h2 id="查看下载的资料"><a href="#查看下载的资料" class="headerlink" title="查看下载的资料"></a>查看下载的资料</h2><p>下载后如图所示：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621080116.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621080116.png" alt="image-20200614025709724"></a></p><p>打开datasets，可以发现是h5文件，与第二周的作业文件相同，是猫的图片数据</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621080119.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621080119.png" alt="image-20200614025724028"></a></p><p>文件因为内容过多，就不截图了。</p><ul><li>打开dnn_utils.py，可以看到提供了神经网络的ReLU激活函数与sigmoid函数（正向与反向）</li><li>打开lr_utils.py，可以看到是第二周作业的读取训练集、测试集数据的代码</li><li>打开testCases.py， 该文件提供了各个函数的测试用参数（测试用的，该文章中没用到）</li></ul><p>根据以上可知，这次作业是使用深层神经网络来完成第二周的作业：识别猫的图片。</p><h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><p>与第二周的作业步骤相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载 lr_utils的load_dataset函数</span></span><br><span class="line"><span class="keyword">from</span> lr_utils <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="comment"># 定义变量来获取load_dataset函数的返回值</span></span><br><span class="line">train_set_x , train_set_y , test_set_x , test_set_y , classes = load_dataset()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"训练集特征的维度："</span>,train_set_x.shape,<span class="string">"训练集特征的类型"</span>,type(train_set_x))</span><br><span class="line">print(<span class="string">"训练集标签的维度："</span>,train_set_y.shape,<span class="string">"训练集标签的类型"</span>,type(train_set_y))</span><br><span class="line">print(<span class="string">"测试集特征的维度："</span>,test_set_x.shape,<span class="string">"测试集特征的类型"</span>,type(test_set_x))</span><br><span class="line">print(<span class="string">"测试集标签的维度："</span>,test_set_y.shape,<span class="string">"测试集标签的类型"</span>,type(test_set_y))</span><br><span class="line">print(<span class="string">"classes的维度："</span>,classes.shape,<span class="string">"classes的类型"</span>,type(classes))</span><br></pre></td></tr></table></figure><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p>与第二周的作业步骤相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_set_x_flatten = train_set_x.reshape(train_set_x.shape[<span class="number">0</span>],<span class="number">-1</span>).T</span><br><span class="line">test_set_x_flatten = test_set_x.reshape(test_set_x.shape[<span class="number">0</span>],<span class="number">-1</span>).T</span><br><span class="line"></span><br><span class="line">train_set_x_flatten_normalization = train_set_x_flatten/<span class="number">255</span></span><br><span class="line">test_set_x_flatten_normalization = test_set_x_flatten/<span class="number">255</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"处理后的训练集维度："</span>,train_set_x_flatten_normalization.shape)</span><br><span class="line">print(<span class="string">"处理后的测试集维度："</span>,test_set_x_flatten_normalization.shape)</span><br></pre></td></tr></table></figure><p>处理后图片的存储矩阵就变为（64<em>64</em>3，样本个数）</p><h2 id="构建神经网络"><a href="#构建神经网络" class="headerlink" title="构建神经网络"></a>构建神经网络</h2><h3 id="导入numpy"><a href="#导入numpy" class="headerlink" title="导入numpy"></a>导入numpy</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h3 id="初始化模型参数函数"><a href="#初始化模型参数函数" class="headerlink" title="初始化模型参数函数"></a>初始化模型参数函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialization_parameters</span><span class="params">(layers)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">            layers 隐藏层列表，元素为对应层的隐藏单元个数</span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">            params 存储W[i] 与b[i] 的字典</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    params = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历隐藏层</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(layers)):</span><br><span class="line">        <span class="comment"># 为每一层初始化模型参数</span></span><br><span class="line">        params[<span class="string">'W'</span>+str(i)] = np.random.randn(layers[i],</span><br><span class="line">                                             layers[i<span class="number">-1</span>]) / np.sqrt(layers[i<span class="number">-1</span>])</span><br><span class="line">        params[<span class="string">'b'</span>+str(i)] = np.zeros((layers[i], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span>(params[<span class="string">'W'</span>+str(i)].shape == (layers[i], layers[i<span class="number">-1</span>]))</span><br><span class="line">        <span class="keyword">assert</span>(params[<span class="string">'b'</span>+str(i)].shape == (layers[i], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回值字典 内容为[W1,b1,W2,b2,W3,b3 ..... WL,bL]</span></span><br><span class="line">    <span class="keyword">return</span> params</span><br></pre></td></tr></table></figure><p>这里传入一个变量layers，用来保存隐藏层的信息，元素为各层的隐藏单元数目，不包括输入层。</p><p>例如：创建一个5层的神经网络，对应隐层分别为 5、5、4、4、1。</p><p>则 layers=[5,5,4,4,1] ，图如下</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621080124.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621080124.png" alt="image-20200615000700220"></a></p><p>这样，<code>len(layers)</code>为神经网络的层数。<code>leyers[i]</code>为第<code>i</code>层的隐藏单元数目。</p><p>用params来存储各隐藏层的模型参数。</p><p>因为与无隐层、单隐层不同，这是一个有L个隐层的神经网络，所以使用遍历的方式来逐层初始化。</p><p><strong>注：</strong> 这里生成随机数后不再 *0.01，该为 <code>/ np.sqrt(layers[i-1])</code>，否则深层的话代价函数更新不下去。</p><h3 id="定义正向传播函数"><a href="#定义正向传播函数" class="headerlink" title="定义正向传播函数"></a>定义正向传播函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dnn_utils <span class="keyword">as</span> dnn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(X, params, activations)</span>:</span></span><br><span class="line">    <span class="string">''' </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">            X 输入特征，即A[i-1]</span></span><br><span class="line"><span class="string">            params 模型参数字典</span></span><br><span class="line"><span class="string">            activation 激活函数列表</span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">            cache 存储A[i] 与 Z[i] 的字典</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义激活函数字典，根据输入的activation来选择对应的激活函数</span></span><br><span class="line">    activation_function = &#123;</span><br><span class="line">        <span class="string">"relu"</span>: dnn.relu,</span><br><span class="line">        <span class="string">"sigmoid"</span>: dnn.sigmoid</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取层数</span></span><br><span class="line">    L = len(activations)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># cache['A0']初始化为输入特征X</span></span><br><span class="line">    cache = &#123;</span><br><span class="line">        <span class="string">'A0'</span>: X</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历隐藏层进行正向传播</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, L+<span class="number">1</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取当前层的W与Z</span></span><br><span class="line">        W = params[<span class="string">'W'</span>+str(i)]</span><br><span class="line">        b = params[<span class="string">'b'</span>+str(i)]</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取当前层的上一层的A，即当前层的输入值</span></span><br><span class="line">        A_pre = cache[<span class="string">'A'</span>+str(i<span class="number">-1</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取当前层选择的激活函数</span></span><br><span class="line">        activation = activations[i<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算Z</span></span><br><span class="line">        Z = np.dot(W, A_pre)+b</span><br><span class="line">        <span class="comment"># 使用dnn_utils中的激活函数来计算当前层的A</span></span><br><span class="line">        cache[<span class="string">'A'</span>+str(i)], cache[<span class="string">'Z'</span>+str(i)</span><br><span class="line">                                 ] = activation_function[activation](Z)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 断言</span></span><br><span class="line">        <span class="keyword">assert</span> cache[<span class="string">'Z'</span>+str(i)].shape == Z.shape, <span class="string">'error：维度错误'</span></span><br><span class="line">        <span class="keyword">assert</span> cache[<span class="string">'A'</span>+str(i)].shape == cache[<span class="string">'Z'</span>+str(i)</span><br><span class="line">                                                ].shape, <span class="string">'error: A与Z的维度不相等'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cache</span><br></pre></td></tr></table></figure><ul><li><p>导入dnn_utils来使用其中的激活函数。</p></li><li><p>传入的参数有一个activations，是一个列表，其元素为从第一个隐藏层开始的各层使用的激活函数，因为本次作业的dnn_utils文件只有ReLU与sigmoid激活函数，所以值为relu或sigmoid。</p></li><li><p>activation_function字典的value值为dnn_utils文件中的函数，这样后面执行<code>activation = activations[i-1]</code>后，只需使用activation_function<a href="Z">activation</a>来将Z传入激活函数即可 。</p><p>关于activation_function[activation]，假如是使用ReLU函数，那么activation=“relu”，结果为activation_function[“relu”]，即dnn.relu，后面加上(Z)，即组成dnn.relu(Z)，调用函数。</p></li><li><p>遍历隐藏层，根据激活函数列表来实现对应的激活函数。</p></li></ul><h3 id="定义代价函数"><a href="#定义代价函数" class="headerlink" title="定义代价函数"></a>定义代价函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(AL,Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    计算交叉熵代价函数</span></span><br><span class="line"><span class="string">    J=1/m * ∑损失函数</span></span><br><span class="line"><span class="string">    损失函数= -[Y*log(A2)+(1-Y)*log(1-A2)]</span></span><br><span class="line"><span class="string">    这里 ∑损失函数 可以用向量来表示。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">         AL - 正向传播最后的输出结果，即损失函数公式中的y帽</span></span><br><span class="line"><span class="string">         Y - 标签</span></span><br><span class="line"><span class="string">         params - 初始化模型参数函数的字典返回值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">         代价 - 交叉熵成本给出方程（13）</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 获取样本数</span></span><br><span class="line">    m = AL.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#计算代价</span></span><br><span class="line">    logprobs  = np.multiply(np.log(AL), Y) + np.multiply((<span class="number">1</span> - Y), np.log(<span class="number">1</span> - AL))</span><br><span class="line">    cost = - np.sum(logprobs) / m</span><br><span class="line">    cost = float(np.squeeze(cost))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure><p>用于计算每一次迭代的代价。</p><h3 id="定义反向传播函数"><a href="#定义反向传播函数" class="headerlink" title="定义反向传播函数"></a>定义反向传播函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_backward</span><span class="params">(X, Y, params, cache, activations)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        参数： </span></span><br><span class="line"><span class="string">            Y 训练集标签</span></span><br><span class="line"><span class="string">            params 模型参数字典</span></span><br><span class="line"><span class="string">            cache A与Z的字典</span></span><br><span class="line"><span class="string">            activations 激活函数列表</span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">            grads 存储dA[i] dW[i] db[i]</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取样本数</span></span><br><span class="line">    m = Y.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取层数</span></span><br><span class="line">    L = len(activations)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取输出层的A （正向传播的输出）</span></span><br><span class="line">    AL = cache[<span class="string">'A'</span>+str(L)]</span><br><span class="line"><span class="comment">#     AL = np.random.randn(1, 2)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 激活函数字典</span></span><br><span class="line">    activation_function = &#123;</span><br><span class="line">        <span class="string">"relu"</span>: dnn.relu_backward,</span><br><span class="line">        <span class="string">"sigmoid"</span>: dnn.sigmoid_backward</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cache[<span class="string">'A0'</span>] = X <span class="comment"># 将cache['A0']定义为输入特征X</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化dAL</span></span><br><span class="line">    grads = &#123;</span><br><span class="line">        <span class="string">'dA'</span>+str(L): -(np.divide(Y, AL) - np.divide(<span class="number">1</span> - Y, <span class="number">1</span> - AL))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播从后往前计算，所以range(L,0,-1)，使用-1来实现区间(0,L]的反向遍历</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(L, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据传入的激活函数列表选择对应的激活函数</span></span><br><span class="line">        activation = activation_function[activations[i<span class="number">-1</span>]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取当前层的W与Z</span></span><br><span class="line">        W = params[<span class="string">'W'</span>+str(i)]</span><br><span class="line">        Z = cache[<span class="string">'Z'</span>+str(i)]</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#获取当前层的上一层的A，即当前层的输入值</span></span><br><span class="line">        A_pre = cache[<span class="string">'A'</span>+str(i<span class="number">-1</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算导数dA与dZ</span></span><br><span class="line">        dA = grads[<span class="string">'dA'</span>+str(i)]</span><br><span class="line">        dZ = activation(dA, Z)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算dW与db 并将dW、db、dA存到grads中</span></span><br><span class="line">        grads[<span class="string">'dW'</span>+str(i)] = np.dot(dZ, A_pre.T)/m</span><br><span class="line">        grads[<span class="string">'db'</span>+str(i)] = np.sum(dZ, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)/m</span><br><span class="line">        grads[<span class="string">'dA'</span>+str(i<span class="number">-1</span>)] = np.dot(W.T, dZ)</span><br><span class="line">    <span class="keyword">return</span> grads</span><br></pre></td></tr></table></figure><p>这里同样使用了activations，与正向不同的是这里是根据激活函数列表来选择对应的激活函数的求导函数。</p><p>其余关于activations的部分与正向传播相同。</p><h3 id="定义更新参数函数"><a href="#定义更新参数函数" class="headerlink" title="定义更新参数函数"></a>定义更新参数函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_params</span><span class="params">(params,grads,L,lr)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        参数： </span></span><br><span class="line"><span class="string">            parameters 模型参数字典</span></span><br><span class="line"><span class="string">            grads  反向传播得到的导数字典</span></span><br><span class="line"><span class="string">            lr 学习率</span></span><br><span class="line"><span class="string">            L 神经网络的层数</span></span><br><span class="line"><span class="string">        返回值：</span></span><br><span class="line"><span class="string">            params 更新后的模型参数字典</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,L+<span class="number">1</span>):</span><br><span class="line">        params[<span class="string">'W'</span>+str(i)] = params[<span class="string">'W'</span>+str(i)] - lr * grads[<span class="string">'dW'</span>+str(i)]</span><br><span class="line">        params[<span class="string">'b'</span>+str(i)] = params[<span class="string">'b'</span>+str(i)] - lr * grads[<span class="string">'db'</span>+str(i)]</span><br><span class="line">    <span class="keyword">return</span> params</span><br></pre></td></tr></table></figure><h3 id="打包训练模型"><a href="#打包训练模型" class="headerlink" title="打包训练模型"></a>打包训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_model</span><span class="params">(X, Y, layers, activations, lr, num_iterations, print_cost=False)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        深层神经网络模型</span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">            X 训练集输入特征</span></span><br><span class="line"><span class="string">            Y 训练集标签</span></span><br><span class="line"><span class="string">            layers 神经网络隐藏层列表(不包含输入层)，元素为各隐藏层的隐藏单元数量</span></span><br><span class="line"><span class="string">            activations 激活函数列表，元素为对应层的激活函数（作业里只有relu和sigmoid）</span></span><br><span class="line"><span class="string">            lr 学习率</span></span><br><span class="line"><span class="string">            num_iterations 迭代次数</span></span><br><span class="line"><span class="string">            seed 随机数种子</span></span><br><span class="line"><span class="string">            print_cost 是否输出代价，默认为否</span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">            parameters 各层更新后的模型参数 字典</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    nx = X.shape[<span class="number">0</span>]  <span class="comment"># 获取输入特征的维数</span></span><br><span class="line">    ny = Y.shape[<span class="number">0</span>]  <span class="comment"># 获取标签的维数</span></span><br><span class="line">    <span class="keyword">assert</span> layers[<span class="number">-1</span>] == ny, <span class="string">'error：请确定输出层的单元数与标签的维数相等'</span></span><br><span class="line"></span><br><span class="line">    L = len(layers)  <span class="comment"># 获取神经网络层数（隐藏层的层数）</span></span><br><span class="line">    <span class="keyword">assert</span> len(activations) == L, <span class="string">'error: 请确定激活函数的个数与隐藏层的层数相等'</span></span><br><span class="line"></span><br><span class="line">    layers.insert(<span class="number">0</span>, nx) <span class="comment"># 输入层的节点数 n0</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"初始化模型参数"</span>)</span><br><span class="line">    params = initialization_parameters(layers)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 梯度下降</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,num_iterations+<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 正向传播</span></span><br><span class="line">        cache = forward(X, params, activations)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算代价</span></span><br><span class="line">        AL = cache[<span class="string">'A'</span>+str(L)]</span><br><span class="line">        cost = compute_cost(AL, Y)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输出代价</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i%<span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"第"</span>,i,<span class="string">"次迭代，当前代价为："</span>,cost)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        grads = model_backward(X,Y, params, cache, activations)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新参数</span></span><br><span class="line">        params = update_params(params,grads,L,lr)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> params</span><br></pre></td></tr></table></figure><p>调用模型函数，传入训练集输入特征X、输出特征Y 与神经网络结构layers、激活函数列表、学习率、迭代次数即可获得训练完成后的模型参数W与b。</p><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><h3 id="定义预测函数"><a href="#定义预测函数" class="headerlink" title="定义预测函数"></a>定义预测函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(X,params,activations)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        预测函数，调用正向传播函数来得到Y帽，即预测值</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数：</span></span><br><span class="line"><span class="string">            X 测试集输入特征</span></span><br><span class="line"><span class="string">            params 由神经网络模型得到的模型参数</span></span><br><span class="line"><span class="string">            activations 激活函数列表</span></span><br><span class="line"><span class="string">        返回：</span></span><br><span class="line"><span class="string">            Y 预测的标签</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 执行正向传播，params存储的为更新完成后的W与b</span></span><br><span class="line">    cache = forward(X,params,activations)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取层数</span></span><br><span class="line">    L = len(activations)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取正向传播后最后的预测值</span></span><br><span class="line">    A = cache[<span class="string">'A'</span>+str(L)]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化标签Y</span></span><br><span class="line">    Y = np.zeros((<span class="number">1</span>, X.shape[<span class="number">1</span>]))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历所有预测值，若预测大于0.5则标签为1，否则为0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(A.shape[<span class="number">1</span>]):</span><br><span class="line">        Y[<span class="number">0</span>][i] = <span class="number">1</span> <span class="keyword">if</span> A[<span class="number">0</span>][i] &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure><p>接下来只需训练模型得到params，将测试集输入特征与params、激活函数列表传入预测函数即可得到预测的标签。</p><h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置随机数种子</span></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 定义神经网络结构</span></span><br><span class="line">layers = [<span class="number">20</span>,<span class="number">7</span>,<span class="number">5</span>,<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 定义各层使用的激活函数</span></span><br><span class="line">activations = [<span class="string">'relu'</span>,<span class="string">'relu'</span>,<span class="string">'relu'</span>,<span class="string">'sigmoid'</span>]</span><br><span class="line"><span class="comment"># 定义学习率</span></span><br><span class="line">lr = <span class="number">0.0075</span></span><br><span class="line"><span class="comment"># 定义迭代次数</span></span><br><span class="line">num_iterations = <span class="number">2500</span></span><br><span class="line"><span class="comment"># 执行模型函数，获得更新后的模型参数字典params</span></span><br><span class="line">params = nn_model(train_set_x_flatten_normalization, train_set_y, layers, activations, lr, num_iterations, print_cost=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>执行后结果如图：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621075431.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621075431.png" alt="image-20200621075429192"></a></p><h3 id="进行预测"><a href="#进行预测" class="headerlink" title="进行预测"></a>进行预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测训练集</span></span><br><span class="line">train_predict_y = predict(train_set_x_flatten_normalization, params, activations)</span><br><span class="line"><span class="comment"># 预测测试集</span></span><br><span class="line">test_predict_y = predict(test_set_x_flatten_normalization, params, activations)</span><br></pre></td></tr></table></figure><h3 id="查看准确率"><a href="#查看准确率" class="headerlink" title="查看准确率"></a>查看准确率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"训练集准确率："</span>, format(<span class="number">100</span>-np.mean(np.abs(train_predict_y-train_set_y))*<span class="number">100</span>), <span class="string">"%"</span>)</span><br><span class="line">print(<span class="string">"测试集准确率："</span>, format(<span class="number">100</span>-np.mean(np.abs(test_predict_y-test_set_y))*<span class="number">100</span>), <span class="string">"%"</span>)</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621075517.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200621075517.png" alt="image-20200621075516324"></a></p><p>可以看出训练集的准确率远高于测试集，明显有过拟合现象。</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用WebStack为Hexo博客添加网址导航页面</title>
      <link href="/post/202006132233/"/>
      <url>/post/202006132233/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>因为经常把一些网站添加到浏览器的书签栏，目前已经多到眼花缭乱了，故想个办法为博客新建一个分页，把一些网址存在博客上，自己浏览器上存一部分。</p><a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>WebStack的github地址：<a href="https://github.com/hui-ho/WebStack-Laravel" target="_blank" rel="noopener">WebStack</a></p><p>配置过程中有很多的坑，</p><p>WebStack是个开源项目，在查阅使用方法时发现基本都是基于wordpress与typecho进行使用，但个人是用的Hexo，所以想在Hexo上实现它。</p><p>基于源代码</p><p>需要：</p><ul><li>解析二级域名到服务器上</li><li>安装PHP≥7.2</li></ul><h2 id="在服务器上克隆源代码"><a href="#在服务器上克隆源代码" class="headerlink" title="在服务器上克隆源代码"></a>在服务器上克隆源代码</h2><p>克隆地址随意。这里因为我用的是宝塔面板，所以放在了wwwroot下面，若不在这里，后面更改创建站点时的路径。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165334.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165334.png" alt="image-20200613085954744"></a></p><h2 id="安装PHP并配置"><a href="#安装PHP并配置" class="headerlink" title="安装PHP并配置"></a>安装PHP并配置</h2><p>到宝塔面板的软件商店搜索PHP，然后安装≥7.2的版本即可。这里我安装的是7.4。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165338.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165338.png" alt="image-20200613091542878"></a></p><p>安装好后，点击设置 ，在禁用函数里把proc_open、passthru、putenv删除。这里是我删除过后又重新加回来的，所以看着顺序不一样，找到自己的删除即可。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165340.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165340.png" alt="image-20200613110549141"></a></p><p>然后在安装拓展里，安装fileinfo</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165342.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165342.png" alt="image-20200613104649606"></a></p><h2 id="创建网站站点"><a href="#创建网站站点" class="headerlink" title="创建网站站点"></a>创建网站站点</h2><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165346.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165346.png" alt="image-20200613102751691"></a></p><p>在 <code>站点设置/网站目录</code> 里面修改一下运行目录，改为public，然后保存</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165349.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165349.png" alt="image-20200613093015517"></a></p><p>在伪静态里将规则改为laravel5，否则后台是404·</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165351.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165351.png" alt="image-20200613124010787"></a></p><h2 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h2><p>输入下面这条指令切换composer源为华为源。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">composer config -g repo.packagist composer https://mirrors.huaweicloud.com/repository/php</span><br></pre></td></tr></table></figure><p>到克隆下来的WebStack-Laravel路径</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd 你的WebStack-Laravel路径</span><br></pre></td></tr></table></figure><p>然后执行以下语句安装composer</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf composer.lock</span><br><span class="line">composer install</span><br></pre></td></tr></table></figure><p>第一次安装会提示失败，出现下图，提示Carbon版本过低。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165355.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165355.png" alt="image-20200613113307204"></a></p><p>打开WebStack-Laravel文件夹下的composer.json 然后在require代码块里插入以下代码：</p><p>注意插入后，原本的最后一句末尾加个逗号。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">"kylekatarnls/laravel-carbon-2": "^1.0.0",</span><br><span class="line">"nesbot/carbon": "2.16.3 as 1.34.0"</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165357.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165357.png" alt="image-20200613110407285"></a></p><p>然后再次执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf composer.lock</span><br><span class="line">composer install</span><br></pre></td></tr></table></figure><p>若出现如图所示信息就没问题了，下面连接数据库的信息不用管</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165400.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165400.png" alt="image-20200613112229847"></a></p><h2 id="编辑配置"><a href="#编辑配置" class="headerlink" title="编辑配置"></a>编辑配置</h2><p>在WebStack-Laravel下执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp .env.example .env</span><br></pre></td></tr></table></figure><p>然后编辑 <code>.env</code>，需要修改的配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">APP_ENV=production</span><br><span class="line">APP_URL=站点二级域名（若没开启SSL则使用http）</span><br><span class="line"></span><br><span class="line">DB_DATABASE=数据库名</span><br><span class="line">DB_USERNAME=数据库用户名</span><br><span class="line">DB_PASSWORD=数据库密码</span><br></pre></td></tr></table></figure><p>示例图如下：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165403.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165403.png" alt="image-20200613112804677"></a></p><p>生成KEY，执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">php artisan key:generate</span><br></pre></td></tr></table></figure><p>迁移数据，执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">php artisan migrate:refresh --seed</span><br></pre></td></tr></table></figure><p>其中提示输入的地方都输入yes即可。最后应该会报错，这时需要修改AppServiceProvider.php</p><p>修改<code>WebStack-Laravel/app/providers/AppServiceProvider.php</code>：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">namespace</span> <span class="title">App</span>\<span class="title">Providers</span>;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">use</span> <span class="title">App</span>\<span class="title">Observers</span>\<span class="title">SiteObserver</span>;</span><br><span class="line"><span class="keyword">use</span> <span class="title">App</span>\<span class="title">Site</span>;</span><br><span class="line"><span class="keyword">use</span> <span class="title">Encore</span>\<span class="title">Admin</span>\<span class="title">Config</span>\<span class="title">Config</span>;</span><br><span class="line"><span class="keyword">use</span> <span class="title">Illuminate</span>\<span class="title">Support</span>\<span class="title">Facades</span>\<span class="title">Schema</span>;</span><br><span class="line"><span class="keyword">use</span> <span class="title">Illuminate</span>\<span class="title">Support</span>\<span class="title">ServiceProvider</span>;</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppServiceProvider</span> <span class="keyword">extends</span> <span class="title">ServiceProvider</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Bootstrap any application services.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> void</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">boot</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        Schema::defaultStringLength(<span class="number">191</span>);</span><br><span class="line">        Site::observe(SiteObserver::class);</span><br><span class="line"> </span><br><span class="line">        $table = config(<span class="string">'admin.extensions.config.table'</span>, <span class="string">'admin_config'</span>);</span><br><span class="line">        <span class="keyword">if</span> (Schema::hasTable($table)) &#123;</span><br><span class="line">            Config::load();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Register any application services.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> void</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">register</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后再次执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">php artisan key:generate</span><br><span class="line">php artisan migrate:refresh --seed</span><br></pre></td></tr></table></figure><hr><p><strong>这里我出现了一个问题：</strong></p><p>提示我admin_config已存在，应该是之前执行<code>php artisan migrate:refresh --seed</code>时导致的 或是在创建站点时初始化导致的。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165407.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165407.png" alt="image-20200613121516612"></a></p><p>故在宝塔面板删除当前的数据库，然后重新创建了一个。</p><p>下图为重新创建的，这里貌似宝塔要求数据库名与用户名要相同。</p><p>当然这里的数据库名、用户名、密码对应着上述修改 <code>.env</code>文件的内容。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165411.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165411.png" alt="image-20200613122220972"></a></p><p>创建好后点击右边的工具确认没有<code>admin_congfig</code>，正常来讲应该是全空的。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165413.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165413.png" alt="image-20200613122324854"></a></p><p>然后执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">php artisan key:generate</span><br><span class="line">php artisan migrate:refresh --seed</span><br></pre></td></tr></table></figure><hr><h2 id="为站点赋予权限"><a href="#为站点赋予权限" class="headerlink" title="为站点赋予权限"></a>为站点赋予权限</h2><p>打开网站进行查看以及后面一些操作时，会经常提示报错信息，都是XXX拒绝访问等等。</p><p>故直接在宝塔上赋予站点目录所有权限。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165418.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165418.png" alt="image-20200613124738186"></a></p><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165420.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165420.png" alt="image-20200613130043246"></a></p><h2 id="后台管理"><a href="#后台管理" class="headerlink" title="后台管理"></a>后台管理</h2><p>在主页的url后面加上<code>/admin</code>即可进入。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165423.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165423.png" alt="image-20200613124140962"></a></p><p>默认的用户名与密码都是admin，进去后可以修改</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165427.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200619165427.png" alt="image-20200613124424354"></a></p><h2 id="清除原有站点（可选）"><a href="#清除原有站点（可选）" class="headerlink" title="清除原有站点（可选）"></a>清除原有站点（可选）</h2><p>执行下方语句进行清除。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">php artisan webstack:clean</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> WebStack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达深度学习编程作业1-3</title>
      <link href="/post/202006112233/"/>
      <url>/post/202006112233/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>吴恩达深度学习课程《神经网络和深度学习》第三周（浅层神经网络）的编程作业。</p><a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>感谢作者<a href="https://blog.csdn.net/u013733326" target="_blank" rel="noopener">阿宽</a>提供作业题目<a href="https://blog.csdn.net/u013733326/article/details/79702148" target="_blank" rel="noopener">【中文】【吴恩达课后编程作业】Course 1 - 神经网络和深度学习 - 第三周作业</a></p><p>数据集以及题目可在该博文中查看与下载。</p><p>题目为建立 单隐藏层的神经网络 对平面数据进行分类。</p><p>下载的文件中：</p><ul><li>testCases 提供一些测试案例来评估正确性，可打开该文件来查看一些测试用例（我这里就不写测试函数了，原博文中有编写）。</li><li>planar_utils 提供在该作业中需要使用的一些功能。</li></ul><p>需要的库：</p><ul><li>numpy 数据科学计算的库</li><li>matplotlib 绘图</li><li>sklearn 机器学习工具包</li><li></li></ul><h2 id="导包"><a href="#导包" class="headerlink" title="导包"></a>导包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> testCases <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets</span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model</span><br><span class="line"><span class="keyword">from</span> planar_utils <span class="keyword">import</span> plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets</span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="literal">False</span></span><br><span class="line">plt.rcParams[<span class="string">'font.family'</span>]=<span class="string">'SimHei'</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置一个随机数种子，与原博文保持一致</span></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h2><p>查看一下X与Y的维度和类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X,Y=load_planar_dataset()</span><br><span class="line">print(<span class="string">"X的维度为："</span>,X.shape,<span class="string">"X的类型为："</span>,type(X))</span><br><span class="line">print(<span class="string">"Y的维度为："</span>,Y.shape,<span class="string">"Y的类型为："</span>,type(Y))</span><br></pre></td></tr></table></figure><p>结果如图：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611052154.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611052154.png" alt="image-20200611052153391"></a></p><p>可知一共有400个样本。其中X的维度中的2为对应的平面图的X轴、Y轴坐标。</p><p>Y的取值为0或1，为样本的标签。  </p><h2 id="将数据集可视化"><a href="#将数据集可视化" class="headerlink" title="将数据集可视化"></a>将数据集可视化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(X[<span class="number">0</span>, :], X[<span class="number">1</span>, :], c=np.squeeze(Y), s=<span class="number">40</span>, cmap=plt.cm.Spectral)</span><br></pre></td></tr></table></figure><p>结果如图：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611051941.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611051941.png" alt="image-20200611051939893"></a></p><p>其中y=0的标签在图中为红色点。</p><p>y=1的标签在图中为蓝色点。  </p><h2 id="查看逻辑回归的准确率"><a href="#查看逻辑回归的准确率" class="headerlink" title="查看逻辑回归的准确率"></a>查看逻辑回归的准确率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用sklearn库建立逻辑回归模型</span></span><br><span class="line">clf = sklearn.linear_model.LogisticRegressionCV()</span><br><span class="line">clf.fit(X.T,Y.T)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: clf.predict(x), X, np.squeeze(Y)) <span class="comment">#绘制决策边界</span></span><br><span class="line">plt.title(<span class="string">"逻辑回归"</span>) <span class="comment">#图标题</span></span><br><span class="line">LR_predictions  = clf.predict(X.T) <span class="comment">#预测结果</span></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"逻辑回归的准确性："</span>,float((np.dot(Y, LR_predictions) + np.dot(<span class="number">1</span> - Y,<span class="number">1</span> - LR_predictions)) / float(Y.size) * <span class="number">100</span>),</span><br><span class="line">       <span class="string">"%"</span>)</span><br></pre></td></tr></table></figure><p>结果如图：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611054526.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611054526.png" alt="image-20200611054524905"></a></p><p>47%表示的为预测正确的所占百分比。</p><p>由结果图可知，逻辑回归的线性决策边界并不能很好的区分这些数据，故正确率仅有47%。  </p><h2 id="构建单隐藏层神经网络"><a href="#构建单隐藏层神经网络" class="headerlink" title="构建单隐藏层神经网络"></a>构建单隐藏层神经网络</h2><h3 id="流程："><a href="#流程：" class="headerlink" title="流程："></a>流程：</h3><ul><li>定义神经网络结构</li><li>初始化模型参数</li><li>进行梯度下降（正向、反向传播、计算代价函数、更新参数）</li></ul><p>其中正向传播与反向传播的公式：</p><p>正向传播（左），反向传播（右）</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611065023.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611065023.png" alt="image-20200611065022546"></a></p><p>可以把这些功能整合到一个模型函数中。</p><p>接下来先根据步骤来逐一编写实现代码。  </p><h3 id="定义神经网络结构"><a href="#定义神经网络结构" class="headerlink" title="定义神经网络结构"></a>定义神经网络结构</h3><p>在这一步定义好神经网络的输入层单元的数量、隐藏层单元的数量、输出层单元的数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layer_sizes</span><span class="params">(X , Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">     X - 输入特征,维度为（输入特征的数量，样本数）</span></span><br><span class="line"><span class="string">     Y - 标签，维度为（输出的数量，样本数）</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">     n_x - 输入层单元的数量</span></span><br><span class="line"><span class="string">     n_h - 隐藏层单元的数量</span></span><br><span class="line"><span class="string">     n_y - 输出层单元的数量</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    n_x = X.shape[<span class="number">0</span>] </span><br><span class="line">    <span class="comment"># 手动定义为4个隐藏单元</span></span><br><span class="line">    n_h = <span class="number">4</span> </span><br><span class="line">    n_y = Y.shape[<span class="number">0</span>] </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (n_x,n_h,n_y)</span><br></pre></td></tr></table></figure><h3 id="定义模型参数初始化函数"><a href="#定义模型参数初始化函数" class="headerlink" title="定义模型参数初始化函数"></a>定义模型参数初始化函数</h3><ul><li>定义了随机数种子为2，确保结果一致。</li><li>不像第二周作业一样用0初始化，改为随机数初始化，不然梯度下降失去作用。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span><span class="params">( n_x , n_h ,n_y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        n_x - 输入层单元的数量</span></span><br><span class="line"><span class="string">        n_h - 隐藏层单元的数量</span></span><br><span class="line"><span class="string">        n_y - 输出层单元的数量</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        params - 包含参数的字典：</span></span><br><span class="line"><span class="string">            W1 - 权重矩阵,维度为（n_h，n_x）</span></span><br><span class="line"><span class="string">            b1 - 偏向量，维度为（n_h，1）</span></span><br><span class="line"><span class="string">            W2 - 权重矩阵，维度为（n_y，n_h）</span></span><br><span class="line"><span class="string">            b2 - 偏向量，维度为（n_y，1）</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 定义随机数种子，确保结果一致</span></span><br><span class="line">    np.random.seed(<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用随机数初始化</span></span><br><span class="line">    W1 = np.random.randn(n_h,n_x) * <span class="number">0.01</span></span><br><span class="line">    b1 = np.zeros(shape=(n_h, <span class="number">1</span>))</span><br><span class="line">    W2 = np.random.randn(n_y,n_h) * <span class="number">0.01</span></span><br><span class="line">    b2 = np.zeros(shape=(n_y, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    parameters = &#123;</span><br><span class="line">        <span class="string">"W1"</span> : W1,</span><br><span class="line">        <span class="string">"b1"</span> : b1,</span><br><span class="line">        <span class="string">"W2"</span> : W2,</span><br><span class="line">        <span class="string">"b2"</span> : b2 </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h3 id="定义正向传播函数"><a href="#定义正向传播函数" class="headerlink" title="定义正向传播函数"></a>定义正向传播函数</h3><ul><li>这里将初始化函数的返回值（字典作为传入参数）</li><li>隐藏层使用的激活函数是tanh。输出层使用sigmoid，因为想要输出结果的取值范围在[0,1]·。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span><span class="params">( X , parameters )</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">         X - 维度为（n_x，样本数）的输入特征。</span></span><br><span class="line"><span class="string">         parameters - 初始化函数（initialization_parameters）的输出</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">         A2 - 使用sigmoid()函数计算的第二次激活后的数值</span></span><br><span class="line"><span class="string">         cache - 包含“Z1”，“A1”，“Z2”和“A2”的字典类型变量</span></span><br><span class="line"><span class="string">     """</span></span><br><span class="line">    <span class="comment"># 读取初始化后的参数</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters[<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters[<span class="string">"b2"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 正向传播，最终输出A2</span></span><br><span class="line">    Z1 = np.dot(W1 , X) + b1</span><br><span class="line">    A1 = np.tanh(Z1) <span class="comment"># 隐藏层使用numpy自带的tanh函数</span></span><br><span class="line">    Z2 = np.dot(W2 , A1) + b2</span><br><span class="line">    A2 = sigmoid(Z2) <span class="comment"># 输出层使用sigmoid激活函数</span></span><br><span class="line"></span><br><span class="line">    cache = &#123;<span class="string">"Z1"</span>: Z1,</span><br><span class="line">             <span class="string">"A1"</span>: A1,</span><br><span class="line">             <span class="string">"Z2"</span>: Z2,</span><br><span class="line">             <span class="string">"A2"</span>: A2&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (A2, cache)</span><br></pre></td></tr></table></figure><h3 id="定义计算代价函数的函数"><a href="#定义计算代价函数的函数" class="headerlink" title="定义计算代价函数的函数"></a>定义计算代价函数的函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span><span class="params">(A2,Y,parameters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    计算交叉熵代价函数</span></span><br><span class="line"><span class="string">    J=1/m * ∑损失函数</span></span><br><span class="line"><span class="string">    损失函数= -[Y*log(A2)+(1-Y)*log(1-A2)]</span></span><br><span class="line"><span class="string">    这里 ∑损失函数 可以用向量来表示。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">         A2 - 正向传播最后的输出结果，即损失函数公式中的y帽</span></span><br><span class="line"><span class="string">         Y - 标签</span></span><br><span class="line"><span class="string">         parameters - 初始化模型参数函数的字典返回值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">         代价 - 交叉熵成本给出方程（13）</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 获取样本数</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取模型参数W1与W2</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#计算代价</span></span><br><span class="line">    logprobs  = np.multiply(np.log(A2), Y) + np.multiply((<span class="number">1</span> - Y), np.log(<span class="number">1</span> - A2))</span><br><span class="line">    cost = - np.sum(logprobs) / m</span><br><span class="line">    cost = float(np.squeeze(cost))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure><h3 id="定义反向传播函数"><a href="#定义反向传播函数" class="headerlink" title="定义反向传播函数"></a>定义反向传播函数</h3><p>这里需要注意的是tanh函数 A=g(Z) 的导数为 1−A2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation</span><span class="params">(parameters,cache,X,Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">     parameters - 包含我们的参数的一个字典类型的变量。</span></span><br><span class="line"><span class="string">     cache - 包含“Z1”，“A1”，“Z2”和“A2”的字典类型的变量。</span></span><br><span class="line"><span class="string">     X - 输入数据，维度为（2，数量）</span></span><br><span class="line"><span class="string">     Y - “True”标签，维度为（1，数量）</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">     grads - 包含W和b的导数一个字典类型的变量。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 获取样本数</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取模型参数W1与w2</span></span><br><span class="line">    W1 = parameters[<span class="string">"W1"</span>]</span><br><span class="line">    W2 = parameters[<span class="string">"W2"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取激活函数的输出A1与A2</span></span><br><span class="line">    A1 = cache[<span class="string">"A1"</span>]</span><br><span class="line">    A2 = cache[<span class="string">"A2"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算导数</span></span><br><span class="line">    dZ2= A2 - Y</span><br><span class="line">    dW2 = (<span class="number">1</span> / m) * np.dot(dZ2, A1.T)</span><br><span class="line">    db2 = (<span class="number">1</span> / m) * np.sum(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    dZ1 = np.multiply(np.dot(W2.T, dZ2), <span class="number">1</span> - np.power(A1, <span class="number">2</span>))</span><br><span class="line">    dW1 = (<span class="number">1</span> / m) * np.dot(dZ1, X.T)</span><br><span class="line">    db1 = (<span class="number">1</span> / m) * np.sum(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    grads = &#123;</span><br><span class="line">        <span class="string">"dW1"</span>: dW1,</span><br><span class="line">        <span class="string">"db1"</span>: db1,</span><br><span class="line">        <span class="string">"dW2"</span>: dW2,</span><br><span class="line">        <span class="string">"db2"</span>: db2</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> grads</span><br></pre></td></tr></table></figure><h3 id="定义更新参数的函数"><a href="#定义更新参数的函数" class="headerlink" title="定义更新参数的函数"></a>定义更新参数的函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_params</span><span class="params">(parameters,grads,lr=<span class="number">1.2</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">     parameters - 包含模型参数的字典类型的变量。</span></span><br><span class="line"><span class="string">     grads - 包含导数的字典类型的变量。</span></span><br><span class="line"><span class="string">     lr(learning rate) - 学习速率</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">     parameters - 更新后的参数的 字典类型的变量。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 读取原模型参数</span></span><br><span class="line">    W1,W2 = parameters[<span class="string">"W1"</span>],parameters[<span class="string">"W2"</span>]</span><br><span class="line">    b1,b2 = parameters[<span class="string">"b1"</span>],parameters[<span class="string">"b2"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 读取模型参数的导数</span></span><br><span class="line">    dW1,dW2 = grads[<span class="string">"dW1"</span>],grads[<span class="string">"dW2"</span>]</span><br><span class="line">    db1,db2 = grads[<span class="string">"db1"</span>],grads[<span class="string">"db2"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    W1 = W1 - lr * dW1</span><br><span class="line">    b1 = b1 - lr * db1</span><br><span class="line">    W2 = W2 - lr * dW2</span><br><span class="line">    b2 = b2 - lr * db2</span><br><span class="line">    </span><br><span class="line">    parameters = &#123;</span><br><span class="line">        <span class="string">"W1"</span>: W1,</span><br><span class="line">        <span class="string">"b1"</span>: b1,</span><br><span class="line">        <span class="string">"W2"</span>: W2,</span><br><span class="line">        <span class="string">"b2"</span>: b2</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h3 id="打包成模型函数"><a href="#打包成模型函数" class="headerlink" title="打包成模型函数"></a>打包成模型函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_model</span><span class="params">(X,Y,n_h,num_iterations,print_cost=False)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        X - 输入特征,维度为（2，样本数）</span></span><br><span class="line"><span class="string">        Y - 标签，维度为（1，样本数）</span></span><br><span class="line"><span class="string">        n_h - 隐藏层的数量</span></span><br><span class="line"><span class="string">        num_iterations - 梯度下降的迭代次数</span></span><br><span class="line"><span class="string">        print_cost - 如果为True，则每1000次迭代打印一次成本数值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        parameters - 模型的参数，用于预测。</span></span><br><span class="line"><span class="string">     """</span></span><br><span class="line">     </span><br><span class="line">    np.random.seed(<span class="number">3</span>) <span class="comment">#指定随机种子</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用设置网络结构函数</span></span><br><span class="line">    n_x = layer_sizes(X, Y)[<span class="number">0</span>]</span><br><span class="line">    n_y = layer_sizes(X, Y)[<span class="number">2</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    parameters  = initialize_parameters(n_x,n_h,n_y)</span><br><span class="line">    W1 = parameters [<span class="string">"W1"</span>]</span><br><span class="line">    b1 = parameters [<span class="string">"b1"</span>]</span><br><span class="line">    W2 = parameters [<span class="string">"W2"</span>]</span><br><span class="line">    b2 = parameters [<span class="string">"b2"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">        A2 , cache = forward_propagation(X,parameters )</span><br><span class="line">        cost = compute_cost(A2,Y,parameters )</span><br><span class="line">        grads = backward_propagation(parameters ,cache,X,Y)</span><br><span class="line">        parameters = update_params(parameters ,grads,lr = <span class="number">0.5</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> print_cost:</span><br><span class="line">            <span class="keyword">if</span> i%<span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"第 "</span>,i,<span class="string">" 次循环，成本为："</span>+str(cost))</span><br><span class="line">                </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><h3 id="出现的问题："><a href="#出现的问题：" class="headerlink" title="出现的问题："></a>出现的问题：</h3><p>根据<a href="https://blog.csdn.net/u013733326/article/details/79702148" target="_blank" rel="noopener">【中文】【吴恩达课后编程作业】Course 1 - 神经网络和深度学习 - 第三周作业</a>的步骤，在测试模型代码时发现与原文不同。</p><p>这是我的结果：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611082222.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611082222.png" alt="image-20200611081307164"></a></p><p>这是原文的结果：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611082252.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611082252.png" alt="image-20200611081331758"></a></p><p>前面的测试结果都一致，这里以为是自己哪一步出了问题导致在打包好的模型函数里调用错误，以至于把代码全改回和原文一致，结果还是不一样。</p><p>最后看评论和与同学进行讨论发现都存在此问题，但用在训练集与测试集时是正常的。</p><p>推测原因应该是此时 numpy相同的随机数种子，生成的随机数却不一样导致的吧。所以现在生成的随机数用在该段代码中会出现错误，如结果提示中的除数为0。</p><h2 id="进行预测"><a href="#进行预测" class="headerlink" title="进行预测"></a>进行预测</h2><h3 id="编写预测函数"><a href="#编写预测函数" class="headerlink" title="编写预测函数"></a>编写预测函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(parameters,X)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">     parameters - 包含模型参数的字典类型的变量。</span></span><br><span class="line"><span class="string">     X - 输入特征（n_x，m）</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">     predictions - 预测的向量（红色：0 /蓝色：1）</span></span><br><span class="line"><span class="string">     """</span></span><br><span class="line">    <span class="comment"># 计算A2</span></span><br><span class="line">    A2 , cache = forward_propagation(X,parameters)</span><br><span class="line">    <span class="comment"># np.round 求平均</span></span><br><span class="line">    predictions = np.round(A2)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> predictions</span><br></pre></td></tr></table></figure><h3 id="查看准确率"><a href="#查看准确率" class="headerlink" title="查看准确率"></a>查看准确率</h3><p>根据博主最后提出的更改隐藏单元数问题，这里设置隐藏单元为5准确率最高，但出于对比，还是设置为了4。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">parameters = nn_model(X, Y, n_h = <span class="number">4</span>, num_iterations=<span class="number">10000</span>, print_cost=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制边界</span></span><br><span class="line">plot_decision_boundary(<span class="keyword">lambda</span> x: predict(parameters, x.T), X, np.squeeze(Y))</span><br><span class="line">plt.title(<span class="string">"隐藏单元数为"</span> + str(<span class="number">4</span>)+<span class="string">"时的决策边界"</span>)</span><br><span class="line"></span><br><span class="line">predictions = predict(parameters, X)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'准确率:'</span>, float((np.dot(Y, predictions.T) + np.dot(<span class="number">1</span> - Y, <span class="number">1</span> - predictions.T)) / float(Y.size) * <span class="number">100</span>),<span class="string">'%'</span>)</span><br></pre></td></tr></table></figure><p>结果：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611082213.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611082213.png" alt="image-20200611082210060"></a></p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达深度学习编程作业1-2</title>
      <link href="/post/202006082233/"/>
      <url>/post/202006082233/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>吴恩达深度学习课程《神经网络和深 度学习》第二周（神经网络基础）的编程作业。</p><a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>感谢作者<a href="https://blog.csdn.net/u013733326" target="_blank" rel="noopener">阿宽</a>提供作业题目<a href="https://blog.csdn.net/u013733326/article/details/79639509" target="_blank" rel="noopener">【中文】【吴恩达课后编程作业】Course 1 - 神经网络和深度学习 - 第二周作业</a></p><p>数据集以及题目可在该博文中查看与下载。</p><p>同时参考了作者<a href="https://blog.csdn.net/iSunwish" target="_blank" rel="noopener">iSunwish</a>的博文<a href="https://blog.csdn.net/iSunwish/article/details/88364097" target="_blank" rel="noopener">深度学习（三）实战：动手实现猫图识别</a></p><p>题目是建立神经网络来通过图片识别猫。虽然说是通过图片来识别，但给出的数据集已经将图片转为矩阵数据存为h5文件。所以读取出来的数据即可直接用来操作，不用进行处理图片的操作。  </p><p>lr_utils.py文件已经实现了对数据的读取，我们要做的就是在代码中执行该文件中的函数来获取返回值即可。</p><p>将下载好的数据集与lr_utils.py 放在与自己的代码相同的文件夹中。</p><p>需要用到的库：</p><ul><li>numpy 数据科学计算的库</li><li>matplotlib 绘图</li><li>h5py 用于交互H5文件（作业的数据集是h5文件）</li><li>scikit-image 用于图像处理  </li></ul><h2 id="查看自带的lr-utils-py文件"><a href="#查看自带的lr-utils-py文件" class="headerlink" title="查看自带的lr_utils.py文件"></a>查看自带的lr_utils.py文件</h2><p>lr_utils.py的代码如下，中文注释为自己添加的说明</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span><span class="params">()</span>:</span></span><br><span class="line"><span class="comment"># 读取训练集数据</span></span><br><span class="line">    train_dataset = h5py.File(<span class="string">'datasets/train_catvnoncat.h5'</span>, <span class="string">"r"</span>)</span><br><span class="line">    <span class="comment"># train_set_x_orig 存储训练集的特征</span></span><br><span class="line">    train_set_x_orig = np.array(train_dataset[<span class="string">"train_set_x"</span>][:]) <span class="comment"># your train set features</span></span><br><span class="line">    <span class="comment"># train_set_y_orig 存储训练集的标签</span></span><br><span class="line">    train_set_y_orig = np.array(train_dataset[<span class="string">"train_set_y"</span>][:]) <span class="comment"># your train set labels</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取测试集数据</span></span><br><span class="line">    test_dataset = h5py.File(<span class="string">'datasets/test_catvnoncat.h5'</span>, <span class="string">"r"</span>)</span><br><span class="line">    <span class="comment"># test_set_x_orig 存储测试集的特征</span></span><br><span class="line">    test_set_x_orig = np.array(test_dataset[<span class="string">"test_set_x"</span>][:]) <span class="comment"># your test set features</span></span><br><span class="line">    <span class="comment"># test_set_y_orig 存储测试集的标签</span></span><br><span class="line">    test_set_y_orig = np.array(test_dataset[<span class="string">"test_set_y"</span>][:]) <span class="comment"># your test set labels</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用classes存储其是猫还是不是猫的二进制字符串（感觉没什么意义？）</span></span><br><span class="line">    classes = np.array(test_dataset[<span class="string">"list_classes"</span>][:]) <span class="comment"># the list of classes</span></span><br><span class="line">    </span><br><span class="line">    train_set_y_orig = train_set_y_orig.reshape((<span class="number">1</span>, train_set_y_orig.shape[<span class="number">0</span>]))</span><br><span class="line">    test_set_y_orig = test_set_y_orig.reshape((<span class="number">1</span>, test_set_y_orig.shape[<span class="number">0</span>]))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes</span><br></pre></td></tr></table></figure><h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载 lr_utils的load_dataset函数</span></span><br><span class="line"><span class="keyword">from</span> lr_utils <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="comment"># 定义变量来获取load_dataset函数的返回值</span></span><br><span class="line">train_set_x , train_set_y , test_set_x , test_set_y , classes = load_dataset()</span><br></pre></td></tr></table></figure><p>执行上述代码后，可以输出变量的shape来查看维度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"训练集特征的维度："</span>,train_set_x.shape,<span class="string">"训练集特征的类型"</span>,type(train_set_x))</span><br><span class="line">print(<span class="string">"训练集标签的维度："</span>,train_set_y.shape,<span class="string">"训练集标签的类型"</span>,type(train_set_y))</span><br><span class="line">print(<span class="string">"测试集特征的维度："</span>,test_set_x.shape,<span class="string">"测试集特征的类型"</span>,type(test_set_x))</span><br><span class="line">print(<span class="string">"测试集标签的维度："</span>,test_set_y.shape,<span class="string">"测试集标签的类型"</span>,type(test_set_y))</span><br><span class="line">print(<span class="string">"classes的维度："</span>,classes.shape,<span class="string">"classes的类型"</span>,type(classes))</span><br></pre></td></tr></table></figure><p>结果：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045854.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045854.png" alt="image-20200608052649184"></a></p><p>可以看到：</p><ul><li>所有变量都是ndarray类型（数组），用数组来表示的矩阵。</li><li>训练集特征一共有209条数据，都是64*64的矩阵（即64x64像素的图片），后面的3表示为图像的RGB三通道（红绿蓝）。</li><li>训练集标签是一维数组，有209个数据。</li><li>测试集特征一共有50条数据，其余与训练集相同。</li><li>测试集标签同训练集标签是一维数组，有50条数据。</li><li>classes的shape为(2,)，其是一个一维数组，有两个数据。</li></ul><p>输出一下classes，即可看到其数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(classes)</span><br></pre></td></tr></table></figure><p>结果为：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045859.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045859.png" alt="image-20200608052714502"></a></p><p>其是一个二进制的值，值为 ‘non-cat’ 或 ’cat’ 。</p><p>若有兴趣也可以输出训练、测试集的特征与标签变量来查看具体的值。</p><h2 id="使用-matplotlib-查看图片（可选）"><a href="#使用-matplotlib-查看图片（可选）" class="headerlink" title="使用 matplotlib 查看图片（可选）"></a>使用 matplotlib 查看图片（可选）</h2><p>吴恩达教授说过，人类擅长处理非结构化数据，而机器擅长处理结构化数据。通过一堆数字我们不能判断这一个样本是一张什么样的图片，故可以使用matplotlib来通过数据绘出原本的图片。</p><p>目前所知，train_set_x里存储的都是图片在计算机上的表示，一共有209个样本。我们可以使用 matplotlib 库的imshow函数来直接绘制图片。这里我使用numpy来生成一个随机数进行随机查看。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">num = np.random.randint(<span class="number">0</span>,<span class="number">209</span>)</span><br><span class="line">print(<span class="string">"第"</span>,num,<span class="string">"个样本的图片为："</span>)</span><br><span class="line">plt.imshow(train_set_x[num])</span><br><span class="line"></span><br><span class="line">print(<span class="string">"其标签为"</span>,np.squeeze(train_set_y)[num],<span class="string">"是一张"</span>,classes[np.squeeze(train_set_y)[num]].decode(<span class="string">"utf-8"</span>),<span class="string">"图片"</span>)</span><br></pre></td></tr></table></figure><p>多次运行后挑选两个结果：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045902.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045902.png" alt="image-20200608011747155"></a>)<a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045907.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045907.png" alt="image-20200608011725392"></a></p><p><strong>注意：</strong></p><ul><li>使用numpy的randint函数来生成一个范围为 [0,209) 的一个随机数，传入的范围是左闭右开区间，且因为是数组所以要从0开始，下标最大值为208，所以应该传入的范围是 0与209。</li><li>numpy的squeeze函数来压缩数组，它会将数组中单维度的条目去掉，进行压缩。比如[[1],[2],[3]] 这是一个维度为(1,3)的数组，压缩后会将无意义的维度去掉，转为[1,2,3]的一维数组。</li><li>classes[X]，指定classes中的值后，要加个decode(“utf-8”)来将原本的二进制数据转为utf-8来输出。否则输出结果会变成 b’cat’ 或者 b’non-cat’ 。（当然仅仅是个人查看的话可以不加）</li></ul><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><h3 id="转换图片的存储方式"><a href="#转换图片的存储方式" class="headerlink" title="转换图片的存储方式"></a>转换图片的存储方式</h3><p>图片在计算机中的存储方式为 像素<em>3 ，而原本的特征矩阵的维度显然不符合该标准，故应该转为维度为（64</em>64*3，209或50）的数组。（训练集为209，测试集为50）</p><p>使用numpy的reshape与 .T 来进行处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_set_x_flatten = train_set_x.reshape(train_set_x.shape[<span class="number">0</span>],<span class="number">-1</span>).T</span><br><span class="line">test_set_x_flatten = test_set_x.reshape(test_set_x.shape[<span class="number">0</span>],<span class="number">-1</span>).T</span><br></pre></td></tr></table></figure><p>以训练集举例：</p><ol><li><p><code>train_set_x.shape[0]</code>出第一个 维数，即样本个数。</p></li><li><p><code>reshap(train_set_x.shape[0],-1)</code>指定行数为样本个数，列数设置为-1让numpy自行计算像素与三色道的组合 。最终转为行数为样本个数，多维数组每一行都是 64<em>64</em>3的图片矩阵 的一个二维数组。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045911.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045911.png" alt="image-20200608013821081"></a></p><p>红框内即图片矩阵，然后一共有209个图片矩阵。此时维度为（209，64<em>64</em>3）</p></li><li><p>最后通过.T来进行转置，变为维度为（64<em>64</em>3，209）的矩阵。然后存储在新变量中。</p></li></ol><p>输出一下看看维度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"转换后的训练集维度："</span>,train_set_x_flatten.shape)</span><br><span class="line">print(<span class="string">"转换后的测试集维度："</span>,test_set_x_flatten.shape)</span><br></pre></td></tr></table></figure><p>结果为：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045914.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045914.png" alt="image-20200608052730484"></a></p><h3 id="转换数据取值范围"><a href="#转换数据取值范围" class="headerlink" title="转换数据取值范围"></a>转换数据取值范围</h3><p>对数值进行归一化 ，将其取值范围定为[0,1]之间。图片数据的处理直接除以255即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_set_x_flatten_normalization = train_set_x_flatten/<span class="number">255</span></span><br><span class="line">test_set_x_flatten_normalization = test_set_x_flatten/<span class="number">255</span></span><br></pre></td></tr></table></figure><h2 id="构建无隐藏层的神经网络"><a href="#构建无隐藏层的神经网络" class="headerlink" title="构建无隐藏层的神经网络"></a>构建无隐藏层的神经网络</h2><h3 id="流程："><a href="#流程：" class="headerlink" title="流程："></a>流程：</h3><ul><li>准备好输入特征</li><li>初始化模型参数</li><li>通过正向传播、反向传播进行梯度下降</li></ul><h3 id="导入numpy库"><a href="#导入numpy库" class="headerlink" title="导入numpy库"></a>导入numpy库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><p>若在[使用 matplotlib 查看图片（可选）](# 使用 matplotlib 查看图片（可选）)中已经导入过numpy库，则直接执行下一步即可。</p><h3 id="定义sigmoid函数"><a href="#定义sigmoid函数" class="headerlink" title="定义sigmoid函数"></a>定义sigmoid函数</h3><p>在吴恩达深度学习的课程中，该作业属于第二周 神经网络基础，故使用的是sigmoid函数，暂时未使用tanh与ReLU函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    a = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br><span class="line">    <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure><h3 id="定义初始化模型参数函数"><a href="#定义初始化模型参数函数" class="headerlink" title="定义初始化模型参数函数"></a>定义初始化模型参数函数</h3><p>模型参数w要与输入特征的维度对应。即w的维度应该为（输入特征x的特征数n_x，1）</p><p>模型参数b的维度应该为 （1，输入特征x的样本数m），不过b可以直接赋值0，利用python广播来计算。</p><p>输入特征x的特征数n_x可以通过 输入特征向量.shape[0]来获得。</p><p>输入特征x的样本数m可以通过 输入特征向量.shape[1]来获得。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialization_parameters</span><span class="params">(nx)</span>:</span></span><br><span class="line"><span class="comment">#     # 随机初始化</span></span><br><span class="line"><span class="comment">#     w = np.random.rand(nx,1)*0.01</span></span><br><span class="line">    w = np.zeros(shape = (nx,<span class="number">1</span>))</span><br><span class="line">    b = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> (w , b)</span><br></pre></td></tr></table></figure><p>这里其实可以用在第三周（浅层神经网络）中的课程 随机初始化中提到的知识点，直接将w初始为随机数。</p><p>但由于没有隐藏层，或者说只有一个输出单元，所以初始化为0或者随机数都一样。</p><p>为了方便与别人的作业观测差距，故这里还是使用了初始化为0。</p><h3 id="关于梯度下降的说明"><a href="#关于梯度下降的说明" class="headerlink" title="关于梯度下降的说明"></a>关于梯度下降的说明</h3><p>先看下伪代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(迭代次数):</span><br><span class="line">Z=np.dot(w.T,X)+b</span><br><span class="line">A=sigmoid(Z)</span><br><span class="line">dz=A-Y</span><br><span class="line">dw=(<span class="number">1</span>/m)*np.dot(X,dz.T)</span><br><span class="line">db=np.sum(dz)/m</span><br><span class="line">w = w - α*dw</span><br><span class="line">b = b - α*db</span><br></pre></td></tr></table></figure><p>目前已知：</p><ul><li>输入特征X</li><li>初始化的参数w与b</li><li>激活函数sigmoid</li><li>输入特征X的个数 m</li></ul><p>可以计算得出：</p><ul><li>dz</li><li>dw</li><li>db</li></ul><p>未知：</p><ul><li>学习率α（需要自定义）</li></ul><p>需要添加：</p><ul><li>代价函数（用于判断是否最小化）</li></ul><p>这里可以在每次梯度下降时都存储一次代价函数的值，用于后面绘图来观测代价函数的变化情况。</p><h3 id="定义梯度下降函数"><a href="#定义梯度下降函数" class="headerlink" title="定义梯度下降函数"></a>定义梯度下降函数</h3><p>关于详细的解释放在了代码中，逐一拿出来说明容易混乱。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 传入参数为：模型参数w、b，训练集的特征、标签，学习率，迭代次数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent</span><span class="params">(w, b, X, Y, alpha, iterations_num)</span>:</span></span><br><span class="line">    <span class="comment"># 获取输入特征个数</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line">    X = X.reshape(X.shape[<span class="number">0</span>], m)</span><br><span class="line">    cost_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(iterations_num):</span><br><span class="line">        <span class="comment"># **正向传播**</span></span><br><span class="line">        Z = np.dot(w.T, X)+b  <span class="comment"># 计算Z</span></span><br><span class="line">        A = sigmoid(Z)  <span class="comment"># 计算激活函数值</span></span><br><span class="line">        cost = (- <span class="number">1</span> / m) * np.sum(Y * np.log(A) +</span><br><span class="line">                                  (<span class="number">1</span> - Y) * (np.log(<span class="number">1</span> - A)))  <span class="comment"># 计算代价函数</span></span><br><span class="line">        <span class="comment"># **正向end**</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># **反向传播**</span></span><br><span class="line">        dz = A-Y  <span class="comment"># 计算dz</span></span><br><span class="line">        dw = (<span class="number">1</span>/m)*np.dot(X, dz.T)  <span class="comment"># 计算dw</span></span><br><span class="line">        db = np.sum(dz)/m  <span class="comment"># 计算db</span></span><br><span class="line">        <span class="comment"># **反向end**</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新参数</span></span><br><span class="line">        w = w-alpha*dw</span><br><span class="line">        b = b-alpha*db</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 每迭代100次存一次代价函数值，并且输出当前的迭代次数与代价函数值</span></span><br><span class="line">        <span class="keyword">if</span>(i % <span class="number">100</span> == <span class="number">0</span>):</span><br><span class="line">            cost_list.append(cost)</span><br><span class="line">            print(<span class="string">"迭代次数："</span>, i, <span class="string">"，代价："</span>, cost)</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># 记录参数，作返回值</span></span><br><span class="line">    param = &#123;</span><br><span class="line">            <span class="string">"costs"</span>: cost_list,</span><br><span class="line">            <span class="string">"w"</span>: w,</span><br><span class="line">            <span class="string">"b"</span>: b,</span><br><span class="line">            <span class="string">"alpha"</span>: alpha</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">return</span> param</span><br></pre></td></tr></table></figure><h3 id="执行梯度下降"><a href="#执行梯度下降" class="headerlink" title="执行梯度下降"></a>执行梯度下降</h3><p>说明一下，训练集特征的维度此时为(12288,209) 课程中表示为 （n_x，m），模型参数w的维度应该为(12288,1) ，这样在计算假设函数Z时，w.T的维度为(1,12288)，符合定义，且能够与 X进行矩阵内积。最后Z的维度为(1,209)，即课程中的 1xm。</p><ol><li>首先获取训练集特征的特征数（非样本数），用nx来存储。</li><li>初始化模型参数w与b。</li><li>进行梯度下降，并用param来接收最后结果的返回值</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过.shape[0]获得训练集输入特征x的特征数</span></span><br><span class="line">nx = train_set_x_flatten_normalization.shape[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 初始化模型参数w与b</span></span><br><span class="line">w, b = initialization_parameters(nx)</span><br><span class="line"><span class="comment"># 执行梯度下降，并用param来获取返回值</span></span><br><span class="line">param = gradient_descent(w, b, train_set_x_flatten_normalization,</span><br><span class="line">                         train_set_y, alpha=<span class="number">0.005</span>, iterations_num=<span class="number">2000</span>)</span><br></pre></td></tr></table></figure><ul><li>alpha为学习率，这是一个自定义的值，需要用户手动选择来输入，目前无法直接确定最优的学习率，现在先通过人为的调试与观察来选择较优的学习率，关于更好的方法日后再讨论。</li><li>iterations_num为迭代次数，也是用户手动输入，但基本有一个阈值，达到迭代次数后，代价函数值就基本不会改变（已最小化或接近最小化）。</li></ul><p>结果：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045922.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045922.png" alt="image-20200608050526192"></a></p><h2 id="进行预测"><a href="#进行预测" class="headerlink" title="进行预测"></a>进行预测</h2><h3 id="定义预测函数"><a href="#定义预测函数" class="headerlink" title="定义预测函数"></a>定义预测函数</h3><p>传入的参数为由梯度下降得到的模型参数w、b，以及进行预测用的输入特征。</p><ul><li>首先初始化向量Y，维度为（1，输入特征的样本数m），用于存放预测结果。</li><li>走一遍逻辑回归模型（计算Z、激活函数A），最后A中的结果即为预测概率。</li><li>如果概率大于0.5，则Y的对应值置为1（表示是猫），否则置为0（表示不是猫）。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(w, b, X)</span>:</span></span><br><span class="line">    Y = np.zeros((<span class="number">1</span>, X.shape[<span class="number">1</span>]))</span><br><span class="line">    Z = np.dot(w.T, X)+b</span><br><span class="line">    A = sigmoid(Z)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(A.shape[<span class="number">1</span>]):</span><br><span class="line">        Y[<span class="number">0</span>][i] = <span class="number">1</span> <span class="keyword">if</span> A[<span class="number">0</span>][i] &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure><h3 id="对训练集与测试集进行预测"><a href="#对训练集与测试集进行预测" class="headerlink" title="对训练集与测试集进行预测"></a>对训练集与测试集进行预测</h3><p>通过param[‘w’]与param[‘b’]即可获得梯度下降结果的模型参数w、b，并将要进行预测的输入特征传入预测函数中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对训练集进行预测</span></span><br><span class="line">train_predict_y = predict(param[<span class="string">'w'</span>], param[<span class="string">'b'</span>], train_set_x_flatten_normalization)</span><br><span class="line"><span class="comment"># 对测试集进行预测</span></span><br><span class="line">test_predict_y = predict(param[<span class="string">'w'</span>], param[<span class="string">'b'</span>],test_set_x_flatten_normalization)</span><br></pre></td></tr></table></figure><h3 id="查看准确率"><a href="#查看准确率" class="headerlink" title="查看准确率"></a>查看准确率</h3><p>采用的准确率公式 ：</p><p>预测的标签值原数据集正确的标签值的绝对值样本个数100−[(预测的标签值−原数据集正确的标签值)的绝对值样本个数]∗100</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"训练集准确率："</span>, format(<span class="number">100</span>-np.mean(np.abs(train_predict_y-train_set_y))*<span class="number">100</span>), <span class="string">"%"</span>)</span><br><span class="line">print(<span class="string">"测试集准确率："</span>, format(<span class="number">100</span>-np.mean(np.abs(test_predict_y-test_set_y))*<span class="number">100</span>), <span class="string">"%"</span>)</span><br></pre></td></tr></table></figure><p>结果：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045929.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045929.png" alt="image-20200608052809376"></a></p><h2 id="观测代价函数变化情况"><a href="#观测代价函数变化情况" class="headerlink" title="观测代价函数变化情况"></a>观测代价函数变化情况</h2><p>使用matplotlib进行绘图，在之前观察图片时已经导入过matplotlib库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置字体，使得能够显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">'font.family'</span>]=<span class="string">'SimHei'</span></span><br><span class="line"><span class="comment"># 设置字体大小</span></span><br><span class="line">fontsize=<span class="number">13</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 传入代价函数数组</span></span><br><span class="line">plt.plot(param[<span class="string">'costs'</span>])</span><br><span class="line"><span class="comment"># 设置y轴标题与y轴字体大小</span></span><br><span class="line">plt.ylabel(<span class="string">'代价函数值'</span>,fontsize=fontsize)</span><br><span class="line">plt.yticks(fontsize=fontsize)</span><br><span class="line"><span class="comment"># 设置x轴标题与x轴字体大小</span></span><br><span class="line">plt.xlabel(<span class="string">'迭代次数（单位：百）'</span>,fontsize=fontsize)</span><br><span class="line">plt.xticks(fontsize=fontsize)</span><br><span class="line"><span class="comment"># 设置图片标题</span></span><br><span class="line">plt.title(<span class="string">"学习率："</span> + str(param[<span class="string">'alpha'</span>]),fontsize=fontsize)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045931.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045931.png" alt="image-20200608053712997"></a></p><h2 id="打包模型"><a href="#打包模型" class="headerlink" title="打包模型"></a>打包模型</h2><p>定义一个函数，用于传入参数后进行构建神经网络并直接返回结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(train_set_x,train_set_y,test_set_x,test_set_y,alpha,iterations_num)</span>:</span></span><br><span class="line">    nx = train_set_x_flatten_normalization.shape[<span class="number">0</span>]</span><br><span class="line">    w, b = initialization_parameters(nx)</span><br><span class="line">    param = gradient_descent(w, b, train_set_x,</span><br><span class="line">                         train_set_y, alpha=alpha, iterations_num=iterations_num)</span><br><span class="line">    train_predict_y = predict(param[<span class="string">'w'</span>], param[<span class="string">'b'</span>], train_set_x)</span><br><span class="line">    test_predict_y = predict(param[<span class="string">'w'</span>], param[<span class="string">'b'</span>],test_set_x)</span><br><span class="line">    print(<span class="string">"训练集准确率："</span>, format(<span class="number">100</span>-np.mean(np.abs(train_predict_y-train_set_y))*<span class="number">100</span>), <span class="string">"%"</span>)</span><br><span class="line">    print(<span class="string">"测试集准确率："</span>, format(<span class="number">100</span>-np.mean(np.abs(test_predict_y-test_set_y))*<span class="number">100</span>), <span class="string">"%"</span>)</span><br><span class="line"></span><br><span class="line">    result=&#123;</span><br><span class="line">        <span class="string">'costs'</span>:param[<span class="string">'costs'</span>],</span><br><span class="line">        <span class="string">'w'</span>:param[<span class="string">'w'</span>],</span><br><span class="line">        <span class="string">'b'</span>:param[<span class="string">'b'</span>],</span><br><span class="line">        <span class="string">'alpha'</span>:param[<span class="string">'alpha'</span>],</span><br><span class="line">        <span class="string">'train_predict_y'</span>:train_predict_y,</span><br><span class="line">        <span class="string">'test_predict_y'</span>:test_predict_y,</span><br><span class="line">        <span class="string">'iterations_num'</span>:param[<span class="string">'iterations_num'</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>将上述流程集合进该函数中，这样只需要传入归一化后的训练集测试集的输入特征、以及训练集测试集的标签，再给定学习率与迭代次数，执行函数后，会输出相应迭代次数的代价（可以在梯度下降函数中将输出代价的代码去掉，简化输出内容），并且返回字典数据类型来存储模型中的一些值。</p><p>如果要进行预测，则执行[定义预测函数](# 定义预测函数)中的预测函数，参数为建模后的w、b，以及要进行预测的数据集的输入特征即可，返回值为预测的标签数组。</p><h2 id="寻找较优学习率（待补充）"><a href="#寻找较优学习率（待补充）" class="headerlink" title="寻找较优学习率（待补充）"></a>寻找较优学习率（待补充）</h2><p>pass</p><h2 id="上传图片进行测试"><a href="#上传图片进行测试" class="headerlink" title="上传图片进行测试"></a>上传图片进行测试</h2><h3 id="安装scikit-image库"><a href="#安装scikit-image库" class="headerlink" title="安装scikit-image库"></a>安装scikit-image库</h3><p>三种安装库的方法。</p><ol><li><p>windows终端命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scikit-image</span><br></pre></td></tr></table></figure></li><li><p>conda终端命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install scikit-image</span><br></pre></td></tr></table></figure></li><li><p>使用Anaconda Navigator进行安装：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045935.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045935.png" alt="image-20200609114326154"></a></p></li></ol><p>安装好后，从skimage中导入io、transform与img_as_ubyte</p><ul><li>io：读取与保存图片</li><li>transform：使用resize转换图片像素</li><li>img_as_ubyte：转换图片数据类型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io,transform,img_as_ubyte</span><br></pre></td></tr></table></figure><h3 id="准备图片"><a href="#准备图片" class="headerlink" title="准备图片"></a>准备图片</h3><p>首先准备好一张图片放在代码文件的同目录下（不在同一个目录也可以，修改path即可）</p><p>以名为cat.jpg的下图为例（百度“猫”，结果第一张）</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050409.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050409.png" alt="cat.jpg"></a></p><p>其像素可以鼠标悬浮在文件上查看，1056*1065</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050415.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050415.png" alt="image-20200609112731831"></a></p><p>然后使用plt的imread函数读取图片。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">'cat.jpg'</span></span><br><span class="line">img = io.imread(path)</span><br><span class="line">print(<span class="string">"读取图片的维度为："</span>,img.shape,<span class="string">"\n输出图片：\n"</span>,img)</span><br></pre></td></tr></table></figure><p>结果为：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050417.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050417.png" alt="image-20200609112602562"></a></p><p>可以看到其存储方式为 (像素，3)，3即三色道矩阵。</p><h3 id="转换图片像素并归一化"><a href="#转换图片像素并归一化" class="headerlink" title="转换图片像素并归一化"></a>转换图片像素并归一化</h3><p>使用transform.resize来转换图片的像素，使其与训练集的图片像素一致。</p><p>transform.resize会自动对图片的值进行归一化。</p><p>需要注意的是transform.resize会将图片的值的数据类型转为float，故使用img_as_ubyte函数转回uint8</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">px = train_set_x.shape[<span class="number">1</span>]</span><br><span class="line">image = transform.resize(img,(px,px))</span><br><span class="line">image = img_as_ubyte(image)</span><br></pre></td></tr></table></figure><h3 id="转为对应输入特征x的存储方式。"><a href="#转为对应输入特征x的存储方式。" class="headerlink" title="转为对应输入特征x的存储方式。"></a>转为对应输入特征x的存储方式。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_flatten = img.reshape(<span class="number">1</span>,<span class="number">-1</span>).T</span><br><span class="line">print(X_flatten.shape)</span><br></pre></td></tr></table></figure><p>即 （64<em>64</em>3，1），这样就与训练集的输入特征x的存储方式一致了。</p><h3 id="对上传图片进行预测"><a href="#对上传图片进行预测" class="headerlink" title="对上传图片进行预测"></a>对上传图片进行预测</h3><p>假若已经建立好模型（得到模型变量model），则直接执行[进行预测](# 进行预测)中的流程即可。</p><p>需要注意的是返回值Y是一个维度为（1，m）的向量。m为输入特征的样本数，故查看结果使用<code>Y[0][0]</code>即可。</p><p>若是多张图片则需要遍历查看对应的预测值，或直接输出Y来观察预测值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Y = predict(model[<span class="string">'w'</span>],model[<span class="string">'b'</span>],X)</span><br><span class="line">result = int(Y[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">print(<span class="string">"预测值为："</span>,result,<span class="string">"\n这是一张 "</span>,classes[result].decode(<span class="string">'utf-8'</span>),<span class="string">" 图片"</span>)</span><br></pre></td></tr></table></figure><p><del>classes这个返回值我终于用上了</del></p><p>预测结果</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050420.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050420.png" alt="image-20200609124045755"></a></p><h3 id="打包预测上传图片代码"><a href="#打包预测上传图片代码" class="headerlink" title="打包预测上传图片代码"></a>打包预测上传图片代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io,transform,img_as_ubyte</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_cat</span><span class="params">(path)</span>:</span></span><br><span class="line">    img = io.imread(path)</span><br><span class="line">    px = train_set_x.shape[<span class="number">1</span>]</span><br><span class="line">    image = transform.resize(img,(px,px))</span><br><span class="line">    image = img_as_ubyte(image)/<span class="number">255</span></span><br><span class="line">    X_flatten = image.reshape(<span class="number">1</span>,<span class="number">-1</span>).T</span><br><span class="line">    </span><br><span class="line">    Y = predict(model[<span class="string">'w'</span>],model[<span class="string">'b'</span>],X_flatten)</span><br><span class="line">    result = int(Y[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">    print(<span class="string">"预测值为："</span>,result,<span class="string">"\n这是一张 "</span>,classes[result].decode(<span class="string">'utf-8'</span>),<span class="string">" 图片"</span>)</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>准备了两张猫的图片，两张狗的图片，一张马，一张豹子，一张白菜，一张纯黑色的图，一张纯白色的图。</p><p>结果预测为猫的有一张猫的图片，豹子、纯黑与纯白的图。</p><p>准确率还是不够高，后尝试通过更改学习率进行优化。</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Valine配置邮件与QQ提醒</title>
      <link href="/post/202005292233/"/>
      <url>/post/202005292233/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>valine在配置好后没有邮件提醒功能，需要到<a href="https://www.leancloud.cn/" target="_blank" rel="noopener">LeanCloud</a>登陆控制台进行一系列设置。</p><p>最开始是只想配置个邮件提醒，但直到看到了这位大佬的博文</p><p><a href="https://www.antmoe.com/posts/2380732b/index.html" target="_blank" rel="noopener">Valine评论之Valine-admin配置攻略</a></p><p>该版本基于Valine-admin的二次开发，加入了微信提醒、QQ提醒功能。</p><p>因为个人常用QQ，微信很少登陆，故只配置了QQ提醒功能。微信提醒的配置方法与QQ类似。</p><p>QQ消息推送机器人：<a href="https://qmsg.zendee.cn/" target="_blank" rel="noopener">Qmsg酱</a></p><p>本文基于上述配置攻略博文，详细记录自己的配置过程。请先确定自己已经配置好了基础的valine评论服务。</p><a id="more"></a><h2 id="获取Qmsg酱的key"><a href="#获取Qmsg酱的key" class="headerlink" title="获取Qmsg酱的key"></a>获取Qmsg酱的key</h2><p>进入官网<a href="https://qmsg.zendee.cn/" target="_blank" rel="noopener">Qmsg酱</a>，使用QQ号一键登录即可。</p><p>在首页如下</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015227.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015227.png" alt="image-20200528185730555"></a></p><p>添加完成后，打开你添加的QQ号，<strong>添加机器人为好友</strong></p><p>选了哪个就加哪个为好友，添加好友后是自动通过的，不加好友怎么收到提醒呢。</p><hr><p>接下来到右上角点击文档，</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015233.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015233.png" alt="image-20200528185920380"></a></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015242.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015242.png" alt="image-20200528190006620"></a></p><p>复制接口地址后面的key值， 即<code>send/</code> 后面的所有字符，可以暂时将该key记录在笔记本等位置，稍后配置要用。</p><h2 id="配置valine实例"><a href="#配置valine实例" class="headerlink" title="配置valine实例"></a>配置valine实例</h2><h3 id="云引擎部署"><a href="#云引擎部署" class="headerlink" title="云引擎部署"></a>云引擎部署</h3><p><a href="https://leancloud.cn/" target="_blank" rel="noopener">Leancloud官网</a>，进入后登陆到自己的控制台。进入自己创建的应用。然后进入云引擎/部署</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015251.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015251.png" alt="image-20200528191403112"></a></p><p>大佬二次开发的valine-admin-server的github地址：<a href="https://github.com/sviptzk/Valine-Admin-Server" target="_blank" rel="noopener">https://github.com/sviptzk/Valine-Admin-Server</a></p><p>在下面的部署中的Deploy from中填入该地址。</p><p><strong>注：若是打算自己定义邮件通知的模板或者QQ提醒的模板的，fork一份到自己的github来修改。</strong></p><p><strong>这样填入的地址使用fork到自己github中的地址，后面修改模板时修改代码即可。</strong></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015255.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015255.png" alt="image-20200528191440296"></a></p><p>填入后点击部署。出现如下所示的log信息（最后提示1个实例部署成功）即可。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200528015233.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200528015233.png" alt="image-20200528015231941"></a></p><h3 id="设置变量"><a href="#设置变量" class="headerlink" title="设置变量"></a>设置变量</h3><p>进入到云引擎/设置中</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015307.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015307.png" alt="image-20200528191931864"></a></p><p>在页面中添加新变量</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015310.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015310.png" alt="image-20200528191921578"></a></p><p>首先添加几个基本变量：</p><p>括号中说明根据使用情况来选填，没有括号的为必填项。</p><table><thead><tr><th>变量名</th><th>变量值</th><th>变量值举例</th></tr></thead><tbody><tr><td>ADMIN_URL</td><td>博客网址</td><td><a href="https://lluuiq.com/">https://lluuiq.com</a></td></tr><tr><td>QMSG_KEY</td><td>（使用QQ提醒必填）之前获得的Qmsg的key</td><td>7b04XXXXXXXXfc5</td></tr><tr><td>QQ</td><td>（使用QQ提醒必填）Qmsg中添加的自己的QQ号</td><td>844520941</td></tr><tr><td>QQ_SHAKE</td><td>（想在提醒时被戳一下就设置）是否开启QQ提醒时戳一戳</td><td>true</td></tr><tr><td>SENDER_NAME</td><td>发件人昵称</td><td>lluuiq</td></tr><tr><td>SITE_NAME</td><td>博客网站名称</td><td>lluuiq’s Blog</td></tr><tr><td>SITE_URL</td><td>网站地址</td><td><a href="https://lluuiq.com/">https://lluuiq.com</a></td></tr><tr><td>SMTP_SERVICE</td><td>SMTP服务器提供商</td><td>163</td></tr><tr><td>SMTP_PASS</td><td>SMTP授权码</td><td>CSTXXXXXXXOUC</td></tr><tr><td>SMTP_USER</td><td>用于发邮件的邮箱，需要与SMTP服务商对应</td><td><a href="mailto:lluuiq@163.com">lluuiq@163.com</a></td></tr><tr><td>TEMPLATE_NAME</td><td>邮件模板</td><td>custom2</td></tr><tr><td>TO_EMAIL</td><td>（在valine评论填邮箱的情况下好像没什么用，但是可以加上用于后面自定义邮件模板时使用）博主的收件邮箱</td><td><a href="mailto:mail@lluuiq.com">mail@lluuiq.com</a></td></tr></tbody></table><p>一些说明：</p><ul><li><p><strong>ADMIN_URL</strong>：开启网页后台管理功能才需要添加的变量，若不需要通过网页来管理的话可以不加，因为可以登陆LeanCloud来进行管理，开启方法后面介绍。</p></li><li><p><strong>QQ</strong>：自己接收消息的QQ号，要存在之前获取key时添加的QQ列表中</p></li><li><p><strong>SMTP_SERVICE</strong>：这是valine支持的一些服务商：<a href="https://nodemailer.com/smtp/well-known/#supported-services" target="_blank" rel="noopener">Supported</a>，选择对应的服务商后，要更改对应的发件邮箱与授权码，关于授权码的获取方法各个服务商的直接百度即可，后面我以网易163的举例。</p><p>关于为什么使用网易，我使用QQ邮箱结果发件一直<code>550 mail content denied</code>，被腾讯服务器当成垃圾广告邮件给退回，故换成了163邮箱。想使用QQ邮箱来接收消息的话，可以设置163邮箱的自动转发。</p></li><li><p><strong>SMTP_PASS</strong>：163为例的获取方法，点击<a href="https://lluuiq.com/post/202005290137/?t=1593036314039#获取SMTP授权码，并设置自动转发（以163举例）">获取SMTP授权码，并设置自动转发（以163举例）</a>跳转到下方查看。</p></li><li><p><strong>TEMPLATE_NAME</strong>：valine自带的主题有默认default、彩虹rainbow，该版本新增的有custom1、custom2，其中custom2的样式如下：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015313.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015313.png" alt="image-20200528193512145"></a></p><p>当然，如果是fork的主题的话，这个是可以自行修改的，后面再讲自己的修改过程。</p></li></ul></br><p><strong>注意事项：</strong></p><p>我没有配置垃圾过滤、微信提醒。以及并没有使用自定义服务商（我配置的总是失败，想使用自定义服务商的可以参考原博文进行配置 ）。</p><p>每次修改变量后，点击保存后是<strong>不会生效</strong>的。需要重新部署一次云引擎（回到<a href="https://lluuiq.com/post/202005290137/?t=1593036314039#云引擎部署">云引擎部署</a>，不用重新填github地址，直接点击部署即可）。</p><p>配置完成后并且重新部署后，即可尝试在valine评论里发送一条评论来进行尝试。</p><p>博主收到的效果：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015319.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015319.png" alt="image-20200528201032449"></a></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015322.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015322.png" alt="image-20200528201058382"></a></p><p>访客收到的效果：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015325.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015325.png" alt="image-20200528201143027"></a></p><p>这是默认的模板，若需要修改的话后面有介绍。</p><h2 id="休眠策略配置"><a href="#休眠策略配置" class="headerlink" title="休眠策略配置"></a>休眠策略配置</h2><p>LeanCloud现在每天必须停机6个小时，并且若30分钟内无访问会自动休眠。</p><p>详细的配置方法还是建议参考原文<a href="https://www.antmoe.com/posts/2380732b/index.html" target="_blank" rel="noopener">Valine评论之Valine-admin配置攻略</a> 。</p><h4 id="自动唤醒任务"><a href="#自动唤醒任务" class="headerlink" title="自动唤醒任务"></a>自动唤醒任务</h4><p>登陆该网址：<a href="https://cron-job.org/" target="_blank" rel="noopener">https://cron-job.org/</a></p><p>注册帐号后，创建任务。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015327.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015327.png" alt="image-20200528231230639"></a></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015603.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015603.png" alt="image-20200529011449656"></a></p><p>第一个title 就是给这个任务起个名字，随意填</p><p>第二个http链接输入LeanCloud的后台管理地址，例如我通过<code>https://abc.lluuiq.com</code>来进入后台，则填进去</p><p>时间使用自定义，然后日、星期、月都全选（先选中第一个，然后拉到最下面按shift点一下最后一个）</p><p>小时我选择的是7点到23点，详细根据自己需要来设置，总之中间要有6小时的时间让LeanCloud停机</p><p>分钟可以使用ctrl键来选择多个，我设置的是0、10、20、30、40、50，即在0分、10分、20分。。的时候访问一次后台。</p><p>这样设置的结果就是每天的7:00开始到晚上12:00，每隔10分钟进行一次访问来唤醒机器。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015333.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015333.png" alt="image-20200529011825115"></a></p><p>最后如果要保存日志则勾选Save responses，创建任务即可。</p><p>创建完成后，任务列表会出现目前进行的任务。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015336.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015336.png" alt="image-20200529011908143"></a></p><p>点击右方的History可以查看历史状态的信息</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015338.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015338.png" alt="image-20200529011955085"></a></p><p>前面有对号的标志即表示成功访问了后台，后面可以看到具体的时间以及状态码等等。</p><h4 id="重发邮件任务"><a href="#重发邮件任务" class="headerlink" title="重发邮件任务"></a>重发邮件任务</h4><p>使用LeanCloud自带的定时任务来完成即可。进入云引擎/定时任务</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015340.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015340.png" alt="image-20200529012155255"></a></p><p>创建定时任务，</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015342.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015342.png" alt="image-20200529012305308"></a></p><p>关于Cron表达式，因为我设置的是每天7点到晚上12点之间来不停唤醒机器，所以我的表达式为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 5 7 * * *</span><br></pre></td></tr></table></figure><p>秒 分 时 天 月 星期，假如Cron表达式为 a b c d e f</p><p>则在 e月份的第d天的c时b分a秒，且仅为星期f时进行该任务。 *表示全部。</p><p>所以我的表达式意思为 在每天的7点05分0秒时，进行resend_mails函数，即检测未发送的邮件进行补发。</p><p>这样就解决了在0点到7点机器停机时假如有回复不能进行提醒的问题。</p><p>（目前仅是理论，因为并未实际测试过）</p><h4 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h4><p>上述配置已成功。7点05收到了邮件补发。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529070827.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529070827.png" alt="image-20200529070819358"></a></p><p>查看日志可以发现</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200531142056.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200531142056.png" alt="image-20200531142051117"></a></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200531141900.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200531141900.png" alt="image-20200531141847831"></a></p><h2 id="获取SMTP授权码，并设置自动转发（以163举例）"><a href="#获取SMTP授权码，并设置自动转发（以163举例）" class="headerlink" title="获取SMTP授权码，并设置自动转发（以163举例）"></a>获取SMTP授权码，并设置自动转发（以163举例）</h2><p>登陆<a href="https://mail.163.com/" target="_blank" rel="noopener">163邮箱</a>，注意登陆的邮箱必须要是变量SMTP_USER填的值。</p><p>在设置里可以找到<code>POP3/SMTP/IMAP</code></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015346.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015346.png" alt="image-20200528194857850"></a></p><p>随便开启一个服务，主要是需要SMTP服务，IMAP与POP3无所谓。</p><p>我记得是开启时就会获得授权码，该授权码即为SMTP_PASS的值。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015348.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015348.png" alt="image-20200528195001992"></a></p><p>也可以在下面添加新的授权码</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015350.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015350.png" alt="image-20200528200300874"></a></p><p>在设置里的常规设置中,找到自动回复/转发</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015352.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015352.png" alt="image-20200528194813459"></a></p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015354.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015354.png" alt="image-20200528200338330"></a></p><p>填写转发到哪个邮箱，然后验证一下即可。若打算在该邮箱内保留邮件，则勾选保留原邮件。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015356.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015356.png" alt="image-20200528200356454"></a></p><p>配置好后返回 <a href="https://lluuiq.com/post/202005290137/?t=1593036314039#设置变量">设置变量</a>继续配置即可。</p><h2 id="以下有需要则看"><a href="#以下有需要则看" class="headerlink" title="====以下有需要则看===="></a>====以下有需要则看====</h2><h2 id="开启网页后台管理"><a href="#开启网页后台管理" class="headerlink" title="开启网页后台管理"></a>开启网页后台管理</h2><p>需要有个域名，进入设置里的域名绑定</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015358.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015358.png" alt="image-20200528202131169"></a></p><p>这里因为我已经绑定过，所以显示的不一样，总之点击绑定新域名的那个按键。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015401.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015401.png" alt="image-20200528202237785"></a></p><p>二级域名可以自定义 ，例如 abc.lluuiq.com，我的域名是lluuiq，二级域名为abc。</p><p>这里就填个abc.lluuiq.com，稍后到域名管理处进行解析。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015402.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015402.png" alt="image-20200528202409331"></a></p><p>填好后大概会稍等一会，然后会给出CNAME记录值。记录值为<code>CNAME:</code>后面的内容，即</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kkfwnugs.cn-n1-cname.leanapp.cn</span><br></pre></td></tr></table></figure><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015405.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015405.png" alt="image-20200528202542704"></a></p><p>接下来到域名管理处进行解析CNAME</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015407.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015407.png" alt="image-20200528202747129"></a></p><p>解析完成后，并且在设置变量中有添加ADMIN_URL的话，即可通过 <code>https://绑定的云引擎域名</code> 来进行访问</p><p>需要注意的是开启了自动管理SSL才能使用https访问，否则只能通过http访问。</p><p>在访问之前，先登陆<code>https://绑定的云引擎域名/sign-up</code>注册一个管理员帐号</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015409.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015409.png" alt="image-20200528211613911"></a></p><p>邮箱是SMTP设置的邮箱，无法修改。</p><p>登录名使用只读里面的邮箱（登陆时要输入邮箱，我用自定义的昵称无法登陆，并且只能让登录名等于只读中的邮箱才有效。。），密码自定义。这样登录名即为SMTP的邮箱，密码为自定义的密码。</p><p>确认设置后，再通过<code>https://绑定的云引擎域名</code>来登陆，即可访问后台。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015412.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015412.png" alt="image-20200528212716610"></a></p><p>管理界面如图所示，样式可以更改，参考<a href="https://lluuiq.com/post/202005290137/?t=1593036314039#修改右键、QQ提醒的模板">修改右键、QQ提醒的模板</a>去修改后台管理的即可。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015414.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015414.png" alt="image-20200528212738206"></a></p><h2 id="修改邮件、QQ提醒的模板"><a href="#修改邮件、QQ提醒的模板" class="headerlink" title="修改邮件、QQ提醒的模板"></a>修改邮件、QQ提醒的模板</h2><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>修改的前提是在<a href="https://lluuiq.com/post/202005290137/?t=1593036314039#云引擎部署">云引擎部署</a>中使用的github地址是fork的地址。</p><p>克隆fork的代码仓库到本地，对文件进行修改。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015419.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015419.png" alt="image-20200528214044654"></a></p><ul><li>public/stylesheets中的css文件是 views/comments.ejs的样式表</li><li>template内的文件夹名即<a href="https://lluuiq.com/post/202005290137/?t=1593036314039#设置变量">设置变量</a>中的<code>TEMPLATE_NAME</code>的值，引入对应的模板。这里我copy了一份custom2文件夹重命名为lluuiq来进行自定义，保证原本样式的情况下来修改。</li><li>check-spam.js为过滤邮件的脚本，基本不用管。</li><li>send-mail.js中设置QQ提醒的模板，并且可以修改发送邮件时的一些设置和邮件标题</li><li>其余的能不动就不动。</li></ul><p><strong>其余说明：</strong></p><ul><li>最好copy一份主题文件到新的文件夹中来对副本进行修改，这样能保持原主题的内容。</li><li>详细的修改可以自己尝试，可以重写一份页面来全面替换，这里例举个人对原有的主题进行修改的内容。</li><li>以下出现的process.env.XXX 表示获取云引擎设置的变量名内容。</li><li>&lt;%=XXX%&gt;为获取send-email.ejs里的对应代码块的变量。notice.ejs获取站长提醒的，send.ejs获取访客提醒的。</li><li>修改完后，要提交和push到github上，然后LeanCloud的云引擎再重新部署才能生效。</li></ul><h3 id="修改发送邮件的标题"><a href="#修改发送邮件的标题" class="headerlink" title="修改发送邮件的标题"></a>修改发送邮件的标题</h3><h4 id="站长邮件提醒"><a href="#站长邮件提醒" class="headerlink" title="站长邮件提醒"></a>站长邮件提醒</h4><p>打开utilities/send-mail.js</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015427.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015427.png" alt="image-20200528214657413"></a></p><p>站长自己发的评论不需要通知的内容为 comment.get(“mail”)来获取新评论的邮箱，如果是站长自己的邮箱则不发送邮件，毕竟自己回复别人干嘛发邮件来提醒自己。（QQ也不会提醒）</p><p>这里因为我设置了163邮箱的转发，所以SMTP_USER=163邮箱，但自己使用的不是这个邮箱。所以如果不进行其他设置的话，这段代码不会生效。这也是为什么当时加了TO_EMAIL变量指向自己的邮箱。当判定获取的邮箱为自己的邮箱时，就不会再进行提醒。</p><p>如果设置的SMTP_USER邮箱与自己接收提醒的邮箱为同一个，那么TO_EMAIL就可以去掉，这部分就不用管了。</p><hr><p>第二个红框的部分，emailSubject为邮件的主题，可以根据自己的喜好来进行修改。</p><p>我在修改主题的下方的变量名中添加了一个变量senderName来获取LeanCloud中的SENDER_NAME变量，用来当自己的昵称，可以放在邮件提醒里的称呼中，也可以放在结尾的 <code>@2020 lluuiq</code> 中。</p><p>其余的部分为LeanCloud的日志输出内容，可以不用管，想修改输出信息的可以进行修改。</p><h4 id="访客邮件提醒"><a href="#访客邮件提醒" class="headerlink" title="访客邮件提醒"></a>访客邮件提醒</h4><p>还是在utilities/send-mail.js中，代码块在下方，注意和站长提醒的类似，但代码是不一样的。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015430.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015430.png" alt="image-20200528215622357"></a></p><p>站长被@不需要提醒，是当访客回复自己时不触发这个回复提醒（毕竟站长提醒那里已经发一次了）。</p><p>第二个红框同上来修改 发送给访客的 邮件的 主题。</p><p>其余同上为输出日志，想修改的自行修改即可。</p><h3 id="修改QQ提醒的模板"><a href="#修改QQ提醒的模板" class="headerlink" title="修改QQ提醒的模板"></a>修改QQ提醒的模板</h3><p>还是utilities/send-mail.js里。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015433.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015433.png" alt="image-20200528220435859"></a></p><p>第一个红框的部分为戳一戳功能，基本不用修改。</p><p>第二个红框的部分为QQ机器人发送消息的模板，<strong>这里是我修改之后的样子</strong>，原来的样式是有一堆QQ表情的，我给删除了，并添加一些语句。[CQ:face,id=63]为鲜花表情，详细的id可以百度搜索。</p><p>$(text) 获取评论内容、$(url) 获取文章地址 、axios.get() 调用Qmsg接口 。。。等这样的内容就不用修改了。</p><p>最后一个红框是输出日志，不管就行了。</p><p>微信的模板修改与QQ的同理，找到对应的内容进行修改即可。</p></br><p>我修改后的简约提醒模板如图：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200531142344.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200531142344.png" alt="image-20200531142340361"></a></p><h3 id="修改发送邮件的内容模板"><a href="#修改发送邮件的内容模板" class="headerlink" title="修改发送邮件的内容模板"></a>修改发送邮件的内容模板</h3><h4 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h4><p>内容模板都在template/主题文件夹 中，若在原主题上进行修改则进入对应文件夹修改ejs文件就行了。这里我copy的custom2来进行修改的。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015436.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015436.png" alt="image-20200528221841902"></a></p><p>notice.ejs为发送给自己的评论提醒模板。</p><p>send.ejs为发送给访客的评论回复模板。</p><h4 id="站长提醒"><a href="#站长提醒" class="headerlink" title="站长提醒"></a>站长提醒</h4><p>进入notice.ejs</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015438.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015438.png" alt="image-20200528223121881"></a></p><p>其中需要说明的是&lt;%=sendName%&gt;，为获取在<a href="https://lluuiq.com/post/202005290137/?t=1593036314039#站长邮件提醒">站长邮件提醒</a>里设置的sendName变量。</p><p>注意notice.ejs获取的是站长邮件提醒的代码块的内容。</p><p>稍后的send.ejs获取的是访客邮件提醒的代码块内容，也就是说如果访客邮件提醒的代码块里没有设置这个变量。那么send.ejs里使用&lt;%=sendName%&gt;是无效的，并且不会发送邮件给访客。（当初发现没有发邮件找了好久的原因，后来才发现是没在访客的代码块里添加该变量）</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015441.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015441.png" alt="image-20200528224442093"></a></p><p>部分获取评论内容的东西就不用修改，修改一些自己想要的样式什么的就行了。</p><p>从这里再往下基本都是CSS，修改样式的。</p><p>效果图：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015443.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015443.png" alt="image-20200528230358526"></a></p><h4 id="访客提醒"><a href="#访客提醒" class="headerlink" title="访客提醒"></a>访客提醒</h4><p>进入send.ejs</p><p>代码内容与notice.ejs几乎一模一样，但是要注意的这里的内容是让访客看到的，根据自己喜好来修改或添加想让访客收到回复时看到的内容就行了。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015446.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015446.png" alt="image-20200528224731789"></a></p><p>Dear &lt;%=pname%&gt;为 Dear 访客昵称。</p><p>我删掉了原来的h3标签，因为显得过于冗余了，直奔主题显示曾经的评论、收到的回复。</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015449.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015449.png" alt="image-20200528225041802"></a></p><p>这里在页脚处添加了一些信息，注意copy原来的<p>标签语句后把id去掉，html里的id只能有一个。</p><p>效果图：</p><p><a href="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015451.png" target="_blank" rel="noopener"><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200529015451.png" alt="image-20200528230322245"></a></p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Valine </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CLion配置成LeetCode做题工具</title>
      <link href="/post/202004071321/"/>
      <url>/post/202004071321/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>LeetCode自带的编译感觉并不好用，而且代码补全与提示是收费，故使用本地IDE作为LeetCode做题的工具。</p><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>关于CLion的C/C++环境配置在另一篇文章里有说明。</p><p>PyCharm、intellij IDEA等JetBrains公司的IDE都可以使用相同的配置流程。 </p><h2 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h2><p>leetcode-editor：</p><p>打开CLion设置，在Plugins搜索leetcode即可找到插件：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407133543.png" alt="image-20200407133534599"></p><p>若网速过慢，或无法下载，也可以下载压缩包然后加载本地插件来安装。</p><p>在Git Hub的Releases下载插件压缩包 <a href="https://github.com/shuzijun/leetcode-editor" target="_blank" rel="noopener">https://github.com/shuzijun/leetcode-editor</a></p><p>在JetBrains的插件库下载压缩包 <a href="https://plugins.jetbrains.com/plugin/12132-leetcode-editor" target="_blank" rel="noopener">https://plugins.jetbrains.com/plugin/12132-leetcode-editor</a></p><p>下载完成后在Plugins的上方点击齿轮处，选择Install Plugin from Disk，然后选择下载的压缩包路径安装即可。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407133737.png" alt="image-20200407133724459"></p><h2 id="配置插件"><a href="#配置插件" class="headerlink" title="配置插件"></a>配置插件</h2><p>leetcode editor <a href="https://github.com/shuzijun/leetcode-editor/blob/master/README_ZH.md" target="_blank" rel="noopener">中文文档</a></p><p>安装好插件后，在IDE的右方侧边栏的下方，可以打开leetcode editor</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407135439.png" alt="image-20200407135437696"></p><p>打开后先点击齿轮进入配置</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407135504.png" alt="image-20200407135502970"></p><p>也可以通过 <code>settings -&gt; Tools -&gt;leetcode plugin</code>进入设置。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407135727.png" alt="image-20200407135725899"></p><p>URL选择境内还是境外的leetcode</p><ul><li><p>Code Type选择C语言（若是其他环境的IDE选择对应语言）</p></li><li><p>LoginName输入登陆的用户名（邮箱）和密码</p></li><li><p>TempFilePath为存放代码的位置，注：选择路径后，会创建<code>leetcode\editor\cn</code>目录来将代码存放在cn，例如我选择路径<code>D:\code\</code>，则会生成路径``D:\code\leetcode\editor\cn`，然后将题目代码放在cn文件夹下</p></li><li><p>LevelColour为划分题目难度的颜色设置，默认即可，也可以修改。</p></li><li><p>CodeFileName为创建题目代码时的文件名，默认为<code>[题目标号]题目名.c</code>，如：<code>[1]两数之和.c</code></p></li><li><p>CodeTemplate为代码编辑处的默认模板，先是题目描述，然后是题目给的默认代码</p><p>两部分都可以根据下方给出的参数来修改模板</p></li></ul><hr><p><strong>注：若需要Debug，则先创建一个project，然后将TempFilePath的路径改为该项目。推荐设置项目名为leetcode，然后将TempFilePath设置为项目的父级文件夹，这样可以少一层插件创建的leetcode文件夹</strong></p><p>例如：我在D:/code下创建一个project名为leetcode，然后插件的路径改为D:/code，则生成路径为下图：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407141640.png" alt="image-20200407141639456"></p><p>但如果我的项目名不是leetcode，然后插件路径设置为D:/code/项目名，则效果为下图：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407142015.png" alt="image-20200407142014111"></p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407142041.png" alt="image-20200407142039705"></p><p>可以看到插件自己生成了leetcode文件夹来当做父级目录</p><hr><p>回到正题，配置完成后保存，然后点击第一个图标登录</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407140500.png" alt="image-20200407140451560"></p><p>若有提示使用cookie登录，则进入LeetCode，按F12点击加载的文件，找到cookie复制粘贴然后login即可</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407140801.png" alt="image-20200407140759524"></p><p>登陆成功后便会刷新出题目，可以浏览全部题目</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407140956.png" alt="image-20200407140830680"></p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407140954.png" alt="image-20200407140951578"></p><p>也可以根据难度、做题状态、以及一些活动来获取题目</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407141000.png" alt="image-20200407140932410"></p><h2 id="配置Debug"><a href="#配置Debug" class="headerlink" title="配置Debug"></a>配置Debug</h2><p>因leetcode给的默认代码为一个类或一个方法，因此需要自己编写main()函数来调用函数，实现Debug。</p><h3 id="自定义代码块"><a href="#自定义代码块" class="headerlink" title="自定义代码块"></a>自定义代码块</h3><p>详细参考：<a href="https://lluuiq.com/post/202003300841/?t=1586250575670">Pycharm自定义模板</a> </p><p>打开设置，搜索<code>Live Templates</code>，进入自定义代码块配置，选择C/C++，点击+号添加模块，这里我已经添加过一个<code>main</code>和一个<code>lmain</code>，默认是没有的。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407171114.png" alt="image-20200407171040815"></p><p>填入缩写、描述以及代码块，下方的Applicable选择C。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407171147.png" alt="image-20200407171145352"></p><p>这里的代码块在调用后，会按$No$（题号）、$FILE$（题目名）、$CODE$（代码块）的顺序进行填写，填写完一项后按TAB切换到下一项，参数的名称是自定义的 。</p><p>关于<code>#include &quot;editor/cn/[$No$]$FILE$.c&quot;</code>，调用目标.c文件，其中文件名应与配置插件时的自定义名称的格式相同。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"stdio.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"editor/cn/[$No$]$FILE$.c"</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    $CODE$</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样当以后想对一道题进行Debug时，只需要新建一个.c文件，然后输入lmain调用该代码块，填写题号和题目后就可以编写对应代码然后调用题目中的函数了，Java、Python应该是调用类 。接下来就是解决C语言一个项目只能有一个main()函数的问题，需要修改CMakeLists。</p><h3 id="实现多个main-函数文件"><a href="#实现多个main-函数文件" class="headerlink" title="实现多个main()函数文件"></a>实现多个main()函数文件</h3><p>添加一个<code>add_executable</code>，内容可以看到前面为一个项目名，后方为main函数的文件</p><p>这个项目名可以不存在，但需要与其他项目名不同，故可以在项目名后方加上数字来表示第几题即可，.c文件的名字自定义就行。这样以后想Debug时只需要在项目中新建一个.c文件，生成自定义代码块然后调用题目代码，编译前添加到CMakeLists即可。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407170825.png" alt="image-20200407170824491"></p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CLion </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CLion配置C/C++开发环境</title>
      <link href="/post/202004062233/"/>
      <url>/post/202004062233/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>记录配置CLion的过程</p><a id="more"></a><h2 id="安装MinGW"><a href="#安装MinGW" class="headerlink" title="安装MinGW"></a>安装MinGW</h2><p>MinGW下载地址：<a href="https://osdn.net/projects/MinGW/releases/" target="_blank" rel="noopener">MinGW</a></p><p>在中间点击图标下载windows版</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406015858.png" alt="image-20200406015857057"></p><p>下载后打开安装，一直下一步最后安装完成后点击Continue。</p><p>在打开的界面中，<code>Basic Setup</code>中勾选<code>MinGW32-gcc-g++-bin</code>。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406225159.png" alt="image-20200406224030801"></p><p>然后进入<code>All Packages</code>，找到<code>mingw32-make-bin</code>勾选。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406225203.png" alt="image-20200406224255010"></p><p>然后点击菜单栏的<code>Installation -&gt;  Apply Changes</code>安装勾选的包</p><p>安装完成后点击Close关闭即可。</p><p>若不小心安装后关掉了或者没有自动打开MinGW，可以在MinGW的安装目录中打开bin文件夹下的</p><p><code>MinGW-get.exe</code></p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406225207.png" alt="image-20200406020903397"></p><h2 id="报错问题"><a href="#报错问题" class="headerlink" title="报错问题"></a>报错问题</h2><p>若在安装时出现<code>输入错误: 没有文件扩展“.js”的脚本引擎</code>的报错，则打开运行，输入<code>regedit</code></p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406020052.png" alt="image-20200406020051445"></p><p>在路径<code>HKEY_CLASSES_ROOT\.js</code>下，更改默认值为<code>JSFile</code></p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406020304.png" alt="image-20200406020303194"></p><h2 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h2><p>右键我的电脑，点击属性，然后进入高级系统设置</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406021233.png" alt="image-20200406021230911"></p><p>点击环境变量</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406225211.png" alt="image-20200406021307818"></p><p>找到系统变量的Path，双击进入编辑</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406021431.png" alt="image-20200406021429668"></p><p>点击新建，添加路径：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\MinGW\bin</span><br></pre></td></tr></table></figure><p>其中<code>C:\MinGW</code>为安装MinGW时的默认路径，若有修改则换为对应路径</p><p>然后打开CMD，输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -v</span><br></pre></td></tr></table></figure><p>查看是否配置成功</p><h2 id="CLion配置"><a href="#CLion配置" class="headerlink" title="CLion配置"></a>CLion配置</h2><p>安装CLion后，并进行基础配置后，会提示配置C/C++环境，确保Environment为MinGW的安装目录即可。</p><p>Make、C语言编译器、C++编译器会自动搜索bin目录下上文中安装好的包（若提示没找到则自行选取路径，若在目录中没找到说明没有安装成功）</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406225216.png" alt="image-20200406224427755"></p><p>其他无需更改，点击OK即可。</p><p>然后就可以新建一个C语言项目</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406225218.png" alt="image-20200406225107766"></p><p>创建完成后会默认生成初始化代码块</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406225316.png" alt="image-20200406225309144"></p><p>然后在菜单栏的Run中点击Run…</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406225344.png" alt="image-20200406225337183"></p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406225357.png" alt="image-20200406225355896"></p><p>初次运行会进行编译，等待编译完成后便会输出结果</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200406225427.png" alt="image-20200406225425856"></p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CLion </tag>
            
            <tag> C </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyCharm自定义模板</title>
      <link href="/post/202003300841/"/>
      <url>/post/202003300841/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><ul><li><p>自定义文件模板：</p><p>​    新建一个文件时自动添加一些头信息。</p></li><li><p>自定义代码块模板 ：</p><p>​    当有的代码自己需要多次使用时，一次次重复编写效率过低，故可以自定义一个缩写来实现按TAB自动将代码块补全。</p></li></ul><a id="more"></a><h2 id="文件模板"><a href="#文件模板" class="headerlink" title="文件模板"></a>文件模板</h2><p>详细说明可查看：<a href="https://www.jetbrains.com/help/pycharm/2017.1/file-and-code-templates-2.html" target="_blank" rel="noopener">官方文档</a></p><p>打开PyCharm的设置，搜索<code>File and Templates</code>，即可看到设置模板的界面</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330091231.png" alt="image-20200330084900658"></p><p>不同的文件可以设置不同的模板，这里设置python文件，选中<code>Python Script</code>，在右边的编辑初添加信息。</p><p>首先添加两行代码用于指定python环境以及采用utf-8编码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># _*_coding:utf-8 _*_</span></span><br></pre></td></tr></table></figure><p>接下来自定义文件的信息。</p><p>不同的变量名：</p><ul><li><code>${PROJECT_NAME}</code> - the name of the current project.</li><li><code>${NAME}</code> - the name of the new file which you specify in the New File dialog box during the file creation.</li><li><code>${USER}</code> - the login name of the current user.</li><li><code>${DATE}</code> - the current system date.</li><li><code>${TIME}</code> - the current system time.</li><li><code>${YEAR}</code> - the current year.</li><li><code>${MONTH}</code> - the current month.</li><li><code>${DAY}</code> - the current day of the month.</li><li><code>${HOUR}</code> - the current hour.</li><li><code>${MINUTE}</code> - the current minute.</li><li><code>${PRODUCT_NAME}</code> - the name of the IDE in which the file will be created.</li><li><code>${MONTH_NAME_SHORT}</code> - the first 3 letters of the month name. Example: Jan, Feb, etc.</li><li><code>${MONTH_NAME_FULL}</code> - full name of a month. Example: January, February, etc.</li></ul><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @Author : lluuiq</span></span><br><span class="line"><span class="comment"># @File : $&#123;NAME&#125;.py</span></span><br><span class="line"><span class="comment"># @project : $&#123;PROJECT_NAME&#125;</span></span><br><span class="line"><span class="comment"># @Time : $&#123;DATE&#125; $&#123;TIME&#125;</span></span><br></pre></td></tr></table></figure><p>最终设置结果：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330091236.png" alt="image-20200330090922739"></p><p>设置后保存，新建一个python文件即可看到效果</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330091240.png" alt="image-20200330091111859"></p><h2 id="代码块模块"><a href="#代码块模块" class="headerlink" title="代码块模块"></a>代码块模块</h2><p>打开PyCharm的设置。搜索<code>Live Template</code>，找到python，点击右方的<code>+</code>添加自定义代码块</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330092511.png" alt="image-20200330091434748"></p><p>选择第一个</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330092515.png" alt="image-20200330091507144"></p><p>设置界面如图</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330092517.png" alt="image-20200330091546411"></p><p>Abbreviation为缩写，即输入什么内容后按TAB会输出该代码块</p><p>Template text为自定义的代码块</p><p>在下方点击Define，勾选python</p><p>Description为描述，可以在输入缩写时弹出的信息中看到该描述</p><p>示例：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330092520.png" alt="image-20200330091927336"></p><p>在python文件中输入<code>demo</code>，可看到如下信息。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330092522.png" alt="image-20200330092010175"></p><p>按TAB后，会自动输出该部分自定义的代码</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330092524.png" alt="image-20200330092035228"></p><p><strong>优化：</strong>回到设置界面，将代码中要输入的内容修改为参数类型</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330092526.png" alt="image-20200330092229808"></p><p>这样输出自定义的代码后，$text1$以及$text2$的内容默认为空，且光标会自动定位在$text1$处，当输入内容后按回车，光标会自动移动到$text2$处，最后移动到$code$处。</p><p>也可以用相同的参数名，这样输出代码后，光标会自动选中两个$text$，此时会对两处同时进行修改，按回车后跳转到$code$处。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200330092530.png" alt="image-20200330092201513"></p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyCharm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyCharm+Anaconda3+PyQt环境配置</title>
      <link href="/post/202003290013/"/>
      <url>/post/202003290013/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>记录用Pycharm搭建PyQt环境的过程</p><a id="more"></a><h2 id="配置Qt-Designer"><a href="#配置Qt-Designer" class="headerlink" title="配置Qt Designer"></a>配置Qt Designer</h2><p>下载PyCharm与Anaconda3后，Anaconda3的包中集成了PyQt，并且也安装了Qt Designer</p><p>其中Qt Designer位于Anaconda3根目录/Library/bin/designer.exe（windows）</p><p>打开PyCharm设置，在Tools中点击External Tools，然后点击+号添加</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200329003506.png" alt="image-20200329002445201"></p><p>然后在设置的界面输入名称与描述（自定义）</p><p>Program为designer.exe路径，比如我的路径为<code>C:\Anaconda3\Library\bin\designer.exe</code></p><p>Working directory设置为项目路径，可以直接复制粘贴该变量或者在右边的Insert Macro中找到ProjectFileDir，点击添加（结果都一样）。最后点击OK即可。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200329003510.png" alt="image-20200329002702298"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ProjectFileDir$</span><br></pre></td></tr></table></figure><p>回到External Tools界面点击OK保存。</p><p>配置完成后，即可通过右键菜单栏启动Qt designer</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200329003512.png" alt="image-20200329003350595"></p><p>或者点击PyCharm上方菜单栏的Tools来启动</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200329003514.png" alt="image-20200329003456533"></p><h2 id="配置pyuic"><a href="#配置pyuic" class="headerlink" title="配置pyuic"></a>配置pyuic</h2><p>添加pyuic用于将Qt designer生成的.ui文件转为.py文件</p><p>在设置的External Tools添加一个新的Tool</p><p>名称与描述自定义，Program为Anaconda3根目录下的python.exe路径</p><p>Arguments填以下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-m PyQt5.uic.pyuic  $FileName$ -o $FileNameWithoutExtension$.py</span><br></pre></td></tr></table></figure><p>Working directory使用当前文件所在的目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$FileDir$</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200331181240.png" alt="image-20200329005406124"></p><p>添加后保存即可。这样每次用designer生成的代码只需要右键-&gt;External Tools-&gt;pyuic即可生成python文件在相同目录下。</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Anaconda3 </tag>
            
            <tag> PyQt </tag>
            
            <tag> PyCharm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Volantis主题DIY笔记</title>
      <link href="/post/202003171229/"/>
      <url>/post/202003171229/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>主题首页：<a href="https://volantis.js.org/" target="_blank" rel="noopener">Volantis</a></p><p>记录一些DIY的过程</p><a id="more"></a><h2 id="主题文件目录"><a href="#主题文件目录" class="headerlink" title="主题文件目录"></a>主题文件目录</h2><p>在主题的根目录下。</p><p>layout为页面、卡片、各部位的布局代码</p><p>source存放css、js、字体、图片等代码与资源</p><p>_config.yml为主题配置文件</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023003.png" alt="mark"></p><h2 id="顶部导航栏"><a href="#顶部导航栏" class="headerlink" title="顶部导航栏"></a>顶部导航栏</h2><p>设置顶部导航栏始终显示。</p><p>打开source/css/_layout/navbar.styl</p><p>找到最下面的代码，将其注释</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200326081504.png" alt="mark"></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// .cover-wrapper</span></span><br><span class="line"><span class="comment">//   .l_header</span></span><br><span class="line"><span class="comment">//     trans(0.5s)</span></span><br><span class="line"><span class="comment">//     transform: translateY(-2 * $navbar-height)</span></span><br><span class="line"><span class="comment">//     &amp;.show</span></span><br><span class="line"><span class="comment">//       transform: translateY(0)</span></span><br></pre></td></tr></table></figure><h2 id="搜索栏"><a href="#搜索栏" class="headerlink" title="搜索栏"></a>搜索栏</h2><p>修改搜索结果中的输入内容的上边距，使内容显示在合适位置</p><p>原来的样式：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023005.png" alt="mark"></p><p>修改后：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023006.png" alt="mark"></p><p>打开source/css_layout/search.styl</p><p>使用搜索功能搜索关键词<code>input</code></p><p>修改margin，将<code>$gap</code>改为<code>5px</code></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#u-search-modal-input</span><br><span class="line"><span class="attribute">margin</span>: <span class="number">5px</span> <span class="number">50px</span></span><br></pre></td></tr></table></figure><h2 id="修改卡片的内外边距"><a href="#修改卡片的内外边距" class="headerlink" title="修改卡片的内外边距"></a>修改卡片的内外边距</h2><p>打开_config.yml</p><p>找到<code>gap</code>的设置，添加base值，大小为要设置的内外边距</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023007.png" alt="mark"></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">base:</span> <span class="string">10px</span></span><br></pre></td></tr></table></figure><p>该方法是同时修改卡片之间的距离以及卡片内容与卡片边框之间的距离。</p><p>若要分开修改需要到css文件逐一修改，可以用该方法添加一个新的变量来传参。</p><p>例如：</p><p>在gap中添加一个变量，变量名自定义，这里用<strong>test</strong>示例，后面的大小为要设置的大小。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">test:</span> <span class="string">10px</span></span><br></pre></td></tr></table></figure><p>接着打开source/css/_defines/layout.styl，找到gap的设置</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023008.png" alt="mark"></p><p>添加自定义的变量</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023009.png" alt="mark"></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$test = convert(hexo-config('style.gap.test')) || 16px</span><br></pre></td></tr></table></figure><p>$test为CSS设置中的变量名，<code>style.gap.test</code>中的test为在_config.yml中设置的变量名，||后面为默认值</p><p>设置完成后，在对应的CSS设置中仅需要将间距大小改为<code>$test</code>，就会使用设置中test的值</p><h2 id="封面界面去掉搜索"><a href="#封面界面去掉搜索" class="headerlink" title="封面界面去掉搜索"></a>封面界面去掉搜索</h2><p>效果如图</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023016.png" alt="mark"></p><p>打开layout/_cover/index.ejs</p><p>找到如图所示代码，将其注释</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023010.png" alt="mark"></p><h2 id="添加QQ在线联系"><a href="#添加QQ在线联系" class="headerlink" title="添加QQ在线联系"></a>添加QQ在线联系</h2><p>打开_config.yml，搜索social，找到社交功能设置部分</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023011.png" alt="mark"></p><p>添加内容如下</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">icon:</span> <span class="string">fab</span> <span class="string">fa-qq</span></span><br><span class="line">  <span class="attr">url:</span> <span class="string">http://wpa.qq.com/msgrd?v=3&amp;uin=【你的QQ号】&amp;site=qq&amp;menu=yes</span></span><br></pre></td></tr></table></figure><p>第一次点击会提示未开通，到提示网站登入一次即可。</p><h2 id="将侧边栏移动到左边"><a href="#将侧边栏移动到左边" class="headerlink" title="将侧边栏移动到左边"></a>将侧边栏移动到左边</h2><p>打开layout文件夹，对以下文件统一修改</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023012.png" alt="image-20200317161443443"></p><p>打开一文件后，搜索代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;%- partial(&#39;_partial&#x2F;side&#39;) %&gt;</span><br></pre></td></tr></table></figure><p>将该行代码复制到第一行代码<code>&lt;%- partial(&#39;_pre&#39;) %&gt;</code>的下方，然后将原来位置的代码注释（方便以后若需要的话改回），示例：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023013.png" alt="mark"></p><p>然后修改CSS文件，</p><p>打开source/css/_layout/main.styl</p><p>搜索<code>.l_main</code>，找到<code>padding-right</code>，将right改为left，使原本的右边距变为左边距</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023014.png" alt="mark"></p><p>修改后为</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023015.png" alt="mark"></p><p>为适应手机端，还需要修改此处</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023017.png" alt="mark"></p><p>若想要手机端的卡片有外边距，则将<code>padding-right: 0</code>按需求修改边距 ，例如若想要左右边距都为10px，则应该改成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">padding-right: 10px</span><br><span class="line">padding-left: 10px</span><br></pre></td></tr></table></figure><p>效果如图：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023021.png" alt="mark"></p><p>若满意现在的效果则到此即可。接下来将侧边栏移动到网页的边缘处，然后让文章列表、其余页面的主要内容居中。</p><p><strong>注：</strong>修改后，在主题的配置文件中的最大宽度max_width将只修改页面内容卡片的宽度</p><h3 id="进一步修改"><a href="#进一步修改" class="headerlink" title="进一步修改"></a>进一步修改</h3><p>首先在_config.yml中修改最大宽度为100%，但注意这样会导致顶部导航栏的宽度也随之变成100%。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023018.png" alt="mark"></p><p>打开source/css/_layout/main.styl，将<code>.body-wrapper</code>中的<code>justify-content: space-between</code>注释。</p><p>该语句会使页面内的flex布局为flex项目之间的距离相等，若只有两个项目的情况下会导致一个在最左边，一个在最右边。注释后会采取默认的布局方式即左对齐。</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200326234018.png" alt="image-20200326234008039"></p><p>页面内容的修改在该文件中的<code>.l_main</code>，将width中的100%调小以更改页面内容的宽度，修改padding-left来更改与侧边栏的距离。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023020.png" alt="mark"></p><p>侧边栏的宽度可以在source/css/_defines/layout.styl中进行修改</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023022.png" alt="mark"></p><h2 id="修改透明度"><a href="#修改透明度" class="headerlink" title="修改透明度"></a>修改透明度</h2><p>使用css两种更改透明度方法，其中透明度取值为0~1，越小则透明程度越高</p><ol><li>使用 background-color:rgba(R,G,B,透明度)</li><li>使用 opacity: 透明度</li></ol><p>若使用rgba，则需要传入RGB颜色代码，并且修改的仅有div元素的背景透明度</p><p>若使用opacity，则只需要传入透明度，修改的是整个div元素的透明度（包括图片、文字等也会变透明）</p><p>在source/css中创建一个新的stylus文件，名字随意</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023023.png" alt="mark"></p><p>编辑内容，其中颜色代码、透明度自行修改</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.widget</span><br><span class="line">  <span class="attribute">background-color</span>:rgba(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">.post</span><br><span class="line">  <span class="attribute">background-color</span>:rgba(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><p>然后打开source/css/style.styl，插入引用语句</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@import <span class="string">'diy_css.styl'</span></span><br></pre></td></tr></table></figure><p>同理可以用此方式进行CSS的自定义，可以做到在不修改原本代码的情况下更改css</p><h2 id="实现pjax"><a href="#实现pjax" class="headerlink" title="实现pjax"></a>实现pjax</h2><p>感谢大佬的博客开源，让我能参考源代码进行修改：<a href="https://stevenmhy.tk/archives/db1997ec.html" target="_blank" rel="noopener">Material X主题pjax使用</a> </p><p>感谢大佬的讲解 ：<a href="https://sunhang.top/2019/12/20/pjax/" target="_blank" rel="noopener">用pjax让你的页面加载飞起来!</a></p><hr><p>在layout/_partial/head.ejs的末尾 <code>&lt;/head&gt;</code>的上方引用pjax</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200325222930.png" alt="image-20200325222920909"></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/npm/pjax/pjax.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>在layout/layout.ejs的末尾<code>&lt;/body&gt;</code>的上方插入代码</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line"><span class="keyword">var</span> pjax = <span class="keyword">new</span> Pjax(&#123;</span><br><span class="line">  elements: <span class="string">"a"</span>,</span><br><span class="line">  selectors: [</span><br><span class="line">    <span class="string">"title"</span>, <span class="comment">//pjax加载标题</span></span><br><span class="line">    <span class="string">".l_main"</span>, <span class="comment">//pjax加载主内容</span></span><br><span class="line">    <span class="string">".l_side"</span>, <span class="comment">//pjax加载侧边栏</span></span><br><span class="line">    <span class="string">".switcher .h-list"</span>, <span class="comment">// 使手机端的搜索框与菜单栏生效</span></span><br><span class="line">  ]</span><br><span class="line">&#125;)</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200325224044.png" alt="image-20200325224042143"></p><p>elements选择触发器，即点击什么来触发pjax（只能用a或者form），a为链接。</p><p>selectors根据css选择器来选择更新的节点（即当触发elements时哪些内容会刷新，其余部分保持不变）</p><p>可以用节点、类、id等选择元素。用法参考：<a href="https://www.runoob.com/cssref/css-selectors.html" target="_blank" rel="noopener">CSS 选择器</a></p><p>这里我设置的为：点击链接，则刷新标题、类为<code>l_main</code>与<code>l_side</code>的元素（页面内容与侧边栏）会刷新，其余不变。</p><h3 id="pjax优化-自动生成Fancybox"><a href="#pjax优化-自动生成Fancybox" class="headerlink" title="pjax优化-自动生成Fancybox"></a>pjax优化-自动生成Fancybox</h3><p>在定义pjax的脚本代码中插入语句（放在&lt;script&gt;与&lt;/script&gt;中）</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//加载fancybox</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">LoadFancybox</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">  $(<span class="string">".article-entry"</span>).find(<span class="string">"img"</span>).each(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="comment">//渲染fancy box</span></span><br><span class="line">    <span class="keyword">var</span> t = <span class="built_in">document</span>.createElement(<span class="string">"a"</span>);</span><br><span class="line">    $(t).attr(<span class="string">"data-fancybox"</span>, <span class="string">"gallery"</span>),</span><br><span class="line">    $(t).attr(<span class="string">"href"</span>, $(<span class="keyword">this</span>).attr(<span class="string">"src"</span>)),</span><br><span class="line">    $(t).attr(<span class="string">"margin"</span>,<span class="string">"0 auto"</span>),</span><br><span class="line">    $(<span class="keyword">this</span>).wrap(t)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// pjax加载结束后执行函数</span></span><br><span class="line"><span class="built_in">document</span>.addEventListener(<span class="string">'pjax:complete'</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>)</span>&#123;</span><br><span class="line">  LoadFancybox();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 窗口监听load(加载、刷新)事件，执行LoadFancybox()函数</span></span><br><span class="line"><span class="built_in">window</span>.addEventListener(<span class="string">'load'</span>,<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">  LoadFancybox();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>插入后结果如图：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200327002933.png" alt="image-20200327002931652"></p><p>修改后发现实现了fancybox，但是图片不再居中，故进行修改。</p><p>打开source/css/_layout/main.styl</p><p>搜索<code>img</code> 找到位于l_main&gt;post&gt;a下的img，将<code>display: inline</code>注释</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200326112446.png" alt="image-20200326104120122"></p><hr><p><strong>BUG：</strong></p><ul><li>放大图片再关闭后，页面位置与放大前不对应，会返回到放大前一张图片时的位置 。</li></ul><p><strong>更新：</strong></p><p>将原来代码中的<code>$(t).attr(&quot;data-fancybox&quot;,&quot;gallery&quot;),</code>中的<code>&quot;gallery&quot;</code>改为<code>&quot;&quot;</code></p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/image-20200625071949974.png" alt="image-20200625071949974"></p><hr><p>实现pjax后发现导航栏在点击不同部分时，主题的下划线不会改变，进行修改没有修改成，故直接将CSS代码注释</p><p>打开source/css/_layout/navbar.styl 搜索<code>&amp;:active,&amp;.active</code> 将该部分代码注释</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200401152132.png" alt="image-20200327013730981"></p><h3 id="pjax刷新评论"><a href="#pjax刷新评论" class="headerlink" title="pjax刷新评论"></a>pjax刷新评论</h3><p><strong>问题</strong>：实现pjax后发现通过pjax刷新页面后评论无法成功加载，推测是因为评论由js脚本引入，pjax刷新页面不会加载js。</p><p><strong>解决思路</strong>：当pjax执行完成后再次调用评论js脚本来生成评论。</p><p>在pjax脚本中插入以下代码，其中调用脚本的方式有两种，用哪一个都可以。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">LoadValine</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="comment">// 两种调用方式，一个调用配置里的js路径，一个调用本地，用哪个都可以</span></span><br><span class="line"> <span class="comment">// $.getScript("&lt;%= theme.comments.valine.js %&gt;", function() &#123;</span></span><br><span class="line">    $.getScript(<span class="string">"/js/Valine.js"</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        </span><br><span class="line">      <span class="comment">// 生成评论的代码</span></span><br><span class="line">      <span class="keyword">var</span> GUEST_INFO = [<span class="string">'nick'</span>,<span class="string">'mail'</span>,<span class="string">'link'</span>];</span><br><span class="line">      <span class="keyword">var</span> guest_info = <span class="string">'&lt;%= theme.comments.valine.meta %&gt;'</span>.split(<span class="string">','</span>).filter(<span class="function"><span class="keyword">function</span>(<span class="params">item</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> GUEST_INFO.indexOf(item) &gt; <span class="number">-1</span></span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="keyword">var</span> notify = <span class="string">'&lt;%= theme.comments.valine.notify %&gt;'</span> == <span class="literal">true</span>;</span><br><span class="line">      <span class="keyword">var</span> verify = <span class="string">'&lt;%= theme.comments.valine.verify %&gt;'</span> == <span class="literal">true</span>;</span><br><span class="line">      <span class="keyword">var</span> valine = <span class="keyword">new</span> Valine();</span><br><span class="line">      valine.init(&#123;</span><br><span class="line">        el: <span class="string">'#valine_container'</span>,</span><br><span class="line">        notify: notify,</span><br><span class="line">        verify: verify,</span><br><span class="line">        guest_info: guest_info,</span><br><span class="line">        &lt;% <span class="keyword">if</span> (page.valine &amp;&amp; page.valine.path) &#123; %&gt;</span><br><span class="line">          path: <span class="string">"&lt;%= page.valine.path %&gt;"</span>,</span><br><span class="line">        &lt;% &#125; <span class="keyword">else</span> <span class="keyword">if</span> (theme.comments.valine.path) &#123; %&gt;</span><br><span class="line">          path: <span class="string">"&lt;%= theme.comments.valine.path %&gt;"</span>,</span><br><span class="line">        &lt;% &#125; %&gt;</span><br><span class="line">        appId: <span class="string">"&lt;%= theme.comments.valine.appId %&gt;"</span>,</span><br><span class="line">        appKey: <span class="string">"&lt;%= theme.comments.valine.appKey %&gt;"</span>,</span><br><span class="line">        placeholder: <span class="string">"&lt;%= (page.valine &amp;&amp; page.valine.placeholder) ? page.valine.placeholder : theme.comments.valine.placeholder %&gt;"</span>,</span><br><span class="line">        pageSize:<span class="string">'&lt;%= theme.comments.valine.pageSize %&gt;'</span>,</span><br><span class="line">        avatar:<span class="string">'&lt;%= theme.comments.valine.avatar %&gt;'</span>,</span><br><span class="line">        lang:<span class="string">'&lt;%= theme.comments.valine.lang %&gt;'</span>,</span><br><span class="line">        visitor: <span class="string">'&lt;%- theme.comments.valine.visitor %&gt;'</span>,</span><br><span class="line">        highlight:<span class="string">'&lt;%= theme.comments.valine.highlight %&gt;'</span></span><br><span class="line">      &#125;)</span><br><span class="line">&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后在监听pjax完成后的函数里调用函数</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 加载pjax后执行的函数</span></span><br><span class="line"><span class="built_in">document</span>.addEventListener(<span class="string">'pjax:complete'</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>)</span>&#123;</span><br><span class="line">    LoadFancybox();</span><br><span class="line">    <span class="comment">// 调用刚刚设置的函数</span></span><br><span class="line">    LoadValine();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>结果应该如图：</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200401152053.png" alt="image-20200401152044289"></p><p><strong>源码位置：</strong><code>layout\_partial\scripts.ejs</code>，上述代码中生成评论的部分即红框内的部分</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200401152332.png" alt="image-20200401152329756"></p><h2 id="添加百度统计"><a href="#添加百度统计" class="headerlink" title="添加百度统计"></a>添加百度统计</h2><p>首先到<a href="https://tongji.baidu.com/" target="_blank" rel="noopener">百度统计</a>注册帐号，然后到管理界面，新增网站</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200401152138.png" alt="image-20200401125207533"></p><p>新增后，会给一段代码，将其复制，并在外面加上ejs模板的语句</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;% if (theme.baidu_analytics)&#123; %&gt;</span><br><span class="line">    &lt;script&gt;</span><br><span class="line">        var _hmt &#x3D; _hmt || [];</span><br><span class="line">        (function() &#123;</span><br><span class="line">          var hm &#x3D; document.createElement(&quot;script&quot;);</span><br><span class="line">          hm.src &#x3D; &quot;https:&#x2F;&#x2F;hm.baidu.com&#x2F;hm.js?【你的key】&quot;;</span><br><span class="line">          var s &#x3D; document.getElementsByTagName(&quot;script&quot;)[0]; </span><br><span class="line">          s.parentNode.insertBefore(hm, s);</span><br><span class="line">        &#125;)();</span><br><span class="line">    &lt;&#x2F;script&gt;</span><br><span class="line">&lt;% &#125; %&gt;</span><br></pre></td></tr></table></figure><p>打<code>layout\_partial\scripts.ejs</code>，将该段代码插入到最后</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200401152144.png" alt="image-20200401125553039"></p><p>再打开<code>_config.yml</code>，加入一条语句</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">baidu_analytics:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>因为用js文件加载的方式，所以百度统计上的代码检查功能失效，需要手动检查。</p><p>保存后，打开网站，按F12打开开发者工具，然后刷新页面，在js文件中看到以hm开头的js文件说明配置成功</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200401152147.png" alt="image-20200401125819253"></p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scrapy笔记</title>
      <link href="/post/202003040405/"/>
      <url>/post/202003040405/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>记录学习Scrapy时遇到的坑</p><p><a href="https://scrapy-chs.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">Scrapy官方文档</a></p><p>学习时看的视频：<a href="https://www.bilibili.com/video/av57909837" target="_blank" rel="noopener">【python爬虫_从入门到精通（高级篇）】scrapy框架、反爬、分布式爬虫</a></p><a id="more"></a><h1 id="使用笔记"><a href="#使用笔记" class="headerlink" title="使用笔记"></a>使用笔记</h1><h2 id="创建爬虫项目"><a href="#创建爬虫项目" class="headerlink" title="创建爬虫项目"></a>创建爬虫项目</h2><p>CMD命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject 【项目文件夹名】</span><br></pre></td></tr></table></figure><p>会在输入命令的目录中生成一个名称为【项目文件夹名】的文件夹用来存放爬虫项目</p><h2 id="创建爬虫"><a href="#创建爬虫" class="headerlink" title="创建爬虫"></a>创建爬虫</h2><p>CMD命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd 【项目文件夹名】</span><br><span class="line">scrapy genspider 【爬虫的名字】 &quot;【爬取的域名】&quot;</span><br></pre></td></tr></table></figure><p>进入创建好的爬虫项目中创建爬虫，名字不能与其他爬虫重复，且不能与项目名相同。</p><p>爬取的域名指定爬取范围，使该爬虫仅仅在该域名内的页面中进行爬取。</p><h2 id="更改设置"><a href="#更改设置" class="headerlink" title="更改设置"></a>更改设置</h2><p>首先更改设置中的一些值</p><p>善用``CTRL+F`搜索参数，快速找到位置</p><p>打开爬虫根目录中的settings.py，进行更改。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 设置爬取的延迟，单位为秒，即间隔1秒爬取一次</span><br><span class="line">DOWNLOAD_DELAY &#x3D; 1</span><br><span class="line"></span><br><span class="line"># 不遵守协议</span><br><span class="line">ROBOTSTXT_OBEY &#x3D; False</span><br><span class="line"></span><br><span class="line"># 设置默认的请求头，如有需要可以添加其他信息。</span><br><span class="line">DEFAULT_REQUEST_HEADERS &#x3D; &#123;</span><br><span class="line">  &#39;User_Agent&#39; :&#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;80.0.3987.132 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 设置pipelines自动运行，用于自动根据代码保存数据，找到后取消注释即可，不用更改</span><br><span class="line">ITEM_PIPELINES &#x3D; &#123;</span><br><span class="line">  # 执行优先级300，值越小，优先级越高</span><br><span class="line">   &#39;【爬虫项目名称】.pipelines.【爬虫项目名称】Pipeline&#39;: 300,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 不显示warning以下级别的输出日志</span><br><span class="line">LOG_LEVEL&#x3D;&quot;WARNING&quot;</span><br></pre></td></tr></table></figure><h2 id="创建运行脚本"><a href="#创建运行脚本" class="headerlink" title="创建运行脚本"></a>创建运行脚本</h2><p>创建后，不用每次运行爬虫都要输入终端命令，只需要执行python文件即可。</p><p>在项目中的任意位置创建一个python文件，名字自定义</p><p>输入内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from scrapy import cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(&#39;scrapy crawl 【爬虫的名字】&#39;.split())</span><br></pre></td></tr></table></figure><p>爬虫的名字指的是创建爬虫时用的名字，而不是项目的名字。</p><h2 id="创建CrawlSpider爬虫"><a href="#创建CrawlSpider爬虫" class="headerlink" title="创建CrawlSpider爬虫"></a>创建CrawlSpider爬虫</h2><p>scrapy爬虫的进化版</p><p>CMD命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider -t crawl 【爬虫名字】 “【域名】”</span><br></pre></td></tr></table></figure><h2 id="Scrapy-Shell"><a href="#Scrapy-Shell" class="headerlink" title="Scrapy Shell"></a>Scrapy Shell</h2><p>cmd终端中，进入爬虫项目文件夹，输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell 【链接】</span><br></pre></td></tr></table></figure><p>即可打开scrapy shell，</p><p>用于进行一些不调用scrapy引擎进行一些测试（如正则表达式，检查获取信息的内容等等）</p><p> <img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023136.png" alt="mark"></p><h2 id="关闭windows的快捷编辑模式"><a href="#关闭windows的快捷编辑模式" class="headerlink" title="关闭windows的快捷编辑模式"></a>关闭windows的快捷编辑模式</h2><p>有时scrapy会在跳转到另一页面时莫名奇妙的自动终止，关掉windows的快捷编辑模式，问题得以解决。</p><h1 id="报错笔记"><a href="#报错笔记" class="headerlink" title="报错笔记"></a>报错笔记</h1><h1 id="ERROR-Spider-error-processing"><a href="#ERROR-Spider-error-processing" class="headerlink" title="ERROR: Spider error processing"></a>ERROR: Spider error processing</h1><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023137.png" alt="mark"></p><p>response.body返回的是二进制文件，不能用w方式进行写入，应改为wb</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> Scrapy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo部署到服务器</title>
      <link href="/post/202002230909/"/>
      <url>/post/202002230909/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>不使用github pages，改为自己的服务器。将代码托管到gtihub，使用webhook实现github与服务器同步推送代码，并且安装hexo-admin来实现后台管理与服务器到github上的推送。</p><a id="more"></a><h1 id="购买服务器"><a href="#购买服务器" class="headerlink" title="购买服务器"></a>购买服务器</h1><p>服务器商千千万，自行挑选一个靠谱的。</p><p><strong>注意：国内各服务商有学生优惠套餐，但是只能购买大陆服务器，且大陆服务器需要备案才能使用，备案很麻烦，要花十几到二十天左右。但是便宜稳定。</strong></p><p>进入服务商的购买页面，选择配置。</p><p>若是一键选择套餐购买，需要选择地区、选择服务器的配置、选择服务器镜像系统、服务器带宽(越大则服务器能承受的压力越大)、购买时长。</p><p>若是自定义配置，需要选择购买的计时方式、配置的详细选择，更多的系统选择以及自定义镜像、存储空间。</p><p>总结就是越强越贵，时间越长越贵。个人博客不需要非常好的配置，推荐系统选择linux</p><p><strong>注意：大陆服务器需要至少购买3个月时长才可以进行备案。</strong></p><fancybox><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324032223.png" alt="mark"></p></fancybox><p>假如是国外服务器，则购买后可以直接进行部署了。如果是头铁选了国内，则需要先进行备案(大概20天左右。备案流程放到最后。)</p><p>我使用的宝塔控制面板，简单方便无脑。安装宝塔后，可以在控制面板进行操作来操作自己的服务器。</p><p>注：若服务器操作过程出现无法挽回的问题，可以在服务器控制台重装系统。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324032233.png" alt="mark"></p><h1 id="连接服务器"><a href="#连接服务器" class="headerlink" title="连接服务器"></a>连接服务器</h1><p>首先下载putty、xhell等连接工具，我使用的是finalshell，用哪个都可以，原理都一样，用服务器商自带的登陆功能也可以。打开后界面如图。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324032240.png" alt="mark"></p><p>点击文件夹，新建一个连接，选择SSH连接</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324032246.png" alt="mark"></p><p>名称自定义，主机为上一步的ip地址。填写完后点击确定。</p><p>(国外服务器可勾选智能加速，国内则不勾选)此时我使用的是美国服务器，所以勾选了海外加速。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072356.png" alt="mark"></p><p>可以看到新建了一个服务器连接，ssr为刚刚自定义的名称，后面有ip地址和端口号，和服务器主机名。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072425.png" alt="mark"></p><p>双击该连接，进入服务器，连接成功出现如图所示界面。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072428.png" alt="mark"></p><p>如果出现该窗口</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072432.png" alt="mark"></p><p>点接受并保存。</p><h1 id="部署到服务器"><a href="#部署到服务器" class="headerlink" title="部署到服务器"></a>部署到服务器</h1><h2 id="解析域名"><a href="#解析域名" class="headerlink" title="解析域名"></a>解析域名</h2><p><strong>注</strong>：若github page有绑定域名的话，先把绑定解除，并且将解析暂停，否则会冲突。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072437.png" alt="mark"></p><hr><p>到域名管理处，点击解析</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072440.png" alt="mark"></p><p>按照如图所示添加两条记录，一个主机记录选<code>@</code>（直接输入域名即可进入网站），一个选<code>www</code>（前面加上www可进入网站），也可以自定义一个前缀，但在后面站点配置时要加进去。</p><p>记录类型选A，指向一个IP地址，然后在记录值处填自己服务器的公网IP。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072448.png" alt="mark"></p><p>主机记录说明：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072555.png" alt="mark"></p><h2 id="安装宝塔面板"><a href="#安装宝塔面板" class="headerlink" title="安装宝塔面板"></a>安装宝塔面板</h2><p>根据官方教程进行安装。</p><blockquote><p><a href="https://www.bt.cn/bbs/thread-19376-1-1.html" target="_blank" rel="noopener">宝塔Linux面板安装教程</a></p><p>若安装完成不能使用，则需要放行端口：</p><p>腾讯云：<a href="https://www.bt.cn/bbs/thread-1229-1-1.html" target="_blank" rel="noopener">https://www.bt.cn/bbs/thread-1229-1-1.html</a></p><p>阿里云：<a href="https://www.bt.cn/bbs/thread-2897-1-1.html" target="_blank" rel="noopener">https://www.bt.cn/bbs/thread-2897-1-1.html</a>  </p><p>华为云：<a href="https://www.bt.cn/bbs/thread-3923-1-1.html" target="_blank" rel="noopener">https://www.bt.cn/bbs/thread-3923-1-1.html</a> </p></blockquote><p>进入服务器，根据自身系统输入安装命令，命令失效则看官方教程，有备用命令</p><p><strong>Centos安装命令：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y wget &amp;&amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; sh install.sh</span><br></pre></td></tr></table></figure><p><strong>Ubuntu/Deepin安装命令：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -O install.sh http://download.bt.cn/install/install-ubuntu_6.0.sh &amp;&amp; sudo bash install.sh</span><br></pre></td></tr></table></figure><p><strong>Debian安装命令：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -O install.sh http://download.bt.cn/install/install-ubuntu_6.0.sh &amp;&amp; bash install.sh</span><br></pre></td></tr></table></figure><p><strong>Fedora安装命令:</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; bash install.sh</span><br></pre></td></tr></table></figure><p>以cenOS为例：</p><p>输入命令进行安装</p><fancybox><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072600.png" alt="mark"></p>  </fancybox><p>输入y，安装宝塔，然后稍等片刻</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072605.png" alt="mark"></p><p>如图安装完成，会显示控制面板的url以及用户名和密码</p><fancybox><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072609.png" alt="mark"></p></fancybox><p>安装完成后，就可以关闭finalShell了，打开浏览器，输入该地址，并输入刚刚显示的用户名和密码，进入面板</p><p>这里建议进入后修改登陆面板的帐号与密码，不使用默认生成的。并且将面板的网址保存起来，方便以后直接输入网址进入面板。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072613.png" alt="mark"></p><p>进入面板后，会出现如下提示，进行安装软件。可以根据需求进行安装，也可以直接点一键安装，推荐LNMP，且选择极速安装，编译安装太慢。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072618.png" alt="mark"></p><h2 id="创建站点"><a href="#创建站点" class="headerlink" title="创建站点"></a>创建站点</h2><p>宝塔面板安装完成后，在导航栏点击网站，选择添加站点。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072623.png" alt="mark"></p><p>设置如下，在域名处填写自己的域名，可填写多个 （填写进的域名在解析完成后可以访问到该网站）</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072627.png" alt="mark"></p><p>生成站点后，点击网站名或者后面的设置，可以进入站点设置来添加一些新的域名以及二级域名等等。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072630.png" alt="mark"></p><p><strong>其中abc为自定义的二级域名，想不想设置随意。设置了就需要在解析时填写对应的主机记录。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072634.png" alt="mark"></p><p>点击添加后如下，这样用户可以通过以下域名访问到该服务器部署的网站，如果不想让github.io的地址也访问到该服务器，可以删除。</p><p><strong>添加的域名需要解析到服务器才可以正常使用。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072637.png" alt="mark"></p><p>添加完成后关闭设置即可。</p><p>最后到域名管理处。进行解析。添加记录如下</p><ul><li>记录值：www和@各添加一次，</li><li>记录类型：选A</li><li>线路类型：默认</li><li>记录值：你的服务器IP地址</li></ul><p>结果如下（若有自定义二级域名等等，需要再添加上。）</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072641.png" alt="mark"></p><p>等待几分钟生效，即可通过域名访问该服务器。</p><h2 id="使用webhook实现同步页面"><a href="#使用webhook实现同步页面" class="headerlink" title="使用webhook实现同步页面"></a>使用webhook实现同步页面</h2><p>虽然服务器是配置好了，但是宝塔并不支持代码托管，也就是说使用<code>hexo d</code>命令推送的代码并不能推到宝塔上来实现更新网站。于是使用webhook来实现与github代码同步。</p><p>原理：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072645.png" alt="mark"></p><h3 id="安装宝塔WebHook"><a href="#安装宝塔WebHook" class="headerlink" title="安装宝塔WebHook"></a>安装宝塔WebHook</h3><p>在宝塔面板导航栏点击软件商店。搜索 <code>webhook</code> 点击安装。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072649.png" alt="mark"></p><h3 id="配置webhook"><a href="#配置webhook" class="headerlink" title="配置webhook"></a>配置webhook</h3><p>安装完成后，点击设置，(可以勾选首页显示。)</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072653.png" alt="mark"></p><p>点击添加，名称随意，执行脚本先随便填写一点内容，点击提交后再编辑脚本。</p><p>（若出现编辑不能保存的情况，则在宝塔面板的右上角点修复）</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072659.png" alt="mark"></p><p>添加完成后点击编辑，删除原来随意填写的内容，添加如下代码并修改gitHttp。</p><p>注：</p><ol><li>原代码有一个$1变量，在后面的密钥部分的URL地址最后通过param=X，将X作为 该变量传入脚本，但因为我无论怎么改都会出现参数错误，因此将该变量删掉了。然后改一下代码，将​$1的参数替换为固定的值，只要站点目录存在就没问题。</li><li>大概是因为自己设置了保存博客源代码的分支为默认分支的原因，用原代码里面的有一句<code>git pull</code>总是拉不过来文件，在服务器上手动拉取发现拉取的是博客源代码的分支。故在原代码中将<code>git pull</code>改成<code>git pull origin master</code>来指定拉取静态页面的分支。</li></ol><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200403160129.png" alt="image-20200403154315216"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">echo ""</span><br><span class="line"><span class="meta">#</span><span class="bash">输出当前时间</span></span><br><span class="line">date --date='0 days ago' "+%Y-%m-%d %H:%M:%S"</span><br><span class="line">echo "Start"</span><br><span class="line"><span class="meta">#</span><span class="bash">git项目路径</span></span><br><span class="line">gitPath="/www/wwwroot/【站点根目录】"</span><br><span class="line"><span class="meta">#</span><span class="bash">git 网址</span></span><br><span class="line">gitHttp="【仓库git地址】"</span><br><span class="line"></span><br><span class="line">echo "Web站点路径：$gitPath"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">判断项目路径是否存在</span></span><br><span class="line">if [ -d "$gitPath" ]; then</span><br><span class="line">        cd $gitPath</span><br><span class="line">        #判断是否存在git目录</span><br><span class="line">        if [ ! -d ".git" ]; then</span><br><span class="line">                echo "在该目录下克隆 git"</span><br><span class="line">                sudo -Hu www git clone $gitHttp gittemp --depth=1</span><br><span class="line">                sudo mv gittemp/.git .</span><br><span class="line">                sudo rm -rf gittemp</span><br><span class="line">        fi</span><br><span class="line">        #拉取最新的项目文件</span><br><span class="line">        echo "拉取最新文件"</span><br><span class="line">        sudo -Hu www git reset --hard origin/master</span><br><span class="line">        sudo -Hu www git pull origin master</span><br><span class="line">        #设置目录权限</span><br><span class="line">        echo "设置目录权限"</span><br><span class="line">        sudo chown -R www:www $gitPath</span><br><span class="line">        echo "End"</span><br><span class="line">        exit</span><br><span class="line">else</span><br><span class="line">        echo "该项目路径不存在"</span><br><span class="line">        echo "End"</span><br><span class="line">        exit</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p><strong>更新：</strong> 在指令语句前加入sudo，授予管理员权限，避免执行失败</p><p>gitHttp路径为github代码仓库的地址，需要到代码库中查看(带.git尾缀的地址，即hexo部署时配置 <code>_config.yml</code>时填写的地址。)，点击复制键进行复制</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072727.png" alt="mark"></p><p>粘贴后格式应该如下    </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitHttp&#x3D;&quot;https:&#x2F;&#x2F;github.com&#x2F;XXXXXX.git&quot;</span><br></pre></td></tr></table></figure><p>随后点击右下角的保存即可。</p><h3 id="github配置hook"><a href="#github配置hook" class="headerlink" title="github配置hook"></a>github配置hook</h3><p>编辑完成后，点击查看密钥</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072732.png" alt="image-20200227215746441"></p><p>复制好密钥以及下方URL的<code>&amp;</code>前面的内容（全复制也可以）</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072735.png" alt="mark"></p><p>进入github的网站代码库的设置，导航栏选webhook，然后点击Add webhook</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072739.png" alt="mark"></p><p>填写内容</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072744.png" alt="mark"></p><p>填写好后点击Add webhook。</p><p>然后回到面板，点击测试，然后在日志中查看结果。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072749.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072753.png" alt="mark"></p><p>同时回到github的webhook界面，编辑刚刚的钩子</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072757.png" alt="mark"></p><p>在最下面可以看到成功的信息。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072803.png" alt="mark"></p><p>这样以后在本地进行的deploy，服务器最自动钩取github仓库的master分支，实现将博客部署到服务器上。然后使用域名就可以进行访问(不要加https://)。</p><h2 id="添加SSL证书，开启https协议"><a href="#添加SSL证书，开启https协议" class="headerlink" title="添加SSL证书，开启https协议"></a>添加SSL证书，开启https协议</h2><p><strong>注</strong>：若出现访问拒绝的话，注意是否加了https协议。</p><p>没有配置SSL证书的话，用https访问会被拒绝。SSL证书有收费的也有免费的。</p><p>宝塔自带免费证书，但要求实名认证。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072807.png" alt="mark"></p><p>接下来以个人服务商腾讯云的免费证书为例，</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072812.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072816.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072820.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072824.png" alt="mark"></p><p>按步骤填写即可注册证书。添加后下载证书，然后解压。</p><p>若关闭了界面，可以在SSL证书处下载证书</p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200403152945.png" alt="image-20200403152926736"></p><p>打开下载好的文件夹，打开Apache</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072833.png" alt="mark"></p><p>打开<code>.crt</code>和<code>.key</code>结尾的文件。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072836.png" alt="mark"></p><p>然后在宝塔面板进入站点的设置，图中点击网站名或者设置都可以</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072840.png" alt="mark"></p><p>如图，在SSL界面其他证书里，将<code>.key</code>结尾的密钥放入左边，<code>.crt</code>结尾的证书放入右边，保存，然后强制HTTPS，即可开启https协议。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072844.png" alt="mark"></p><h1 id="源代码同步到服务器（舍弃）"><a href="#源代码同步到服务器（舍弃）" class="headerlink" title="源代码同步到服务器（舍弃）"></a>源代码同步到服务器（舍弃）</h1><h2 id="更新（必看）："><a href="#更新（必看）：" class="headerlink" title="更新（必看）："></a>更新（必看）：</h2><p>本来是想的利用hexo-admin实现在服务器上开启后台管理，然后就能实现理想中的功能：</p><ol><li><p>本地操作完博客后，源代码+静态页面+文章都可以同步到服务器上</p></li><li><p>服务器操作完博客后，源代码+静态页面+文章也都同步到本地</p></li></ol><p>这样的话，我可以在本地尝试修改主题与配置，满意后进行推送同步到服务器。在没有hexo与git环境时（如临时用其他电脑或者用手机），然后又不能安装或者不想安装的话，可以通过hexo-admin后台来写文章并deploy，等到了自己的电脑上直接克隆就可以完成同步了。</p><p>但在配置时发现了一个问题，hexo-admin提供的deploy功能貌似仅支持以hexo开头的命令，如<code>hexo d</code>、<code>hexo new &quot;文章名&quot;</code>，我试图加入git命令然后就报错了。</p><p>这就导致我能成功将本地的源代码、静态页面推送到服务器，但是用hexo-admin新建然后写的文章是没办法自动保存到github上来克隆到本地的。再考虑到安装插件的问题，一些功能需要安装一些插件（如音乐播放器、live2D、加入视频等等）。插件是不会被推送的，若想推送插件的话，每次推送都要等待很长时间。</p><p>综上，故暂时舍弃源代码同步到服务器，让服务器仅保存静态页面就行了。所以下面的内容可以不用看了。</p><p>PS：关于能否使用git命令的问题已经提交到github上的Issues，如果有解决办法的话希望能留言告诉我。</p><h2 id="在服务器上部署hexo"><a href="#在服务器上部署hexo" class="headerlink" title="在服务器上部署hexo"></a>在服务器上部署hexo</h2><p>关于CentOS的安装git、Node.js我遇到一些问题，参考了下面两篇文章完美解决，故这里就不说安装方法了，直接看这两篇就行了。</p><p>CentOS安装Git参考链接：<br><a href="https://www.cnblogs.com/imyalost/p/8715688.html" target="_blank" rel="noopener">https://www.cnblogs.com/imyalost/p/8715688.html</a></p><p><strong>注</strong>：Hexo需要10版本以上才能支持，默认安装的话版本开头为6，需要安装最新版本才可以，我就用默认安装Node.js的方法结果最后hexo安装失败。</p><p>CentOS安装最新版Node.js参考链接：</p><p><a href="https://www.jianshu.com/p/4a9449506924" target="_blank" rel="noopener">https://www.jianshu.com/p/4a9449506924</a></p><p>安装hexo指令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324072854.png" alt="mark"></p><p>警告不用理会。</p><h2 id="克隆保存在github上的博客代码"><a href="#克隆保存在github上的博客代码" class="headerlink" title="克隆保存在github上的博客代码"></a>克隆保存在github上的博客代码</h2><p>通过cd命令切换到想保存博客根目录的文件夹下，例如我打算把博客的根目录放在 /www下，则输入<code>cd /www</code>，</p><p>然后克隆在github上的博客源代码，例如我的命令为</p><p><code>git clone https://github.com/lluuiq/lluuiq.github.io.git</code>，后面是仓库地址，改为自己的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone 【仓库地址】</span><br></pre></td></tr></table></figure><p>这样在输入该指令的文件夹下会出现【yourusername】.github.io的文件夹，里面放着博客的源代码。</p><p>若想改个名字的话，在包含根目录的文件夹下（我的是/www）输入下面指令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv 【yourusername】.github.io 【newname】</span><br></pre></td></tr></table></figure><p>我将文件夹名称改为wa2000，下面的wa2000文件夹都是博客根目录。</p><p>在服务器上的hexo根目录已经建成，接下来就是同步github上的源代码仓库，使得当github仓库的文件更新时，服务器上的博客源代码也会同步更新。</p><h2 id="服务器上的hexo同步github"><a href="#服务器上的hexo同步github" class="headerlink" title="服务器上的hexo同步github"></a>服务器上的hexo同步github</h2><h3 id="宝塔与webhook安装"><a href="#宝塔与webhook安装" class="headerlink" title="宝塔与webhook安装"></a>宝塔与webhook安装</h3><p>步骤同 <a href="#部署到服务器">部署到服务器</a></p><h3 id="设置webhook"><a href="#设置webhook" class="headerlink" title="设置webhook"></a>设置webhook</h3><p>与上方内容相同，但需要更改的是分支名选择存放博客目录的分支</p><p>个人的配置（参照修改）</p><p>git项目路径：<code>gitPath=&quot;/www/wa2000&quot;</code></p><p>git网址：<code>gitHttp=&quot;https://github.com/lluuiq/lluuiq.github.io.git&quot;</code></p><p>分支名：<code>source</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">echo &quot;&quot;</span><br><span class="line">#输出当前时间</span><br><span class="line">date --date&#x3D;&#39;0 days ago&#39; &quot;+%Y-%m-%d %H:%M:%S&quot;</span><br><span class="line">echo &quot;Start&quot;</span><br><span class="line">#git项目路径</span><br><span class="line">gitPath&#x3D;&quot;【你的博客根目录地址】&quot;</span><br><span class="line">#git 网址</span><br><span class="line">gitHttp&#x3D;&quot;【你的仓库地址】&quot;</span><br><span class="line"></span><br><span class="line">echo &quot;Web站点路径：$gitPath&quot;</span><br><span class="line"></span><br><span class="line">#判断项目路径是否存在</span><br><span class="line">if [ -d &quot;$gitPath&quot; ]; then</span><br><span class="line">        cd $gitPath</span><br><span class="line">        #判断是否存在git目录</span><br><span class="line">        if [ ! -d &quot;.git&quot; ]; then</span><br><span class="line">                echo &quot;在该目录下克隆 git&quot;</span><br><span class="line">                git clone $gitHttp gittemp</span><br><span class="line">                mv gittemp&#x2F;.git .</span><br><span class="line">                rm -rf gittemp</span><br><span class="line">        fi</span><br><span class="line">        #拉取最新的项目文件</span><br><span class="line">        git reset --hard origin&#x2F;【你的分支名】</span><br><span class="line">        git pull</span><br><span class="line">        #设置目录权限</span><br><span class="line">        chown -R www:www $gitPath</span><br><span class="line">        echo &quot;End&quot;</span><br><span class="line">        exit</span><br><span class="line">else</span><br><span class="line">        echo &quot;该项目路径不存在&quot;</span><br><span class="line">        echo &quot;End&quot;</span><br><span class="line">        exit</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>添加webhook后，参考上方内容与仓库进行链接即可。</p><h3 id="创建站点-1"><a href="#创建站点-1" class="headerlink" title="创建站点"></a>创建站点</h3><p>如图点击添加站点。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073316.png" alt="mark"></p><p>添加域名可以加前缀，但加了前缀也要加入对应的解析。根目录后面一定要是public文件夹，生成的静态页面会保存在该文件夹中，只有将该文件夹设为根目录网站才会正常显示，最后点击提交即可创建。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073320.png" alt="mark"></p><p>然后回到服务器，安装必要包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo --save</span><br><span class="line">npm install --save hexo-deployer-git</span><br></pre></td></tr></table></figure><p>输入github的用户名与密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.email &quot;【github邮箱】&quot;</span><br><span class="line">git config --global user.name &quot;【github用户名】&quot;</span><br></pre></td></tr></table></figure><h3 id="配置SSH"><a href="#配置SSH" class="headerlink" title="配置SSH"></a>配置SSH</h3><p>配置SSH免去每次推送都要帐号密码，任意地方输入下方指令，【注释】部分可用自己邮箱，github,也可以不加<code>-C</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;【注释】&quot;</span><br></pre></td></tr></table></figure><p>中间都按回车就行了，然后到ssh存放的地方</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~&#x2F;.ssh</span><br><span class="line">vim id_rsa.pub</span><br></pre></td></tr></table></figure><p>打开id_rsa.pub后，复制里面的公钥（用finalshell的话直接在下方的文件目录里双击打开也可以）</p><p>然后到如图地方添加公钥</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073333.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073337.png" alt="mark"></p><p>然后到仓库的地方，复制ssh地址</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073342.png" alt="mark"></p><p><img src="http://blogimg.wa2000.cn/blog/20200223/pTndRV7uRMpW.png?imageslim" alt="mark"></p><p>（若本来就是ssh地址则跳过）打开根目录的配置文件_config.yml，将deploy下的repository改为ssh地址。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073349.png" alt="mark"></p><p>在博客的根目录下生成静态页面并尝试推送到github</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>注：若出现下方情况则使用下方命令删除<code>.user.ini</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chattr -i 【.user.ini路径】</span><br><span class="line">rm -rf 【.user.ini路径】</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073354.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073400.png" alt="mark"></p><p>若出现下方情况则修改ssh配置</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073406.png" alt="mark"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config</span><br></pre></td></tr></table></figure><p>找到 RSAAuthentication与PubkeyAuthentication，将注释去掉，并确定AuthorizedKeysFile后面为<code>.ssh/authorized_keys</code>且可用。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073410.png" alt="mark"></p><p>然后重启ssh服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;sbin&#x2F;service sshd restart</span><br></pre></td></tr></table></figure><p>再次执行<code>hexo d</code>可能会出现下方警告</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073413.png" alt="mark"></p><p>该警告是让你将github的IP加入host，可以无视，也可以加进去去掉警告。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;hosts</span><br></pre></td></tr></table></figure><p>然后在里面加入<code>【警告中的IP地址】 github.com</code>，保存并退出即可。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073417.png" alt="mark"></p><p>清除、生成、推送都成功后，重启宝塔面板</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;etc&#x2F;init.d&#x2F;bt restart</span><br></pre></td></tr></table></figure><p>重启后，在本地使用推送将博客源代码推到github时，服务器上会自动拉取进行同步。</p><p>接下来就是在服务器上开启远程后台管理了。</p><h1 id="开启后台管理（舍弃）"><a href="#开启后台管理（舍弃）" class="headerlink" title="开启后台管理（舍弃）"></a>开启后台管理（舍弃）</h1><p>使用hexo-admin插件开启后台管理功能，可以通过网页进入后台管理文章，也可以通过内置的脚本实现部署与推送。</p><h2 id="放行4000端口"><a href="#放行4000端口" class="headerlink" title="放行4000端口"></a>放行4000端口</h2><p>到宝塔面板的安全里放行4000端口，说明随意填。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073800.png" alt="mark"></p><p>以腾讯云为例，到服务器的管理处放行4000端口。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073648.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073809.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073824.png" alt="mark"></p><p><strong>注意</strong>：<code>hexo s</code>命令不支持https，在输入网站时不要加https</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073828.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073834.png" alt="mark"></p><h2 id="测试推送"><a href="#测试推送" class="headerlink" title="测试推送"></a>测试推送</h2><p><a href="https://git-scm.com/docs" target="_blank" rel="noopener">git操作官方文档</a>，或者百度git指令查询详细用法。</p><p>在根目录处执行下方执行指令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m &quot;【更新说明，随便填】&quot;</span><br><span class="line">git push origin 【博客源代码分支名】</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073840.png" alt="mark"></p><p>出现上方提示说明可以进行推送。</p><p>如果保存源代码的分支不是默认的，要在<code>git push</code>后面空一格加上<code>origin 【博客源代码分支名】</code></p><p>若提示</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073843.png" alt="mark"></p><p>则输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin 【github仓库的ssh地址】</span><br></pre></td></tr></table></figure><h2 id="编写脚本"><a href="#编写脚本" class="headerlink" title="编写脚本"></a>编写脚本</h2><p>在根目录创建一个文件夹存放脚本（直接放根目录也行，但后面记得更改配置的路径），名称随意，我用admin作为文件夹名，deploy作为脚本名。然后进入创建的文件夹，新建并编辑一个脚本文件</p><p>我的代码为<code>mkdir admin</code>与<code>vim deploy.sh</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir 【新建的文件夹】</span><br><span class="line">cd 【创建的文件夹】</span><br><span class="line">vim 【脚本名】.sh</span><br></pre></td></tr></table></figure><p>在脚本文件中输入下方指令，“save blog”里面是更新说明，自定义填写。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/usr/bin/env sh</span></span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>然后按ESC，接着输入<code>:wq</code>保存并退出。</p><p>这样当用后台管理时，会先生成静态页面，再进行部署，部署完成后会将源代码推送到github。</p><p>可自行修改需要的命令，例如加入<code>hexo clean</code>，也可以加一些其他自己需要的命令。</p><p>为刚刚脚本授予权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x 【脚本名】.sh</span><br></pre></td></tr></table></figure><p>然后执行该脚本看看效果，如果一切顺利，则可以进行下一步。效果大概如图：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073849.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073853.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073856.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073901.png" alt="mark"></p><p>脚本配置好后，开启开机自动启动<code>hexo s</code>命令来启动后台，因为hexo-admin</p><p>在创建的存放脚本的文件夹中新建自启脚本（同样名称自定义）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd 【存放脚本的文件夹】</span><br><span class="line">vim 【自启脚本文件名】.sh</span><br></pre></td></tr></table></figure><p>然后输入命令，cd后面的路径要换成自己的博客根目录路径，例如我的为<code>cd /www/wa2000</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">cd 【博客根目录路径】</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><p>写完后同样按ESC，输入<code>:wq</code>保存并退出</p><p>添加权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x 【自启脚本名】.sh</span><br></pre></td></tr></table></figure><p>然后返回服务器的根目录，打开<code>etc/rc.d/rc.local</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">vim &#x2F;etc&#x2F;rc.d&#x2F;rc.local</span><br></pre></td></tr></table></figure><p>在下面添加脚本路径，如我的脚本存放目录为<code>/www/blog/admin/server.sh</code>，添加效果如下</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073906.png" alt="mark"></p><p>然后保存并退出。</p><p>执行下方命令授权</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x &#x2F;etc&#x2F;rc.d&#x2F;rc.local</span><br></pre></td></tr></table></figure><p>然后重启服务器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure><p>稍等片刻进入<code>http://【域名】:4000</code>，若能进入，说明配置成功。</p><h2 id="安装hexo-admin并配置"><a href="#安装hexo-admin并配置" class="headerlink" title="安装hexo-admin并配置"></a>安装hexo-admin并配置</h2><p>参考文档：<a href="https://easyhexo.com/4-High-order-hexo-gamer/4-1-remote-editing/#三、在本地安装-hexo-admin" target="_blank" rel="noopener">Easy Hexo</a>    <a href="https://jaredforsyth.com/hexo-admin/" target="_blank" rel="noopener">hexo-admin官网</a></p><p>服务器上进入博客根目录，然后输入命令安装hexo-admin</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-admin</span><br></pre></td></tr></table></figure><p>安装完成后即可通过<code>http://【域名】:4000/admin</code> 进入后台。接下来进行一些配置。</p><p>进入后台的设置界面，点击红框内的链接。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073910.png" alt="mark"></p><p>如图，填入登陆后台用的用户名与密码，secret能为密码进行加密，随意填自己喜欢的短语就行。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073919.png" alt="image-20200223201005011"></p><p>将生成的代码拷贝到博客根目录下的配置文件<code>_config.yml</code>中，并添加deployCommand</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073925.png" alt="mark"></p><p>deployCommand的内容单引号内为一条指令</p><p><code>./admin/deploy.sh</code>指运行保存在admin文件夹内的deploy.sh，将路径改为自己的脚本运行指令即可。</p><p>保存，然后重启服务器。</p><h1 id="关于网站备案的琐事"><a href="#关于网站备案的琐事" class="headerlink" title="关于网站备案的琐事"></a>关于网站备案的琐事</h1><p>到购买服务器/域名的服务商那里有详细的备案流程说明，这里仅记录个人备案遇到的坑。以腾讯云举例。</p><blockquote><p><a href="https://cloud.tencent.com/document/product/243/18958" target="_blank" rel="noopener">腾讯云备案流程</a></p></blockquote><ol><li><p>国家规定服务器需要购买至少3个月才能备案</p><p>学生套餐优惠只能购买三次，一次最短购买一个月时长，最长为一年时长，本来抱着试试的心态只买了一个月，结果发现居然要至少3个月才能备案，于是只能再去用学生套餐来延长时长，本来三次机会，结果花了两次机会只买了一年一个月，如果确定想用大陆服务器并且想长时间使用的话，建议一次购买最长时长，10元/月算非常便宜了。</p></li><li><p>审核时间长</p><p>首先需要先为域名进行实名认证，实名认证后备案需要申请幕布进行拍照(给你邮过去，免邮)，等幕布到了以后按要求拍照并上传，填写关于网站的资料以及服务器的资料，最后提交。</p><p>大概腾讯那边审核一两天，然后腾讯帮你提交到审核局审核个10天左右(最晚一个月，个人经历时间为10天左右)，审核通过后会给你工信部备案号，但还要到<a href="http://www.beian.gov.cn/portal/index.do" target="_blank" rel="noopener">全国互联网安全管理服务平台</a>再提交一次备案，不过这个审核较快，一天就通过了。通过后会给你联网备案号。</p><p>以百度为例<img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324073929.png" alt="mark">上面的为工信部备案号，下面的为联网备案号。</p></li><li><p>关于在<strong>全国互联网安全管理服务平台</strong>备案</p><p><strong>注意</strong>：里面有一个为网站填写信息的，有个选择网站是否为交互类型，如果不是论坛、有注册功能的那种一定要选择否，选是的话需要到当地公安局一趟进行当面审核。这是为了保证网站安全所以需要到公安局进行审核，并且填写大概7-8页厚的表格。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> github </tag>
            
            <tag> webhook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo写作简易化</title>
      <link href="/post/202002220037/"/>
      <url>/post/202002220037/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>hexo写文章不像WordPress与Typecho那样拥有后台管理系统，每次都要新通过指令新建文章（若本地创建的话没有配置的front-matter），并且写完后还要清除缓存，生成页面，然后部署。<br>而且hexo上传到网上的文章要考虑一个图床的问题，图片若不是url链接是无法在网上被访问到的。<br>hexo也缺少一个方便的、随时随地修改文章的后台管理。<br>于是写篇文章记录我简化写作的的过程。</p><a id="more"></a><h2 id="使用HexoEditor进行写作"><a href="#使用HexoEditor进行写作" class="headerlink" title="使用HexoEditor进行写作"></a>使用HexoEditor进行写作</h2><p>点击进入项目地址：<a href="https://github.com/zhuzhuyule/HexoEditor" target="_blank" rel="noopener">HexoEditor</a><br>HexoEditor的优点：<br>    1. 读取hexo的post模板生成文章<br>        2. 可以在软件上清除缓存、生成页面、推送，也可以直接一键部署<br>        3. 支持图床链接<br>HexoEditor的缺点：<br>        1. 没有文件目录<br>        2. 没有文章目录<br>        3. 个人遇到了腾讯云无法配置图床以及七牛云图床链接缺少一个’/‘的问题 </p><h3 id="安装："><a href="#安装：" class="headerlink" title="安装："></a>安装：</h3><p>到HexoEditor的github地址，下载压缩包解压即可。<br><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023219.png" alt="mark"></p><h2 id="使用Typora进行写作"><a href="#使用Typora进行写作" class="headerlink" title="使用Typora进行写作"></a>使用Typora进行写作</h2><p>Typora<a href="https://typora.io/" target="_blank" rel="noopener">官方网站</a><br>Typora具有写作即样式的效果，使用markdown的语法后会直接将该部分文字转为markdown的样子，真·所见即所得。<br>这是刚写完的一句话<br><img src="D:%5Cblog%5Csource_posts%5Chexo%E5%86%99%E4%BD%9C%E7%AE%80%E6%98%93%E5%8C%96.assets%5C4ubdJFf3jImV.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023224.png" alt="mark"></p><p>当光标没有聚焦在该部分时，就会自动转为markdown样式，当光标再次回来时又会变成文本。<br>当然，因为Typora是一个markdown写作软件，不是专为hexo订制，所以写完后还是要通过命令行指令进行部署。</p><h2 id="关于图床"><a href="#关于图床" class="headerlink" title="关于图床"></a>关于图床</h2><p>有很多能存储图床的服务商，有域名的话可以选择自己域名的服务商提供的空间存储，也可以使用七牛云（个人目前使用），免费的图床有sm.ms。下面以个人使用的七牛云为例优化写作时的图片插入问题。</p><h3 id="使用HexoEditor（舍弃）"><a href="#使用HexoEditor（舍弃）" class="headerlink" title="使用HexoEditor（舍弃）"></a><del>使用HexoEditor</del>（舍弃）</h3><p>因七牛云的链接会缺少一个’/‘符号，导致要手动添加，腾讯云又无法配置，故不推荐使用，若用sm.ms作为图床的话可以使用（个人没有sm.ms，所以没有测试是否存在问题)</p><hr><p>HexoEditor仅支持截图，不支持复制图片。<br>HexoEditor自带上传然后转化功能。只需要填好该三项，存储空间与域名会自动显示出，然后自行选择即可。<br>进入七牛云的密钥管理（HexoEditor右键空白处有快速打开能进入七牛云主页）。<br><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023222.png" alt="mark"><br>可以看到对应的密钥，隐藏的话点击显示即可复制。<br><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023223.png" alt="mark"><br>AK粘贴到AccessKey，SK粘贴到SecretKey，就完成配置了。<br>用法举例：<br>当截图后，会在本地保存图片，如下图所示，</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023221.png" alt="mark"><br>右键空白处，点击上传 七牛，链接会自动转化为七牛云存储空间里的URL，并且是整篇文章的图片全部转化。</p><h2 id="使用Mpic"><a href="#使用Mpic" class="headerlink" title="使用Mpic"></a>使用Mpic</h2><p><a href="http://mpic.lzhaofu.cn/" target="_blank" rel="noopener">Mpic官网</a><br>这是我一直在用的类似小工具一样的东西，支持截图（看更新日志说是QQ截图，不知其他截图是否支持）、复制、拖拽均可自动上传并复制URL，还可以查看上传目录并且复制链接或者删除（但没有预览图，可以复制URL地址粘贴到网址栏然后查看）<br><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023226.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023225.png" alt="mark"></p><p>配置方法参考上方HexoEditor的配置，但域名、空间名需要自己填写。</p><h1 id="使用Hexo-admin实现后台管理"><a href="#使用Hexo-admin实现后台管理" class="headerlink" title="使用Hexo-admin实现后台管理"></a>使用Hexo-admin实现后台管理</h1><p>hexo-admin有个缺点是只能在开启<code>hexo server</code>时才能进行管理。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><a href="https://jaredforsyth.com/hexo-admin/" target="_blank" rel="noopener">hexo-admin官网</a><br>在下方可以看到安装流程</p><p>若已经安装过hexo和创建好博客根目录了，则直接安装插件即可。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023229.png" alt="mark"></p><p>在博客根目录内右键空白处，点击<code>Git Bash Here</code></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023227.png" alt="mark"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-admin</span><br><span class="line">hexo server -d</span><br></pre></td></tr></table></figure><p>然后打开浏览器输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;localhost:4000&#x2F;admin&#x2F;</span><br></pre></td></tr></table></figure><p>即可进入后台管理。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023228.png" alt="mark"></p><p>Posts为文章列表<br>Pages管理hexo的页面<br>About是关于插件与hexo的信息<br>Deploy可以部署一些脚本<br>左边为写作区，右边为预览区，右上角有删除、文章设置与发布（这个发布仅仅部署在本地，未推送）。<br>文章会自动保存，同时也支持复制图片URL（但是我用的Mpic,hexo-admin的图片老是裂开）<br><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023230.png" alt="mark"><br>点击发布后，会变成Unpublish，再次点击会取消在本地的部署。并且发布后，在这里编辑的内容可以在本地服务器上事实预览。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023231.png" alt="mark"></p><p><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407221243.png" alt="mark"></p><h2 id="为后台添加密码"><a href="#为后台添加密码" class="headerlink" title="为后台添加密码"></a>为后台添加密码</h2><p>可以设置是否需要帐号密码进入后台。（设置后每次hexo clean后登陆都要帐号密码）<br>点击Settings，点击如图所示的链接<br><img src="https://gitee.com/lluuiq/blog_img/raw/master/img/20200407221234.png" alt="mark"><br>然后填好帐号与密码，Secret是加密用的，内容不用改。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023233.png" alt="mark"><br>最下面会生成一段代码，将这些拷贝到网站根目录下的配置文件<code>_config.yml</code>，然后保存即可。</p><h2 id="实现一键部署"><a href="#实现一键部署" class="headerlink" title="实现一键部署"></a>实现一键部署</h2><p>按照写脚本部署的方法windows不知道是因为权限问题还是不支持的问题，部署一直报错，查阅github上的issue后找到了作者给出的解决办法。<br>issue链接：<a href="https://github.com/jaredly/hexo-admin/issues/94" target="_blank" rel="noopener">https://github.com/jaredly/hexo-admin/issues/94</a><br>直接打开根目录下的node_modules文件夹，再打开hexo-admin文件夹，编辑器打开deploy.js，<br>将</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var proc &#x3D; spawn(command, [message], &#123;detached: true&#125;);</span><br></pre></td></tr></table></figure><p>改为（把原来的注释掉，换成下面这行代码即可）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var proc &#x3D; spawn((process.platform &#x3D;&#x3D;&#x3D; &quot;win32&quot; ? &quot;hexo.cmd&quot; : &quot;hexo&quot;), [&#39;d&#39;, &#39;-g&#39;]);</span><br></pre></td></tr></table></figure><p>结果如图：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023232.png" alt="mark"></p><p>改完后要通过在网站根目录打开Git Bash 然后输入<code>hexo clean</code>清除缓存，之后输入’hexo g’重新生成静态页面，启动本地服务器即可。<br>回到hexo admin的部署界面，直接点击Deploy，效果如下<br><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324023234.png" alt="mark"><br>可以看到 Std Output里的内容说明部署成功，下方的警告是指windows与linux的换行符问题，可以无视。</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>考研成绩总结</title>
      <link href="/post/202002201905/"/>
      <url>/post/202002201905/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>20届的考研，今天查了考研成绩，结果在预料之中，不算非常失望，但也没有带来意外的惊喜。总结下考研的过程，也可以给想考研的人一些参考（学霸就当看笑话就行了）。</p><p>成绩不高，毕竟人傻学习差，但已经满意了，要说遗憾的就是数学考砸了。</p><a id="more"></a><h1 id="成绩"><a href="#成绩" class="headerlink" title="成绩"></a>成绩</h1><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030704.png" alt="mark"></p><h1 id="关于准备时间"><a href="#关于准备时间" class="headerlink" title="关于准备时间"></a>关于准备时间</h1><p>因个人的专业方向选择了大数据相关，发现该专业相关岗位大部分要求学历要高，而本人仅仅是个三本渣渣，2019年7月初有了考研的想法，7月30号开始学习，而在此之前没有该想法时报了学校内的实训，导致中间还有一个月的时间参与实训，又缩短了学习的时长。但是感谢实训的老师能睁一只眼闭一只眼，让我在实训过程中也能抽空学习。</p><h1 id="关于报考"><a href="#关于报考" class="headerlink" title="关于报考"></a>关于报考</h1><p>报考院校为南京信息工程大学 人工智能学院，双非，大气专业一流学科。</p><p>专业计算机科学与技术，学硕。</p><p>考虑自己准备时间仅仅4个月，赶不上别人一两天准备的进度，故放弃985与211。</p><p>目标确定为双非后，筛掉高人气的学校，如杭电、南邮，因为竞争激烈，如果我是准备了一年的时间的话还可以考虑。在7月份看了很多学校，如浙江工业大学、浙江工商大学、宁波大学、南京理工大学、江苏科技大学、南京工业大学、南京审计大学、南京信息工程大学、<del>东南大学</del>(???)、成都理工大学、重庆邮电大学、河南工业大学、安徽理工大学、青岛大学、燕山大学等等。</p><p>因为比较宅(上海举办的活动多)加上想去长三角，所以目标确定为浙江、江苏。为什么不考虑上海嘞？因为上海是个旱区，而且我有自知之明复试会被刷。</p><p>最后考虑到自己时间不够，所以报考院校的专业课最好只有一门，而且是简单点的，学校又要好，计算机专业又强的(<del>又想好，又想好考</del>)最后确定目标为南京信息工程大学，计科学硕考试科目：政治、英一、数一、C语言。为什么选学硕不选专硕嘞？因为当时的相关信息是只招学硕，到9月学校发出招生目录时发现今年新增了专硕，同时有的学校专业课改考408，这也导致了南信的报考人数突然激增了。而且新建了一个学院(人工智能学院)，以前的30+名额划分了一半给新学院….. 这就导致了计算机学院就17个名额、人工智能学院14个名额(研招网数据)。南信大实力越来越强了，今后考研选南信大的话难度会上升。</p><p>考虑自己的情况，数学成绩平时还算不错，但英语是真的渣，政治还可以，C语言是强项(课本内容限定)，最后决定还是报学硕，因为专硕人太多，鬼知道有什么妖魔鬼怪。</p><p>我英语很差，属于初中词汇有的都还不认识的，比如分不清 影响<code>affect、effect</code>、期望<code>expect</code>、专家<code>expert</code>。英一英二对我来说都一个样，(后来发现如果考英二的话，成绩还是会比英一高10分左右的，不过也差不多了)。</p><p>数学一相比数学二多了高数部分内容以及概率，线代多的那点部分比较简单，自认为数学应该不会太差于是确定最后还是报考学硕，事实证明数学选学硕专硕最后结果好像差不多。</p><h1 id="学习过程"><a href="#学习过程" class="headerlink" title="学习过程"></a>学习过程</h1><p>首先自己是个晚上经常睡不着的人，晚上1点–3点睡已经成了日常了，要闭眼至少10分钟才能入睡，经常因为睡觉时闭上眼睛感觉眼前一片发白难以入眠，有几次一晚都睡不着(失眠)。一般都睡到中午12点左右，不管早睡晚睡。后来干脆晚上都是4–5点睡觉，然后12点起来吃饭，除了吃饭时会看看假面骑士、番剧、星际炉石直播等，其余时间一直学习。</p><p>推荐一个微信公众号：考研学子，分享很多爱心分享版课程，包括一些难搞到的。</p><p>资源下载网站：<a href="http://kyxz.ys168.com/" target="_blank" rel="noopener">http://kyxz.ys168.com/</a></p><h2 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h2><p>主要学习内容就是数学，毕竟是个重点项目。在大学学习时，高数和线代起码还有听过课。高数一般，线代学的不错。高数属于快考试了赶紧学学，平时作业都是抄。线代就是学的比较好，题都能做出来，最后期末考90分。（然而后来全忘了。）。概率是我大学时唯一一个根本没听过的课，上课全在玩手机，期末突击了一下基本压着线过的。然而考研结束后，线代白给，概率成了拿分点。</p><p>最开始看的汤家凤老师的高数基础，然后看的李永乐老师的线代，王式安老师的概率，都说李永乐线代地位无可撼动，但个人有的地方听不懂，后来去看了方浩的线代，听懂了一些，然后又听不懂了，最后直接看书自学了。</p><p>概率是打从一开始就没听懂，最后问了朋友一些概率重点，理清了概率这部分的框架，然后看了汤老师的概率提高班。</p><p>第二遍时高数看的武钟祥老师，发现武钟祥的讲课内容与思路就非常适合我。线代在自学遇到不懂的地方就看李永乐的课。概率自学，整理知识点。</p><p>练习题因为时间短，没有选择1800题，最开始做的张宇的1000题，后来感觉这都什么J eight ，直接让书吃灰去了，然后选择了330+660（然而到考试都没做完）。在11月的时候发现某宝上李林老师的书卖的非常便宜，只要几块钱，就买了。主要是我室友不考了，给了我很多数二的书，导致我的书架上有好几个老师的各种数学书……光数学相关的就占了我一个桌子长度的1/3，等开学返校了拍个照看看都有什么。草稿纸在全力投入数学的时间内基本两天一本（草稿纸一张写的很乱，没有排版一样的去用，但是正反两面都写完了再用下一本）。笔芯是一天一杆左右，这里推荐下听雨轩这个牌子的笔芯，是真的好用，不会有断墨现象，笔摔地上了拿起来还能用。</p><p>11月份才直到关于李林老师的事，最后我也做了他的题，听了一点课（他的绝密押题班能听就听，虽然在互联网的伟大实力下已经不绝密了，而且我考试的这一年只压中了数二的一道大题，有人说数一压中了一道，但我怎么都没找到）。</p><p>我学习是几乎不做笔记的，因为做了也不会看，比较喜欢理解原理然后掌握内容，数学的笔记我只做了知识点框架和解题方法，把解题方法与对应的知识点写在一起，写在纸上然后夹在书里，因为写在书上我经常找不到或者为了找到对应的笔记浪费时间，而且我没有笔记本，因为感觉把笔记夹在书上的对应章节里更简单省事。</p><p>概率理清后我倒是自己写了大概4–5张纸的笔记 ，主要记随机变量分布、数字特征、样本统计量、大数定理中心极限定理的知识点以及公式、相关题型的求法，比如怎么求知X、Y的分布求Z的，然后对应各种情况的解法写上去，最后订起来忘了就看，临近考试时每天看一遍。</p><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><p>英语本来就没基础，时间又短，中间试过几天用那个什么遗忘曲线背多少单词，然后过段时间全忘了，已经没救了，直接放弃。</p><p>在最后还剩1个月的时间准备了下英语的大小作文模板，顺便准备了四级的。看的刘晓艳老师的课，模板讲的非常好，还会讲很多题型该怎么做，比如翻译该怎么翻译，不会翻的怎么办，她的保命班确实保了我英语刚好压线（大概过了），强力推荐，英语无论好的还是差的都可以看。</p><p>关于作文模版，我是参考刘晓艳老师讲的结构，然后自己想好中文，接着各种百度查、用有道、问同学翻译出优美点的，通用的句子，主题词的空一挖，到时候考啥填啥。比如考到积极乐观的品质相关的（勤奋、勇敢、乐观、孝顺等等），写一个：文学巨匠鲁迅曾经说过：“XX是一个人通往成功所必备的品质”（Lu Xun, a literary giant, once said that x is a necessary quality for a man to succeed），翻译是用百度翻译出来的，实际写的不是这个，做了修改。也可以换成其他人说过啥啥怎么样。四级同样可以用模板，对应不同的题型（书信、图画、议论等）各准备一个就行了。</p><h2 id="政治"><a href="#政治" class="headerlink" title="政治"></a>政治</h2><p>政治我无脑推荐徐涛老师，本来政治的内容就很枯燥，但徐涛老师的课让我对哲学和近代史提起了很大兴趣，尤其是马哲部分，难以理解的内容他总能用恰当的例子让你明白这部分什么意思，也多亏了他我政治取得了自认为还算不错的成绩。做题就肖秀荣的1000题还有肖4肖8（然而今年纯背肖4的话有点危险，压中的没有往年多，但如果理解了肖4的答题原理还是轻松的），但我1000题没有做完，基本只做了一半，徐涛的优题库几乎做完了，毕竟喜欢看徐涛的视频，可以做完看他的讲解。</p><p>关于政治的背诵，我是几乎没有背，选择题一些经常考的匹配的背会就行了（我还绝大部分都没背，个人真不适合背东西，背了就忘，反复背还是能忘），比如XX时期对待富农的态度是，我国的基本政治是。最后狂背肖4，按肖老师给的优先顺序，把重要的背了，其他的实在记不住了，而且时间不也不够。</p><p>马哲部分一定要去理解，可以既背又理解，但理解了其实很多都不用背，所以千万不要死记硬背。马哲不像近代史、毛中特、思修那样答案出来直接选，它的题都是挖掘题目中的故事信息，然后选择符合这个题意的选项，也就是说答案可能全是对的，要找出题目想让你选什么。也有可能马哲里直接出现错误的选项，如人人创造历史，这种就相当于给放水了。</p><p>近代史一定要捋清时间线，历史很好的话近代史学起来会轻松很多，最好理解当时的国情去学习，用当时的思想去体会能好学很多，下面举个例子，可以直接不看，也可以当我讲故事。</p><hr><p>鸦片战争后老外侵入我国，太平天国（农民）起身反抗最后失败，然后高官中也想救国（洋务运动），但因为当时思想腐朽，而且高官想维护自己的统治地位，所以只学西方的技术，不学西方的体制（也就是中体西用），然后一个甲午战争直接全没了，不仅把洋务运动给打没了，而且列强发现wocao原来中国这么好欺负，就来瓜分我们，中华民族也由此意识到再这样下去不行了，投入这么大的项目结果一战全没了，还是被当年的弟弟日本给打败的，普遍意识觉醒，当然战争结束后要签署条约进行赔款，所以签订了《马关条约》。后来戊戌变法，先进知识分子总结了失败的原因，认为洋务运动只学了技术，没有学体制，认为别人西方君主立宪制才会这么diao，所以主张立宪，这也是与洋务运动的辩论战的主要点（要不要君主立宪），当然最后失败了，因为他们企图让腐败的清政府悔改，但人家清政府好好的官坐着，怎么能说放弃就放弃。再后来辛亥革命时，孙中山先生认为指望政府没救了，打算领一帮精英要用暴力手段直接干掉清政府，强行改变，这也是第二次辩论战的主要点（要不要武力推翻清政府）。辛亥革命成功推翻了清政府，但实际是失败的，因为袁世凯隔岸观火最后渔翁得利，逼迫孙中山交出政权想称帝。可以发现，除了太平天国，其他的革命都没有动用人民群众的力量。徐涛也讲过这些运动失败的原因，里面都有一个阶级局限性，意思就是你们这个阶级就决定了你们都是five，只有我(dang)能救中国。毕竟政治考的是立场，不是研究对与错的问题，心中有dang，成绩理想是有道理的。</p><hr><p>毛中特在学习近代史后结合国情去理解一些政策会好懂很多，因为毛中特学的并不好（有大量要记的东西），所以没法讲出有参考价值的东西。思修我就没怎么看过，除了法律很多用常识就可以解题（只要不反人类）。</p><p>近代史一般多选答案要么全对，要么对三个，习大大说的全是对的，不知道符合不符合题意的选项只要它说的对就选。</p><h2 id="专业课"><a href="#专业课" class="headerlink" title="专业课"></a>专业课</h2><p>这个就没有参考价值了，因为我本来C语言学的就不错，考研学习期间C语言看的时间不到一周，考试时又几乎全是练习题原题，稳过。</p><h1 id="考完后"><a href="#考完后" class="headerlink" title="考完后"></a>考完后</h1><h2 id="数学-1"><a href="#数学-1" class="headerlink" title="数学"></a>数学</h2><p>选择和填空还可以，一共错了4道，有一道求行列式的第一遍做对了，结果检查一遍后写了个错的上去，草（中日双语）。在做出6道题后，靠总结的历年选择比例 <code>3:2:2:1</code> 以及 <code>2:2:2:2</code>把不会的蒙上去了。最后好像选择错了一道，填空错了3道。</p><p>大题直接白给。</p><p>高数第一道大题求最大值，把公式给忘了，但靠中间解题的步骤给了步骤分。求曲线积分的对了一道。证明和空间曲线就当场死亡，证明题本来就是放弃的，空间曲线加了个函数=白给。</p><p>线代今年改成了一个二阶矩阵，而且题改成了给出变化过程求参数（这个真不应该，准备了很久变换的写法，结果改成了求参数，按理说应该能算出来），脑子短路了，临近考试瞎写了一些上去。第二道看到证明就知道完了，汤家凤的1800题里是原题，但是我没做过。线代本应是个稳拿分点，结果成了稳失分点。（但除了学霸，大部分人线代都做的不好，应该是不适应这种题型）</p><p>应该是看到线代完了心态直接崩了，概率第一题的第一问做错了（写出来了，但最后对答案发现错了），好在第二问做对了（大概）。第二题就是全对了，毕竟概率的出题风格相对稳定，最后一道都是最大似然估计，平时做题也很注重这一点。</p><h2 id="英语-1"><a href="#英语-1" class="headerlink" title="英语"></a>英语</h2><p>我的英语没啥好说的，能不能过全靠上天，模板写的还可以，就是把大作文的习惯写成了behavior，草（中日双语）。最后应该是压线过。</p><h2 id="政治-1"><a href="#政治-1" class="headerlink" title="政治"></a>政治</h2><p>政治选择发挥的不错（指较平时做题），平时做题时差了22-25分，最高的一次32分，考完对答案估分选择大概在34~36左右。大题因为只背了肖4和15个坚持，答的不够好，全靠自己的政治精神补充内容。</p><p>在大题有一道写出社会主义核心价值观的，当时突然把社会的自由平等给忘了，抬头四顾心茫然，绝望之中发现在考场的黑板旁挂着牌子，上面写着鲜亮的社会主义核心价值观几个大字，直接对着抄上去了。</p><h2 id="专业课-1"><a href="#专业课-1" class="headerlink" title="专业课"></a>专业课</h2><p>选择填空写的非常顺利，可以确定全对。三道编程题一道10分，只写出了一道，另外两道需要学习一个算法。考完看群，有人说写的暴力破解的方法，但当时我没想到:cry:。最后随便写了一些上去，不管对不对了，认为起码给点步骤分吧，结果一份都没给。估分时认为130分起步，步骤分给一点能130+，结果成绩130。</p><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>国家线应该是过了，但复试线很悬，又不想参加调剂，毕竟学历差，成绩也不算高，调不到好的学校。打算如果没过复试线就找工作，找不到的话再二战。</p><p><strong>更新：</strong> 已被录取。</p>]]></content>
      
      
      <categories>
          
          <category> 人生相谈 </category>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 考研 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>markdown文章显示测试</title>
      <link href="/post/202002201856/"/>
      <url>/post/202002201856/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="这是一个测试用的文档，该句也是一级标题"><a href="#这是一个测试用的文档，该句也是一级标题" class="headerlink" title="这是一个测试用的文档，该句也是一级标题"></a>这是一个测试用的文档，该句也是一级标题</h1><h2 id="这是二级标题"><a href="#这是二级标题" class="headerlink" title="这是二级标题"></a>这是二级标题</h2><h3 id="这是三级标题"><a href="#这是三级标题" class="headerlink" title="这是三级标题"></a>这是三级标题</h3><h4 id="这是四级标题"><a href="#这是四级标题" class="headerlink" title="这是四级标题"></a>这是四级标题</h4><h5 id="这是五级标题"><a href="#这是五级标题" class="headerlink" title="这是五级标题"></a>这是五级标题</h5><p>接下来是阅读更多 <a id="more"></a></p><p>接下来的测试内容用二级标题标注</p><h2 id="分隔符："><a href="#分隔符：" class="headerlink" title="分隔符："></a>分隔符：</h2><p>第一行，接下来加入分隔符</p><hr><p>第二行，与第一行之间有分隔符</p><h2 id="加粗："><a href="#加粗：" class="headerlink" title="加粗："></a>加粗：</h2><p>正常文字 vs <strong>加粗文字</strong></p><h2 id="斜体："><a href="#斜体：" class="headerlink" title="斜体："></a>斜体：</h2><p>正常文字 vs *斜体文字</p><h2 id="删除线："><a href="#删除线：" class="headerlink" title="删除线："></a>删除线：</h2><p>正常文字 vs <del>删除线文字</del></p><h2 id="代码框："><a href="#代码框：" class="headerlink" title="代码框："></a>代码框：</h2><p>正常文字 vs <code>代码框内文字</code></p><h2 id="高亮："><a href="#高亮：" class="headerlink" title="高亮："></a>高亮：</h2><p>正常文字 vs ==高亮==</p><h2 id="添加注释："><a href="#添加注释：" class="headerlink" title="添加注释："></a>添加注释：</h2><p>正常的内容正常<a href="注释内容注释内容注释内容">^注释</a>的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容正常的内容。</p><h2 id="角标："><a href="#角标：" class="headerlink" title="角标："></a>角标：</h2><p><strong>上角标：</strong>写个X的平方+Y的平方：x^2^+y^2^</p><p><strong>下角标：</strong>写个H2O：H<del>2</del>O</p><h2 id="数学公式："><a href="#数学公式：" class="headerlink" title="数学公式："></a>数学公式：</h2><p>公式写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x^2 + x^2 &#x3D; 2x </span><br><span class="line">\\</span><br><span class="line">f(x)&#x3D;\frac&#123;1&#125;&#123;\sqrt&#123;2\pi\sigma&#125;&#125;exp(-\frac&#123;(x-\mu)^2&#125;&#123;2\sigma^2&#125;)</span><br></pre></td></tr></table></figure><p>效果如下：<br>$$<br>x^2 + x^2 = 2x<br>\<br>f(x)=\frac{1}{\sqrt{2\pi\sigma}}exp(-\frac{(x-\mu)^2}{2\sigma^2})<br>$$</p><h2 id="列表："><a href="#列表：" class="headerlink" title="列表："></a>列表：</h2><p><strong>有序列表：</strong></p><ol><li><p>第一行</p></li><li><p>第二行</p><ol><li><p>第二行的子行1号</p></li><li><p>第二行的子行2号</p><p>突然无序的行</p><p>3.忽然有序的行</p></li></ol></li></ol><p><strong>无序列表：</strong></p><ul><li>第一行</li><li>第二行</li></ul><h2 id="表格："><a href="#表格：" class="headerlink" title="表格："></a>表格：</h2><table><thead><tr><th>one</th><th>two</th><th>three</th></tr></thead><tbody><tr><td>two</td><td></td><td></td></tr><tr><td>three</td><td></td><td></td></tr><tr><td>four</td><td></td><td></td></tr></tbody></table><h2 id="链接："><a href="#链接：" class="headerlink" title="链接："></a>链接：</h2><p><a href="https://www.baidu.com" target="_blank" rel="noopener">百度</a></p><h2 id="代码块："><a href="#代码块：" class="headerlink" title="代码块："></a>代码块：</h2><p>markdown原生：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> plotly.graph_objs <span class="keyword">as</span> go</span><br><span class="line"><span class="keyword">import</span> plotly.offline <span class="keyword">as</span> py</span><br><span class="line"><span class="keyword">from</span> plotly <span class="keyword">import</span> subplots</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加isPass列，得分为60及以上的学生设为几个，否则为不及格</span></span><br><span class="line">df[<span class="string">'isPass'</span>]=df[<span class="string">'score'</span>].apply(<span class="keyword">lambda</span> x: <span class="string">'及格'</span> <span class="keyword">if</span> x&gt;=<span class="number">60</span> <span class="keyword">else</span> <span class="string">'不及格'</span>)</span><br><span class="line"><span class="comment"># 将及格的学生赋值给 df_isPass</span></span><br><span class="line">df_isPass = df[df[<span class="string">'isPass'</span>] == <span class="string">'及格'</span>]</span><br></pre></td></tr></table></figure><p>Volantis2.2.1主题代码块：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200326082340.png" alt="image-20200326082338331"></p><figure class="highlight python"><figcaption><span>标题</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code snippet</span><br></pre></td></tr></table></figure><h2 id="emoji："><a href="#emoji：" class="headerlink" title="emoji："></a>emoji：</h2><p>我:heart:你，:kiss:</p><h2 id="引用："><a href="#引用：" class="headerlink" title="引用："></a>引用：</h2><p>正常的内容</p><blockquote><p>引用的内容</p></blockquote><h2 id="图片测试："><a href="#图片测试：" class="headerlink" title="图片测试："></a>图片测试：</h2><p>正常内容。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324021616.png" alt="mark"></p><p>正常内容。</p><h2 id="Tab测试："><a href="#Tab测试：" class="headerlink" title="Tab测试："></a>Tab测试：</h2><div class="tabs" id="tab-id"><ul class="nav-tabs"><li class="tab active"><a href="#tab-id-1">第一个tab的名字</a></li><li class="tab"><a href="#tab-id-2">第二个tab的名字</a></li></ul><div class="tab-content"><div class="tab-pane active" id="tab-id-1"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">代码框</span><br></pre></td></tr></table></figure><p>正常文字</p></div><div class="tab-pane" id="tab-id-2"><p>正常的文字</p><p>插入图片：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324021616.png" alt="mark"></p></div></div></div><hr><p>暂时想到了这么多，如有遗漏希望评论留言帮忙补充(<del>估计也不会有人这么闲能看这个测试看到这里</del>)，感谢。</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo本地部署流程</title>
      <link href="/post/202002192100/"/>
      <url>/post/202002192100/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>一年前用hexo部署过博客，由于其他事情导致长时间未使用，后来又尝试了wordpress与typecho，但个人比较喜欢修改主题样式，感觉wordpress与typecho的封装性太强，于是又回来继续使用hexo。记录自己重新部署hexo的过程，更新以前的部署笔记，故有的时间显示为2019年，但流程都是一样的。</p><p>这篇笔记里可以看到    </p><ol><li><a href="#本地部署过程">本地部署过程</a></li><li><a href="#博客部署到github过程">静态页面部署到github过程</a></li><li><a href="#hexo修改配置">hexo修改配置</a></li><li><a href="#绑定域名">绑定域名</a></li><li><a href="#源代码保存到github">源代码保存到github</a></li></ol><a id="more"></a><hr><h1 id="本地部署过程"><a href="#本地部署过程" class="headerlink" title="本地部署过程"></a>本地部署过程</h1><p>需要安装的东西：git、Node.js、hexo。</p><p>其中git安装完成后的Git Bash，其作用与系统自带的CMD命令行相同，系统中的CMD命令同样可以在Git Bash中完成。</p><p>链接：</p><ul><li><p><a href="https://git-scm.com/downloads" target="_blank" rel="noopener">git官方下载地址</a></p></li><li><p><a href="https://npm.taobao.org/mirrors/git-for-windows/" target="_blank" rel="noopener">git淘宝镜像下载地址</a></p></li><li><p><a href="https://nodejs.org/en/" target="_blank" rel="noopener">Node.js官网下载地址</a></p></li></ul><p>hexo使用命令安装。</p><p><a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">hexo官方文档</a>里面有关于hexo的各种使用方法，包括各个指令、文件的说明、如何更改网站的一些信息等等。</p><hr><h2 id="hexo常用指令："><a href="#hexo常用指令：" class="headerlink" title="hexo常用指令："></a>hexo常用指令：</h2><p><code>hexo new &quot;title&quot;</code> 新建文章(md文件)，title为文章的标题<br><code>hexo new page &quot;pagename&quot;</code> 新建网页，pagename为网页的名称<br><code>hexo clean</code> 清除部署的緩存<br><code>hexo n == hexo new</code> 新建一篇文章<br><code>hexo g == hexo generate</code> 生成静态页面<br><code>hexo s == hexo server</code> 本地部署，可预览网站，默认端口为4000，浏览器输入<code>localhost:4000</code>即可进入网站进行预览，回到git-bash按<code>ctrl+c</code>退出预览(退出后<code>localhost:4000</code>失效)<br><code>hexo d == hexo deploy</code> 将网站部署到GitHub<br><code>hexo g -d</code> 生成页面并部署到GitHub<br><code>hexo g -s</code> 生成页面并本地部署进行预览</p><hr><h2 id="安装git："><a href="#安装git：" class="headerlink" title="安装git："></a>安装git：</h2><p>本文章书写日期时最新版本为2.22.0版本</p><p>因版本可能不同，因此安装过程中的组件选择可能会有所差异，基本默认选项即可</p><p>下载完成后进入安装界面 (注:以下安装的选项请以实际自身需求为准，仅供参考):</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030720.png" alt="mark"></p><p>选择需要安装的组件。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030722.png" alt="mark"></p><p>选择git的默认编辑器:</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030724.png" alt="mark"></p><p>配置环境变量选项,推荐默认第二项:</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030721.png" alt="mark"></p><p>选择https传输协议 默认即可:</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030723.png" alt="mark"></p><p>选择git的换行方式 请根据自身需求更改:</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030725.png" alt="mark"></p><p>设置git命令行的样式:</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030726.png" alt="mark"></p><p>设置选项：1.是否允许文件缓存 2.是否允许git许可证管理，默认勾选：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030740.png" alt="mark"></p><p>是否参与新的测试,貌似是会使git更快，但还不稳定:</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030727.png" alt="mark"></p><p>install 安装即可:</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030728.png" alt="mark"></p><p>git安装完成后，需要进行配置，在git安装目录或菜单栏中找到git-bash，打开后如图</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030737.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030729.png" alt="mark"></p><p>输入如下，其中” “中的your name 和your email为你的Git Hub用户名(非昵称)与邮箱</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;your name&quot;</span><br><span class="line">git config --global user.email &quot;your email&quot;</span><br></pre></td></tr></table></figure><p>并可通过以下命令查询用户名与邮箱</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config user.name</span><br><span class="line">git config user.email</span><br></pre></td></tr></table></figure><p>结果如下</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030731.png" alt="mark"></p><h2 id="安装Node-js："><a href="#安装Node-js：" class="headerlink" title="安装Node.js："></a>安装Node.js：</h2><p>该文章书写时，版本为10.16.0</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030730.png" alt="mark"></p><p>安装界面:</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030732.png" alt="mark"></p><p>选择安装模式,我选择了第四个，next即可:</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030733.png" alt="mark"></p><p>以下过程命令行既可使用windows的cmd，也可以使用git安装过程中的 git-bash进行操作</p><p>命令行中输入<code>node -v</code>可查看node的版本 ,输入 <code>npm -v</code>查看npm包的版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030735.png" alt="mark"></p><p>因为npm为国外源，下载速度感人，故使用cnpm使下载指向国内源。</p><p>使用淘宝镜像下载 cnpm:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g cnpm --registry&#x3D;https:&#x2F;&#x2F;registry.npm.taobao.org</span><br></pre></td></tr></table></figure><p>下载完后查看cnpm版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm -v</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030734.png" alt="mark"></p><p>查询成功则证明安装完成。</p><h2 id="安装hexo："><a href="#安装hexo：" class="headerlink" title="安装hexo："></a>安装hexo：</h2><p>使用cnpm下载hexo,用hexo -v查看hexo的版本:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cnpm install -g hexo-cli</span><br><span class="line">hexo -v</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030736.png" alt="mark"></p><h2 id="hexo部署博客："><a href="#hexo部署博客：" class="headerlink" title="hexo部署博客："></a>hexo部署博客：</h2><p>在我的电脑中创建文件夹用于存储博客网站，即网站的站点。文件夹名称自定义，我使用blog,目录为D:\blog。打开blog文件夹，右键空白处点击Git Bash Here在该目录下打开Git Bash(或者用CMD切换到该目录也行)。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030738.png" alt="mark"></p><p>输入<code>cnpm install hexo --save</code>安装组件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm install hexo --save</span><br></pre></td></tr></table></figure><p>输入<code>hexo init</code>进行初始化，等待时间较长，约几分钟。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030741.png" alt="mark"></p><p><strong>注</strong>：若blog文件夹非空，则会报错:</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030742.png" alt="mark"></p><p>使用<code>hexo s</code> 在本地启动博客</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030739.png" alt="mark"></p><p>如图所示显示本地部署成功</p><p>打开网页，地址栏输入<code>http://localhost:4000</code>即可从本地进入博客</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030746.png" alt="mark"></p><p>目录内的各个文件的作用参考<a href="https://hexo.io/zh-cn/docs/setup" target="_blank" rel="noopener">官方文档</a></p><h1 id="静态页面部署到github过程"><a href="#静态页面部署到github过程" class="headerlink" title="静态页面部署到github过程"></a>静态页面部署到github过程</h1><h2 id="在github上创建静态网站的存储库："><a href="#在github上创建静态网站的存储库：" class="headerlink" title="在github上创建静态网站的存储库："></a>在github上创建静态网站的存储库：</h2><p>通过<code>Ctrl+C</code>停止服务</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030744.png" alt="mark"></p><p>登陆自己的Git Hub <a href="https://github.com/login" target="_blank" rel="noopener">点击进入登陆界面</a></p><p>登陆成功后，网页右上角个人头像旁边，点击 + 号 选择New repository创建一个新的仓库</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030743.png" alt="mark"></p><p>输入的信息如下，其中 Repository name内容必须是 github的用户名，而不是昵称。点击Create repository创建项目。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030745.png" alt="mark"></p><p>创建成功后，界面如图，复制https的链接。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030748.png" alt="mark"></p><p>回到git-bash 使用cnpm安装git部署插件，插件名为:hexo-deployer-git</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm install --save hexo-deployer-git</span><br></pre></td></tr></table></figure><p>安装过程中若有警告可以忽略</p><h2 id="修改-config-yml-文件："><a href="#修改-config-yml-文件：" class="headerlink" title="修改 _config.yml 文件："></a>修改 _config.yml 文件：</h2><p>打开网站目录的 _config.yml</p><p>移动到最低端，在deploy:后面写入内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">type: git</span><br><span class="line">repo: 刚刚复制的https链接</span><br><span class="line">branch: master</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030747.png" alt="mark"></p><h2 id="推送到github-page："><a href="#推送到github-page：" class="headerlink" title="推送到github page："></a>推送到github page：</h2><p>修改完成后，保存文件，在Git Bash中输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>即可将本地的网站服务器渲染出的静态页面上传到github。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030809.png" alt="mark"></p><p>该过程可能需要输入github和coding的用户名和密码，若Git Hub配置过SSH则不需要输入。</p><p>如果有报错，检查之前的配置是否有误。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;your name&quot;</span><br><span class="line">git config --global user.email &quot;your email&quot;</span><br></pre></td></tr></table></figure><p>配置语句是否正确 your name为用户名(非昵称)</p><p>推送完成后，再次进入仓库，即可看到上传完成的静态网页。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030750.png" alt="mark"></p><p>并且可以通过 <code>你的用户名.github.io</code> 来进入网站，此时网站已经部署到github page，其他人也可以通过该地址访问你的网站。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030751.png" alt="mark"></p><p><code>hexo s</code>指令仅启动本地服务，修改后只能通过localhost:4000来进行访问，此时没有推送页面到github。想要推送到github生成页面的话，需要通过<code>hexo d</code>进行推送。推送前输入指令<code>hexo clean</code>清除缓存，然后再输入<code>hexo g</code>重新生成静态页面，然后推送即可。</p><h1 id="hexo修改配置"><a href="#hexo修改配置" class="headerlink" title="hexo修改配置"></a>hexo修改配置</h1><p><a href="https://hexo.io/zh-cn/docs/configuration" target="_blank" rel="noopener">官方文档</a>里有基本的配置文件内容说明，例如修改博主名称、网站名称、副标题、描述等等。</p><h2 id="永久链接："><a href="#永久链接：" class="headerlink" title="永久链接："></a>永久链接：</h2><p>打开博客目录下的配置文件_config.yml，按<code>Ctrl+F</code>搜索 URL</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030800.png" alt="mark"></p><p>url内容不用改，修改permalink内容</p><p>其意思为：修改一篇文章的url</p><p>默认的设置为将一篇文章的创建日期+title作为永久链接，但这样并不美观，并且在分享链接时因为编码问题中文会被转码造成如下结果</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030749.png" alt="mark"></p><p>链接的格式为 你的域名/permalink内容，</p><p>比如我修改后的<code>post/:year:month:day:hour:minute/</code></p><p>会将创建文件时的年月日时分作为永久链接，避免了分享中文时的乱码。</p><p>加一个post是为了将文章统一放在一个文件夹中，在生成静态网页时，会生成一个post文件夹，里面存放生成的文章。还有其余的样式，在官方文档的永久链接中有说明。</p><p>还有一种改法是使用<code>:urlname</code>，然后在文档的头信息中给urlname参数，让该参数的值为永久链接，但同样避免不了中文转码的问题，我个人就使用日期作为永久链接了。但这样其实有个问题就是以后管理文档时，post文件夹内显示的都是日期数字，不能直观的看到文章标题。</p><h2 id="修改默认文章模板："><a href="#修改默认文章模板：" class="headerlink" title="修改默认文章模板："></a>修改默认文章模板：</h2><p>打开站点目录下的<code>scaffolds</code>文件夹，打开<code>post.md</code></p><p>该markdown文档的内容会在生成一个markdown文档后自动添加进去。</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: &#123;&#123; title &#125;&#125; </span><br><span class="line">date: &#123;&#123; date &#125;&#125; </span><br><span class="line">comments: true # 是否开启评论</span><br><span class="line">mathjax: false # 是否开启数学公式渲染</span><br><span class="line">toc: true # 是否启用目录</span><br><span class="line">top: false # 是否置顶</span><br><span class="line"></span><br><span class="line"><span class="section"># 若使用urlname作为永久链接则添加该项</span></span><br><span class="line">urlname:</span><br><span class="line"></span><br><span class="line">categories: </span><br><span class="line"><span class="bullet">- </span>[父类,子类]</span><br><span class="line"><span class="bullet">- </span>同级分类</span><br><span class="line">tags: [标签1,标签2]</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="comment">&lt;!-- more --&gt;</span></span></span><br></pre></td></tr></table></figure><p>提前设置好模板，这样生成一个新markdown文档后，只需修改urlname以及设置分类<code>categories</code>与标签<code>tags</code>即可，若主题支持，可设置是否有目录<code>toc</code>，是否置顶<code>top</code>，是否开启评论<code>comments</code>，不同的主题可能名称不同，根据自己的主题修改即可。</p><p>若有不支持的功能也不会出错，仅仅无法加载该内容。</p>hexo本地部署流程与1582117239000 为标题与文档创建日期，不需要改动<p>分类<code>categories</code>里，前面有减号<code>-</code>的表示为同级分类，中括号<code>[]</code>括起来的为父子分类。</p><p>例如</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">categories: </span><br><span class="line"><span class="bullet">- </span>[生活,笔记]</span><br><span class="line"><span class="bullet">- </span>娱乐</span><br></pre></td></tr></table></figure><p>文档在推送后，分类为生活类中的笔记类，同时也是娱乐类。</p><p>也可以将娱乐类改为 <code>[娱乐,音乐]</code>，这样就同时是娱乐类中的音乐类。</p><h1 id="绑定域名"><a href="#绑定域名" class="headerlink" title="绑定域名"></a>绑定域名</h1><h2 id="解析域名"><a href="#解析域名" class="headerlink" title="解析域名"></a>解析域名</h2><p>以我的域名为例，不同商家解析时都差不多。在域名管理处点击解析</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030752.png" alt="mark"></p><p>点击添加记录。会出现如图的添加设置。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030755.png" alt="mark"></p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030757.png" alt="mark"></p><p>主机记录可理解为域名前缀，即用户输入什么样的网址访问到该解析目标。如果主机记录为www ，则用户需要输入www.[你的域名]才能访问到该解析目标。如果为@，则直接输入域名即可。如果不添加www ，则通过www+域名方式访问的用户将访问失败，@同理，其余的也同理。</p><fancybox><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030754.png" alt="mark"></p></fancybox><p>记录类型为解析目标的类型，如果想把该域名绑定到一个ip地址，则选A，如果目标为一个网址，则选CNAME。</p><p>这里有两种绑定方法，一种是选CNAME然后在记录值填写 [yourname].github.io ，另一种是选A，然后通过cmd命令行输入 <code>ping [yourname].github.io</code> 获取ip地址，记录值里填入ip地址。</p><p>获取 [yourname].github.io 的ip地址，如图，ping通后会显示ip地址。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030753.png" alt="mark"></p><p>记录值根据选择的记录类型进行填写。线路选默认。TTL为缓存生效时间，默认600秒即可，即10分钟后生效(实际大约需要5 分钟)。填写完毕后点击保存。可以为域名填写多个记录， 如图</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030756.png" alt="mark"></p><p>前两个是为github pages绑定时添加的记录，一个www、一个@，这样可以让用域名直接访问的和加了www访问的用户都能访问到自己的博客 (部署到服务器后就不再用了所以暂停了)。接下来两条A类型是将网站部署到自己的服务器时，把域名解析到了自己的服务器IP地址，这样可以通过www、或者直接输入域名的方式来访问自己的服务器。最后一条是绑定的七牛云，用来当做博客的图床。每条记录后面都有操作可以进行修改以及暂停和开启。</p><h2 id="绑定到github-pages"><a href="#绑定到github-pages" class="headerlink" title="绑定到github pages"></a>绑定到github pages</h2><p>登陆到自己的github，进入网站绑定的仓库，进入设置</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030759.png" alt="mark"></p><p>往下找到GitHub Pages，在Custom domain填入刚刚购买的域名，点击save保存。勾选Enforce HTTPS则开启HTTPS安全协议。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030758.png" alt="mark"></p><p>然后到本地博客<code>source</code>文件夹下新建文件CNAME，输入内容为自己的域名，并将文件尾缀如<code>.txt</code>等删掉然后保存即可。(没有的话貌似每次将代码从本地推到github都会使域名访问404，因为每次推送都会覆盖原本的仓库代码。所以把CNAME文件放在source中，使每次推送都会建立一个CNAME)</p><p>至此，github pages的域名绑定完成了，稍等片刻即可尝试使用域名访问。</p><h1 id="源代码保存到github"><a href="#源代码保存到github" class="headerlink" title="源代码保存到github"></a>源代码保存到github</h1><h2 id="创建分支"><a href="#创建分支" class="headerlink" title="创建分支"></a>创建分支</h2><p>在仓库中的文件列表的左上方，点击Branch。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030802.png" alt="mark"></p><p>搜索 source （分支名，自定义），会提示未找到，是否创建，点击即可创建该分支</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030804.png" alt="mark"></p><h2 id="设置新建分支为默认分支"><a href="#设置新建分支为默认分支" class="headerlink" title="设置新建分支为默认分支"></a>设置新建分支为默认分支</h2><p>进入设置，左边的列表中选择 Branches，默认分支为master，改为新建的分支，然后点击Update更新。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030805.png" alt="mark"></p><h2 id="同步配置"><a href="#同步配置" class="headerlink" title="同步配置"></a>同步配置</h2><p>首先随便找个地方新建一个文件夹，将你的仓库克隆下来。</p><p>打开新建的文件夹，右键空白处点击<code>Git Bash Here</code></p><p>然后输入下方命令克隆文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone 【你的仓库地址】</span><br></pre></td></tr></table></figure><p>仓库地址获取方法：</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030803.png" alt="mark"></p><p>点击红框内的按钮复制，然后粘贴到clone后面即可，用空格与clone隔开。</p><p>克隆完成后，该文件夹内会出现<code>【你的用户名】.github.io</code>文件夹，进去拷贝<code>.git</code>文件夹到本地的博客根目录，然后这个新建的文件夹就可以删除了。</p><p>接下来在博客根目录右键空白处，打开git bash，输入下方命令，警告不用理会，若没出现报错就没问题。</p><p>会需要github的帐号密码，填一下就OK了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin 【你的仓库地址】</span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;【描述，随便写】&quot;</span><br><span class="line">git push origin 【你的保存源代码的分支名】</span><br></pre></td></tr></table></figure><p>描述部分的效果如图，会将内容显示在该分支上。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030807.png" alt="mark"></p><p>每次推送时，输入的描述都会在这次推送时更新的文件后面显示出来。</p><p>接下来每次想保存时，输入下方指令即可，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m &quot;【描述】&quot;</span><br><span class="line">git push</span><br></pre></td></tr></table></figure><p>但每次都要输入这么多很麻烦，可以创建一个脚本文件，在博客根目录下新建一个txt文本文件，名字随意自己能知道是保存用的就行，将上方三条指令写进去，描述写好后以后固定都是这个，然后将文件改为<code>.sh</code>结尾。也可以直接建一个<code>.sh</code>尾缀文件，然后用编辑器打开写入。这样以后每次运行这个脚本文件就会自动执行上面三条指令，完成推送。</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030806.png" alt="mark"></p><p>本地同步到github就完成了，但要注意的是只保存了关键文件，如主题、文章、配置等。</p><p>node_modules文件夹和public文件夹是没有保存上去的，public文件夹是生成的静态页面，不需要保存，若迁移后直接生成就有了。</p><p>node_modules文件夹存放着需要用到的插件，如果想保存的话，打开<code>.gitignore</code>文件，把里面的node_modules删掉保存即可，但是这样会造成每次保存都需要很久时间，因为里面东西太多了，看个人需要决定是否需要保存。</p><p>只要配置文件里面的deploy里的branch的值是master的话，生成的静态页面会推送到master分支</p><p><img src="https://cdn.jsdelivr.net/gh/lluuiq/blog_img/img/20200324030808.png" alt="mark"></p><p>配置完成后，若以后要迁移到其他的服务器或者电脑上，只需要安装好git、Node.js、hexo，然后使用<code>hexo init</code>命令初始化一个根目录，再克隆下来就行了，若不指定克隆分支的话，会克隆默认分支，即设置好的保存博客源代码的分支。</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>

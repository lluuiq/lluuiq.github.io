---
title: 吴恩达深度学习编程作业1-2
comments: true
toc: true
top: false
mathjax: true

categories:
- [神经网络,学习笔记]
tags: [神经网络]

date: 2020-06-08 22:33:21
---

吴恩达深度学习课程《神经网络和深 度学习》第二周（神经网络基础）的编程作业。

<!-- more -->

## 说明

感谢作者[阿宽](https://blog.csdn.net/u013733326)提供作业题目[【中文】【吴恩达课后编程作业】Course 1 - 神经网络和深度学习 - 第二周作业](https://blog.csdn.net/u013733326/article/details/79639509)

数据集以及题目可在该博文中查看与下载。

同时参考了作者[iSunwish](https://blog.csdn.net/iSunwish)的博文[深度学习（三）实战：动手实现猫图识别](https://blog.csdn.net/iSunwish/article/details/88364097)

  

题目是建立神经网络来通过图片识别猫。虽然说是通过图片来识别，但给出的数据集已经将图片转为矩阵数据存为h5文件。所以读取出来的数据即可直接用来操作，不用进行处理图片的操作。  



lr_utils.py文件已经实现了对数据的读取，我们要做的就是在代码中执行该文件中的函数来获取返回值即可。

将下载好的数据集与lr_utils.py 放在与自己的代码相同的文件夹中。

需要用到的库：

- numpy 数据科学计算的库
- matplotlib 绘图
- h5py 用于交互H5文件（作业的数据集是h5文件）
- scikit-image 用于图像处理  

## 查看自带的lr_utils.py文件

lr_utils.py的代码如下，中文注释为自己添加的说明

```python
import numpy as np
import h5py
    
    
def load_dataset():
	# 读取训练集数据
    train_dataset = h5py.File('datasets/train_catvnoncat.h5', "r")
    # train_set_x_orig 存储训练集的特征
    train_set_x_orig = np.array(train_dataset["train_set_x"][:]) # your train set features
    # train_set_y_orig 存储训练集的标签
    train_set_y_orig = np.array(train_dataset["train_set_y"][:]) # your train set labels

	# 读取测试集数据
    test_dataset = h5py.File('datasets/test_catvnoncat.h5', "r")
    # test_set_x_orig 存储测试集的特征
    test_set_x_orig = np.array(test_dataset["test_set_x"][:]) # your test set features
    # test_set_y_orig 存储测试集的标签
    test_set_y_orig = np.array(test_dataset["test_set_y"][:]) # your test set labels

	# 用classes存储其是猫还是不是猫的二进制字符串（感觉没什么意义？）
    classes = np.array(test_dataset["list_classes"][:]) # the list of classes
    
    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))
    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))
    
    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes
```

## 读取数据

```python
# 加载 lr_utils的load_dataset函数
from lr_utils import load_dataset
# 定义变量来获取load_dataset函数的返回值
train_set_x , train_set_y , test_set_x , test_set_y , classes = load_dataset()
```

执行上述代码后，可以输出变量的shape来查看维度

```python
print("训练集特征的维度：",train_set_x.shape,"训练集特征的类型",type(train_set_x))
print("训练集标签的维度：",train_set_y.shape,"训练集标签的类型",type(train_set_y))
print("测试集特征的维度：",test_set_x.shape,"测试集特征的类型",type(test_set_x))
print("测试集标签的维度：",test_set_y.shape,"测试集标签的类型",type(test_set_y))
print("classes的维度：",classes.shape,"classes的类型",type(classes))
```

结果：

[![image-20200608052649184](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045854.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045854.png)

可以看到：

- 所有变量都是ndarray类型（数组），用数组来表示的矩阵。
- 训练集特征一共有209条数据，都是64*64的矩阵（即64x64像素的图片），后面的3表示为图像的RGB三通道（红绿蓝）。
- 训练集标签是一维数组，有209个数据。
- 测试集特征一共有50条数据，其余与训练集相同。
- 测试集标签同训练集标签是一维数组，有50条数据。
- classes的shape为(2,)，其是一个一维数组，有两个数据。

输出一下classes，即可看到其数据

```python
print(classes)
```

结果为：

[![image-20200608052714502](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045859.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045859.png)

其是一个二进制的值，值为 ‘non-cat’ 或 ’cat’ 。

若有兴趣也可以输出训练、测试集的特征与标签变量来查看具体的值。

## 使用 matplotlib 查看图片（可选）

吴恩达教授说过，人类擅长处理非结构化数据，而机器擅长处理结构化数据。通过一堆数字我们不能判断这一个样本是一张什么样的图片，故可以使用matplotlib来通过数据绘出原本的图片。

目前所知，train_set_x里存储的都是图片在计算机上的表示，一共有209个样本。我们可以使用 matplotlib 库的imshow函数来直接绘制图片。这里我使用numpy来生成一个随机数进行随机查看。

```python
import matplotlib.pyplot as plt
import numpy as np
num = np.random.randint(0,209)
print("第",num,"个样本的图片为：")
plt.imshow(train_set_x[num])

print("其标签为",np.squeeze(train_set_y)[num],"是一张",classes[np.squeeze(train_set_y)[num]].decode("utf-8"),"图片")
```

多次运行后挑选两个结果：

[![image-20200608011747155](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045902.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045902.png))[![image-20200608011725392](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045907.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045907.png)

**注意：**

- 使用numpy的randint函数来生成一个范围为 [0,209) 的一个随机数，传入的范围是左闭右开区间，且因为是数组所以要从0开始，下标最大值为208，所以应该传入的范围是 0与209。
- numpy的squeeze函数来压缩数组，它会将数组中单维度的条目去掉，进行压缩。比如[[1],[2],[3]] 这是一个维度为(1,3)的数组，压缩后会将无意义的维度去掉，转为[1,2,3]的一维数组。
- classes[X]，指定classes中的值后，要加个decode(“utf-8”)来将原本的二进制数据转为utf-8来输出。否则输出结果会变成 b’cat’ 或者 b’non-cat’ 。（当然仅仅是个人查看的话可以不加）

## 数据处理

### 转换图片的存储方式

图片在计算机中的存储方式为 像素*3 ，而原本的特征矩阵的维度显然不符合该标准，故应该转为维度为（64*64*3，209或50）的数组。（训练集为209，测试集为50）

使用numpy的reshape与 .T 来进行处理。

```python
train_set_x_flatten = train_set_x.reshape(train_set_x.shape[0],-1).T
test_set_x_flatten = test_set_x.reshape(test_set_x.shape[0],-1).T
```

以训练集举例：

1. `train_set_x.shape[0]`出第一个 维数，即样本个数。

2. `reshap(train_set_x.shape[0],-1)`指定行数为样本个数，列数设置为-1让numpy自行计算像素与三色道的组合 。最终转为行数为样本个数，多维数组每一行都是 64*64*3的图片矩阵 的一个二维数组。

   [![image-20200608013821081](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045911.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045911.png)

   红框内即图片矩阵，然后一共有209个图片矩阵。此时维度为（209，64*64*3）

3. 最后通过.T来进行转置，变为维度为（64*64*3，209）的矩阵。然后存储在新变量中。

输出一下看看维度

```python
print("转换后的训练集维度：",train_set_x_flatten.shape)
print("转换后的测试集维度：",test_set_x_flatten.shape)
```

结果为：

[![image-20200608052730484](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045914.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045914.png)

### 转换数据取值范围

对数值进行归一化 ，将其取值范围定为[0,1]之间。图片数据的处理直接除以255即可。

```python
train_set_x_flatten_normalization = train_set_x_flatten/255
test_set_x_flatten_normalization = test_set_x_flatten/255
```

## 构建无隐藏层的神经网络

### 流程：

- 准备好输入特征
- 初始化模型参数
- 通过正向传播、反向传播进行梯度下降

### 导入numpy库

```python
import numpy as np
```

若在[使用 matplotlib 查看图片（可选）](# 使用 matplotlib 查看图片（可选）)中已经导入过numpy库，则直接执行下一步即可。

### 定义sigmoid函数

在吴恩达深度学习的课程中，该作业属于第二周 神经网络基础，故使用的是sigmoid函数，暂时未使用tanh与ReLU函数。

```python
def sigmoid(z):
    a = 1 / (1 + np.exp(-z))
    return a
```

### 定义初始化模型参数函数

模型参数w要与输入特征的维度对应。即w的维度应该为（输入特征x的特征数n_x，1）

模型参数b的维度应该为 （1，输入特征x的样本数m），不过b可以直接赋值0，利用python广播来计算。

输入特征x的特征数n_x可以通过 输入特征向量.shape[0]来获得。

输入特征x的样本数m可以通过 输入特征向量.shape[1]来获得。

```python
def initialization_parameters(nx):
#     # 随机初始化
#     w = np.random.rand(nx,1)*0.01
    w = np.zeros(shape = (nx,1))
    b = 0
    return (w , b)
```

这里其实可以用在第三周（浅层神经网络）中的课程 随机初始化中提到的知识点，直接将w初始为随机数。

但由于没有隐藏层，或者说只有一个输出单元，所以初始化为0或者随机数都一样。

为了方便与别人的作业观测差距，故这里还是使用了初始化为0。

### 关于梯度下降的说明

先看下伪代码：

```python
for i in range(迭代次数):
	Z=np.dot(w.T,X)+b
	A=sigmoid(Z)
	dz=A-Y
	dw=(1/m)*np.dot(X,dz.T)
	db=np.sum(dz)/m
	w = w - α*dw
	b = b - α*db
```

目前已知：

- 输入特征X
- 初始化的参数w与b
- 激活函数sigmoid
- 输入特征X的个数 m

可以计算得出：

- dz
- dw
- db

未知：

- 学习率α（需要自定义）

需要添加：

- 代价函数（用于判断是否最小化）

这里可以在每次梯度下降时都存储一次代价函数的值，用于后面绘图来观测代价函数的变化情况。

### 定义梯度下降函数

关于详细的解释放在了代码中，逐一拿出来说明容易混乱。

```python
# 传入参数为：模型参数w、b，训练集的特征、标签，学习率，迭代次数
def gradient_descent(w, b, X, Y, alpha, iterations_num):
    # 获取输入特征个数
    m = X.shape[1]
    X = X.reshape(X.shape[0], m)
    cost_list = []
    for i in range(iterations_num):
        # **正向传播**
        Z = np.dot(w.T, X)+b  # 计算Z
        A = sigmoid(Z)  # 计算激活函数值
        cost = (- 1 / m) * np.sum(Y * np.log(A) +
                                  (1 - Y) * (np.log(1 - A)))  # 计算代价函数
        # **正向end**

        # **反向传播**
        dz = A-Y  # 计算dz
        dw = (1/m)*np.dot(X, dz.T)  # 计算dw
        db = np.sum(dz)/m  # 计算db
        # **反向end**
		
        # 更新参数
        w = w-alpha*dw
        b = b-alpha*db
        
        # 每迭代100次存一次代价函数值，并且输出当前的迭代次数与代价函数值
        if(i % 100 == 0):
            cost_list.append(cost)
            print("迭代次数：", i, "，代价：", cost)
            
    # 记录参数，作返回值
    param = {
            "costs": cost_list,
            "w": w,
            "b": b,
            "alpha": alpha
        }
    return param
```

### 执行梯度下降

说明一下，训练集特征的维度此时为(12288,209) 课程中表示为 （n_x，m），模型参数w的维度应该为(12288,1) ，这样在计算假设函数Z时，w.T的维度为(1,12288)，符合定义，且能够与 X进行矩阵内积。最后Z的维度为(1,209)，即课程中的 1xm。

1. 首先获取训练集特征的特征数（非样本数），用nx来存储。
2. 初始化模型参数w与b。
3. 进行梯度下降，并用param来接收最后结果的返回值

```python
# 通过.shape[0]获得训练集输入特征x的特征数
nx = train_set_x_flatten_normalization.shape[0]
# 初始化模型参数w与b
w, b = initialization_parameters(nx)
# 执行梯度下降，并用param来获取返回值
param = gradient_descent(w, b, train_set_x_flatten_normalization,
                         train_set_y, alpha=0.005, iterations_num=2000)
```

- alpha为学习率，这是一个自定义的值，需要用户手动选择来输入，目前无法直接确定最优的学习率，现在先通过人为的调试与观察来选择较优的学习率，关于更好的方法日后再讨论。
- iterations_num为迭代次数，也是用户手动输入，但基本有一个阈值，达到迭代次数后，代价函数值就基本不会改变（已最小化或接近最小化）。

结果：

[![image-20200608050526192](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045922.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045922.png)

## 进行预测

### 定义预测函数

传入的参数为由梯度下降得到的模型参数w、b，以及进行预测用的输入特征。

- 首先初始化向量Y，维度为（1，输入特征的样本数m），用于存放预测结果。
- 走一遍逻辑回归模型（计算Z、激活函数A），最后A中的结果即为预测概率。
- 如果概率大于0.5，则Y的对应值置为1（表示是猫），否则置为0（表示不是猫）。

```python
def predict(w, b, X):
    Y = np.zeros((1, X.shape[1]))
    Z = np.dot(w.T, X)+b
    A = sigmoid(Z)
    for i in range(A.shape[1]):
        Y[0][i] = 1 if A[0][i] > 0.5 else 0
    return Y
```

### 对训练集与测试集进行预测

通过param[‘w’]与param[‘b’]即可获得梯度下降结果的模型参数w、b，并将要进行预测的输入特征传入预测函数中。

```python
# 对训练集进行预测
train_predict_y = predict(param['w'], param['b'], train_set_x_flatten_normalization)
# 对测试集进行预测
test_predict_y = predict(param['w'], param['b'],test_set_x_flatten_normalization)
```

### 查看准确率

采用的准确率公式 ：

预测的标签值原数据集正确的标签值的绝对值样本个数100−[(预测的标签值−原数据集正确的标签值)的绝对值样本个数]∗100

```python
print("训练集准确率：", format(100-np.mean(np.abs(train_predict_y-train_set_y))*100), "%")
print("测试集准确率：", format(100-np.mean(np.abs(test_predict_y-test_set_y))*100), "%")
```

结果：

[![image-20200608052809376](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045929.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045929.png)

## 观测代价函数变化情况

使用matplotlib进行绘图，在之前观察图片时已经导入过matplotlib库。

```python
# 设置字体，使得能够显示中文
plt.rcParams['font.family']='SimHei'
# 设置字体大小
fontsize=13

# 传入代价函数数组
plt.plot(param['costs'])
# 设置y轴标题与y轴字体大小
plt.ylabel('代价函数值',fontsize=fontsize)
plt.yticks(fontsize=fontsize)
# 设置x轴标题与x轴字体大小
plt.xlabel('迭代次数（单位：百）',fontsize=fontsize)
plt.xticks(fontsize=fontsize)
# 设置图片标题
plt.title("学习率：" + str(param['alpha']),fontsize=fontsize)
plt.show()
```

结果：

[![image-20200608053712997](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045931.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045931.png)

## 打包模型

定义一个函数，用于传入参数后进行构建神经网络并直接返回结果

```python
def model(train_set_x,train_set_y,test_set_x,test_set_y,alpha,iterations_num):
    nx = train_set_x_flatten_normalization.shape[0]
    w, b = initialization_parameters(nx)
    param = gradient_descent(w, b, train_set_x,
                         train_set_y, alpha=alpha, iterations_num=iterations_num)
    train_predict_y = predict(param['w'], param['b'], train_set_x)
    test_predict_y = predict(param['w'], param['b'],test_set_x)
    print("训练集准确率：", format(100-np.mean(np.abs(train_predict_y-train_set_y))*100), "%")
    print("测试集准确率：", format(100-np.mean(np.abs(test_predict_y-test_set_y))*100), "%")

    result={
        'costs':param['costs'],
        'w':param['w'],
        'b':param['b'],
        'alpha':param['alpha'],
        'train_predict_y':train_predict_y,
        'test_predict_y':test_predict_y,
        'iterations_num':param['iterations_num']
    }
    return result
```

将上述流程集合进该函数中，这样只需要传入归一化后的训练集测试集的输入特征、以及训练集测试集的标签，再给定学习率与迭代次数，执行函数后，会输出相应迭代次数的代价（可以在梯度下降函数中将输出代价的代码去掉，简化输出内容），并且返回字典数据类型来存储模型中的一些值。

如果要进行预测，则执行[定义预测函数](# 定义预测函数)中的预测函数，参数为建模后的w、b，以及要进行预测的数据集的输入特征即可，返回值为预测的标签数组。

## 寻找较优学习率（待补充）

pass

## 上传图片进行测试

### 安装scikit-image库

三种安装库的方法。

1. windows终端命令：

   ```python
   pip install scikit-image
   ```

2. conda终端命令：

   ```python
   conda install scikit-image
   ```

3. 使用Anaconda Navigator进行安装：

   [![image-20200609114326154](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045935.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611045935.png)

安装好后，从skimage中导入io、transform与img_as_ubyte

- io：读取与保存图片
- transform：使用resize转换图片像素
- img_as_ubyte：转换图片数据类型

```python
from skimage import io,transform,img_as_ubyte
```

### 准备图片

首先准备好一张图片放在代码文件的同目录下（不在同一个目录也可以，修改path即可）

以名为cat.jpg的下图为例（百度“猫”，结果第一张）

[![cat.jpg](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050409.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050409.png)

其像素可以鼠标悬浮在文件上查看，1056*1065

[![image-20200609112731831](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050415.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050415.png)

然后使用plt的imread函数读取图片。

```python
path = 'cat.jpg'
img = io.imread(path)
print("读取图片的维度为：",img.shape,"\n输出图片：\n",img)
```

结果为：

[![image-20200609112602562](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050417.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050417.png)

可以看到其存储方式为 (像素，3)，3即三色道矩阵。

### 转换图片像素并归一化

使用transform.resize来转换图片的像素，使其与训练集的图片像素一致。

transform.resize会自动对图片的值进行归一化。

需要注意的是transform.resize会将图片的值的数据类型转为float，故使用img_as_ubyte函数转回uint8

```python
px = train_set_x.shape[1]
image = transform.resize(img,(px,px))
image = img_as_ubyte(image)
```

### 转为对应输入特征x的存储方式。

```python
X_flatten = img.reshape(1,-1).T
print(X_flatten.shape)
```

即 （64*64*3，1），这样就与训练集的输入特征x的存储方式一致了。

### 对上传图片进行预测

假若已经建立好模型（得到模型变量model），则直接执行[进行预测](# 进行预测)中的流程即可。

需要注意的是返回值Y是一个维度为（1，m）的向量。m为输入特征的样本数，故查看结果使用`Y[0][0]`即可。

若是多张图片则需要遍历查看对应的预测值，或直接输出Y来观察预测值。

```python
Y = predict(model['w'],model['b'],X)
result = int(Y[0][0])
print("预测值为：",result,"\n这是一张 ",classes[result].decode('utf-8')," 图片")
```

~~classes这个返回值我终于用上了~~

预测结果

[![image-20200609124045755](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050420.png)](https://gitee.com/lluuiq/blog_img/raw/master/img/20200611050420.png)

### 打包预测上传图片代码

```python
from skimage import io,transform,img_as_ubyte

def predict_cat(path):
    img = io.imread(path)
    px = train_set_x.shape[1]
    image = transform.resize(img,(px,px))
    image = img_as_ubyte(image)/255
    X_flatten = image.reshape(1,-1).T
    
    Y = predict(model['w'],model['b'],X_flatten)
    result = int(Y[0][0])
    print("预测值为：",result,"\n这是一张 ",classes[result].decode('utf-8')," 图片")
    return Y
```

## 总结

准备了两张猫的图片，两张狗的图片，一张马，一张豹子，一张白菜，一张纯黑色的图，一张纯白色的图。

结果预测为猫的有一张猫的图片，豹子、纯黑与纯白的图。

准确率还是不够高，后尝试通过更改学习率进行优化。